---
title: "Information Theory and Machine Learning Reveal Synergistic Interactions in
  Gut Microbiota Related to Disease - data analysis pipeline"
output:
  html_document:
    toc: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Initial data preparation

Read the raw taxonomy abundance info and metadata from delimiter separated files.

```{r read}
metadata.filename <- "merged_metadata.txt"
taxa.filename <- "merged_taxonomy.txt"
tdata <- as.data.frame(t(read.delim(taxa.filename, header = TRUE, sep = "\t")))
colnames(tdata) <- tdata[1,]
tdata <- tdata[-1,]

metadata<-read.delim(metadata.filename, header = TRUE, sep = "\t")
#rownames(metadata)<-metadata[,1]
#metadata<-metadata[,-1]

```

## Selection of the cohorts with reasonable class sizes


```{r}

read.table("duze.asc") |> unlist() |> unname() -> cohort_ids 
cohort_ids[[2]]="HMP_2019_t2d"
cohort_ids<- cohort_ids[-c(2,4)]
lapply(cohort_ids, function(id){
  print(id)
  print(metadata$category[metadata$cohort==id] |> table())
}
  ) |> invisible()

```

#### Binary problem preparation

Healthy vs rest.

Decision vectors are stored in a list `decision`, `decision$cohor_name` gives the vector for the corresponding cohort.

1 encodes the state of disease present, 0 - healthy.

exact disease names encoded by 1 can be seen by inspecting `attr(decision$cohort_name, "code_dict")`

```{r}

lapply(cohort_ids,
       function(id){
         dec<-metadata$category[metadata$cohort==id] |> as.character()
         unique(dec)-> classes
         classes[classes!="healthy"] |> paste0( collapse="_or_") -> other
         dict= list(healthy=0,
                    other=1)
         names(dict)[[2]]<-other
         y=rep(0, length(dec))
         y[dec!="healthy" ]=1
         attr(y,"code_dict")<-dict
         names(y)<- metadata$sample[metadata$cohort==id]
         return(y)
       }
         )-> decision
names(decision)<-cohort_ids


```

### Taxa table preparation 

Similarly, taxa abundancies are stored in list of data.frames, one row per sample. Row order is obviously matched with the ordering of the samples in the corresponding decision vector.

#### Remove cohorts with no fully matching ids between taxa abundance and metadata

```{r}
allOK <-sapply(decision, function(y) length(intersect(names(y), rownames(tdata) ))==length(names(y)))
cohort_ids<- cohort_ids[allOK]
decision<- decision[allOK]
taxa<- lapply(decision, function(y)
                tdata[names(y),])
taxa<-lapply(taxa, function(df)
                    lapply(df, as.numeric) |> as.data.frame()
  )

```

#### Alpha diversity analysis and normalization

Normalize abundancies and use proportions to calculate 3 versions of alpha diversity indexes and plot them against the cumulative abundance in each sample. 

At this stage of preprocessing, we do not see any evidence for clear relationship between diveristy value and the cumulative abundance, so we do not filter the data further in the "samples" dimension.

```{r}
diversity_indices<- function(tdata, data_name){
lib_sizes<- rowSums(tdata) 
  t_props<-( tdata
            )/lib_sizes #due to R recycling, each row gets divided by its sum
  shannon_div<- -rowSums((t_props+1e-10)*log(t_props+1e-10))
  simpson_index<- rowSums ( 1 - t_props^2  )
  inverse_simp<- 1/rowSums( t_props^2 )
  size_order<-order(lib_sizes)

  #taxa_min_lib_size= 3636 
  #crit_rank= which.min(abs(lib_sizes[size_order] - taxa_min_lib_size))

  plot(shannon_div[size_order],type='l', main=data_name, 
       ylab="shannon diversity", xlab="library size rank")
  #abline(v = crit_rank, col="red",lwd=2) 
  plot(simpson_index[size_order],type='l', main=data_name,
       ylab="simpson diversity",xlab="library size rank")
  #abline(v = crit_rank, col="red",lwd=2) 
  plot(inverse_simp[size_order],type='l', main=data_name,
       ylab="inverse simpson index",xlab="library size rank")
  #abline(v = crit_rank, col="red",lwd=2) 
}
```


```{r}
 mapply(diversity_indices, taxa, names(taxa)) |> invisible()
```

```{r}

lapply(taxa, function(data) data/rowSums(data))-> taxa

```


#### Binarization


```{r}

mapply(function(data, name)
  {(colSums(data>0))|> sort() |> plot(main=sprintf("%s, nubmers of non zero entries per taxa
  # of taxa w/ # of non zero entries>=30 = %d",name, sum(colSums(data>0)>=30)  ),
  xlab="# non zero entries",ylab="taxon"); abline(h=30)},
  taxa,names(taxa)) |> invisible()


```




We use two approaches: binarization based on median or zero. 
In case of median, entries less than or equal to median normalized abundance for each taxon are zeroed out, while for "zero" strategy, zero entries get mapped to zeros an other to ones. 
The only difference will be visible in case of common taxa, being present in more than half of the samples.

```{r}

library(matrixStats)
binarize_taxa<- function(taxonomy, binarize_on_median=TRUE){
  taxonomy<- as.matrix(taxonomy)
meds= if (binarize_on_median) colMedians(taxonomy) else rep(0,ncol(taxonomy))
tb<- t( t(taxonomy)>meds )*1. #exploit recycling mechanism.
			      #column [[i]] of `taxonomy` gets binarized by meds[[i]]
return(tb)}

taxa_binary<- lapply(taxa, binarize_taxa, binarize_on_median=TRUE)
names(taxa_binary)<- paste0(names(taxa_binary),"_med")
taxa_binary0<- lapply(taxa, binarize_taxa, binarize_on_median=FALSE)
names(taxa_binary0)<-paste0(names(taxa_binary0),"_0")
taxa_binary<- c(taxa_binary,taxa_binary0)


```

#### Filter taxa with insufficient sample count per binary class for information theoretic inference

```{r}

filter_sparse_cols<- function(data, thr) {
  #including data==0 matters only for few common taxa in "zero" based binarization
  pmin(colSums(data==0),colSums(data==1))-> minority_count
  data[, minority_count >= thr]
  
}

lapply(taxa_binary, filter_sparse_cols,30)-> taxa_binary



```

### test FS procedures

```{r}
# script contains function for U-test  based feature selection
source("resample_FS_procedure.R")

```


```{r}
mapply( function(X,y){
          U_test_FS(data=X,decision=y,lvl=0.05,p.adjust.method = "holm")},
        taxa, decision, SIMPLIFY = FALSE
  )-> U_test

```

We apply MDFS on two types of binary data, and select final relevant set as union of those two approaches

```{r}
library(MDFS)
mapply( function(X,y){ attributes(y)<-NULL;
        MDFS.discrete(data=X,decision = y,dimensions = 1,
                      p.adjust.method = "holm",level=0.05,seed=123) } ,
        taxa_binary, decision, SIMPLIFY = FALSE
  )-> MDFS_1D
mapply( function(X,y){attributes(y)<-NULL
        MDFS.discrete(data=X,decision = y,dimensions = 2,
                      p.adjust.method = "holm",level=0.05,seed=123) } ,
        taxa_binary, decision, SIMPLIFY = FALSE
  )-> MDFS_2D

```

```{r}

mapply(function(X,mdfs)
      colnames(X)[mdfs$relevant.variables],taxa_binary,MDFS_1D,SIMPLIFY = FALSE
  )-> MDFS_1D_rel
mapply(function(X,mdfs)
      colnames(X)[mdfs$relevant.variables],taxa_binary,MDFS_2D,SIMPLIFY = FALSE
  )-> MDFS_2D_rel

for (nm in names(taxa))
{
 grep(nm,names(taxa_binary))-> cohort_mask
 MDFS_1D_rel[[nm]]<- Reduce(union,MDFS_1D_rel[cohort_mask])
 MDFS_2D_rel[[nm]]<- Reduce(union,MDFS_2D_rel[cohort_mask])
}

```

#### Compare U-test and MDFS on each of the cohorts:

```{r}

intersection_matrix<- function(sets_list){
  
  M<-matrix(nrow=length(sets_list),ncol=length(sets_list))
  for (i in seq_along(sets_list))
    for (j in seq_along(sets_list))
      M[i,j]= length(intersect(sets_list[[i]],sets_list[[j]]))
  colnames(M)<-rownames(M)<-names(sets_list)
  M
}


for (nm in names(U_test)){
  print(nm)
  print(
    intersection_matrix(
      list(U_test=U_test[[nm]]$rel_set,
           MDFS_1D=MDFS_1D_rel[[nm]],
           MDFS_2D=MDFS_2D_rel[[nm]],
           MDFS_1_or_2D= union(MDFS_2D_rel[[nm]], MDFS_1D_rel[[nm]]))
    )
  )
  
}
  

```



### Inspect synergistic interactions obtained from 2D analysis

```{r}
get_interaction_partner<- function(dataset, decision, interesting.vars, ...){
attributes(decision)<-NULL
if (!(all(interesting.vars %in% 1:ncol(dataset))))
        stop("interesting.vars must be in 1:ncol(dataset)")

if (is.null(colnames(dataset)))
        stop("datatset should have column names (taxa names)")

best.tuples <- ComputeInterestingTuplesDiscrete(dataset,
                                        decision,
                                        interesting.vars =interesting.vars,                                         ...
                                          )
do.call(rbind,
       lapply(interesting.vars, function(V){

               V_subset<- best.tuples$Var == V
               V_which.max<- which.max( best.tuples[ V_subset,]$IG )
              m_t1<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.1"]]
              m_t2<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.2"]]
              p_IDX<- if( V== m_t1) m_t2 else m_t1
              data.frame( rel_IDX= V, partner_IDX= p_IDX, rel_name = colnames(dataset)[[V]],                                                                             partner_name= colnames(dataset)[[p_IDX]],
                 rel_IG= best.tuples[ V_subset, ][V_which.max,][["IG"]] )
              }
             )
       )
}
```

```{r}

mapply(function(data, dec, mdfs){
        get_interaction_partner(dataset=data, decision = dec, 
                                interesting.vars = mdfs$relevant.variables)-> res
                      res[order(-res$rel_IG),]},
       taxa_binary, c(decision,decision), MDFS_2D, SIMPLIFY = FALSE )-> partners

```

#### Strongest 2D interactions

```{r}

for (cohort in names(taxa)){
  
  partners[ grep(cohort,names(partners)) ]-> sublist
  
  do.call(rbind, lapply(sublist, function(df) df[1,] ))-> df.strongest
  idx.strongest<- which.max(df.strongest$rel_IG)
  best_pair<- df.strongest[idx.strongest, c("rel_name","partner_name")]
  names(partners)[grep(cohort,names(partners))][idx.strongest]-> variant_used
  taxa_binary[[variant_used]][, best_pair$rel_name]-> rel_taxa
  taxa_binary[[variant_used]][, best_pair$partner_name] -> partnering_taxa
  table(rel_taxa ,
    partnering_taxa,
    decision[[cohort]]
    )-> tab
  print(cohort)
  print(sprintf("rel_taxa: %s, partner: %s", best_pair$rel_name, best_pair$partner_name))
  print(table(decision[[cohort]]))
  print((tab[,,1]/sum(tab[,,1]) )|> round(2))
  print((tab[,,2]/sum(tab[,,2]) )|> round(2))
  MDFS_1D[[ variant_used ]]$statistic-> stat_1D
  MDFS_2D[[ variant_used ]]$statistic-> stat_2D
  names(stat_1D)<-names(stat_2D)<-colnames(taxa_binary[[variant_used]])
  print(sprintf("IG increase of rel_taxa=%.3f, min IG1D=%.3f", 
                stat_2D[[ best_pair$rel_name ]] - stat_1D[[ best_pair$rel_name ]],
                min(stat_1D[ MDFS_1D[[variant_used]]$relevant.variables  ])
                ) )
  
}

```

#### Interactions of 2D only taxa

```{r}
for (cohort in names(taxa)){
  
  partners[ grep(cohort,names(partners)) ]-> sublist
  MDFS_2D_rel[ names(sublist)  ] -> rel_2D_sublist
  MDFS_1D_rel[ names(sublist)  ] -> rel_1D_sublist
  mapply(function(taxa_names1,taxa_names2) 
          setdiff(taxa_names2, taxa_names1),rel_1D_sublist, rel_2D_sublist, SIMPLIFY = FALSE)-> only_2D_taxa
  if (length(unlist(only_2D_taxa))){
  df.2D<- do.call(rbind,mapply( function(df,name_subset, variant_name)
            cbind(df[df$rel_name %in% name_subset,], variant=rep(variant_name, 
                                                                 sum(df$rel_name %in% name_subset) )),
             sublist,only_2D_taxa, names(sublist)
             ,SIMPLIFY=FALSE))
  rownames(df.2D)<-NULL
  
  df.2D$rel_IG_increase= sapply(1:nrow(df.2D), function(i)
    MDFS_2D[[ df.2D$variant[[i]] ]]$statistic [ colnames(taxa_binary[[ df.2D$variant[[i]] ]])== df.2D$rel_name[[i]] ] - MDFS_1D[[ df.2D$variant[[i]] ]]$statistic [ colnames(taxa_binary[[ df.2D$variant[[i]] ]])== df.2D$rel_name[[i]] ])
for (i in 1:nrow(df.2D)){
    taxa_binary[[ df.2D$variant[[i]] ]]-> tb
    tab<-table(tb[, df.2D$rel_name[[i]] ],  tb[, df.2D$partner_name[[i]] ], decision[[cohort]])
    print(df.2D$variant[[i]] )
    print(table(decision[[cohort]]))
    print(sprintf("rel_taxa: %s, partner: %s", df.2D$rel_name[[i]], df.2D$partner_name[[i]]))
    print((tab[,,1]/sum(tab[,,1]) )|> round(2))
   print((tab[,,2]/sum(tab[,,2]) )|> round(2))
    print(sprintf("IG increase of rel_taxa=%.3f, min IG1D=%.3f", 
              df.2D$rel_IG_increase[[i]],
              min(MDFS_1D[[ df.2D$variant[[i]] ]]$statistic[ MDFS_1D[[ df.2D$variant[[i]] ]]$relevant.variables  ]  )
             ) )
}
  } else { print(sprintf("no only 2D taxa found for %s", cohort ))}
  
}

```

### Test RF run

```{r}

library(pROC)
library(randomForest)
set.seed(234)
for (cohort in names(decision)){
  randomForest(x = taxa[[cohort]][, MDFS_1D_rel[[cohort]]  ], y = as.factor(decision[[cohort]]),
               importance = TRUE)-> RF_1D
  randomForest(x = taxa[[cohort]][, union(MDFS_2D_rel[[cohort]],
                                          MDFS_1D_rel[[cohort]]) ], 
               y = as.factor(decision[[cohort]]),
               importance = TRUE)-> RF_2D
   randomForest(x = taxa[[cohort]][, U_test[[cohort]]$rel_set  ], y = as.factor(decision[[cohort]]),
               importance = TRUE)-> RF_U
  AUC_1D<- auc( response= decision[[cohort]],
                 predictor= RF_1D$votes[,2], quiet=TRUE )
  AUC_2D<- auc( response= decision[[cohort]],
                 predictor= RF_2D$votes[,2], quiet=TRUE )
  AUC_U<- auc( response= decision[[cohort]],
               predictor= RF_U$votes[,2], quiet=TRUE )
  print(cohort)
  print("OOB AUC: U_test, MDFS_1D, MDFS_1 or 2D")
  print(AUC_U)
  print(AUC_1D)
  print(AUC_2D)

}

```
#### Bootstrap resampling validation

```{r}

set.seed(234)

lapply(taxa, function(taxa_cohort)
          sample(1:nrow(taxa_cohort), nrow(taxa_cohort),replace=TRUE )
  )-> B_idx

```

```{r}

MDFS_FS<- function(X, y, mc=30){
   attributes(y)<-NULL
   binarize_taxa(X,binarize_on_median = TRUE)|> filter_sparse_cols(thr=mc) -> Xm
   
   binarize_taxa(X,binarize_on_median = FALSE)|> filter_sparse_cols(thr=mc) -> X0
   to_keep<- c("statistic","p.value","adjusted.p.value","relevant.variables")
   MDFS.discrete(data=Xm,decision = y,dimensions = 1,
                      p.adjust.method = "holm",level=0.05,seed=123)[to_keep]-> res_1Dm
   MDFS.discrete(data=Xm,decision = y,dimensions = 2,
                      p.adjust.method = "holm",level=0.05,seed=123)[to_keep]-> res_2Dm
   MDFS.discrete(data=X0,decision = y,dimensions = 1,
                      p.adjust.method = "holm",level=0.05,seed=123)[to_keep]-> res_1D0
   MDFS.discrete(data=X0,decision = y,dimensions = 2,
                      p.adjust.method = "holm",level=0.05,seed=123)[to_keep]-> res_2D0
  
   res_1Dm$rel_set= colnames(Xm)[res_1Dm$relevant.variables]
   res_2Dm$rel_set= colnames(Xm)[res_2Dm$relevant.variables]
   res_1D0$rel_set= colnames(X0)[res_1D0$relevant.variables]
   res_2D0$rel_set= colnames(X0)[res_2D0$relevant.variables]
   
   RESULT<-list(
     res_1Dm=res_1Dm,
     res_2Dm=res_2Dm,
     res_1D0=res_1D0,
     res_2D0=res_2D0
   )
   
}

```


```{r}
res_mdfs_base<-list()
res_u_base<-list()
for (cohort in names(taxa)){
  MDFS_FS(taxa[[cohort]], y = decision[[cohort]], mc = 30)-> res_mdfs_base[[cohort]]
    U_test_FS(data=taxa[[cohort]], decision = decision[[cohort]])-> res_u_base[[cohort]]
  }

```



```{r}
ntry=20
mdfs<-list()
ut<-list()
for (j in 1:ntry){

lapply(taxa, function(taxa_cohort)
          sample(1:nrow(taxa_cohort), nrow(taxa_cohort),replace=TRUE )
  )-> B_idx

  for (cohort in names(taxa)){
  MDFS_FS(taxa[[cohort]][B_idx[[cohort]], ], y = decision[[cohort]][B_idx[[cohort]] ], mc = 30)-> res_mdfs
    U_test_FS(data=taxa[[cohort]][B_idx[[cohort]], ], decision = decision[[cohort]][B_idx[[cohort]] ])-> res_u
    mdfs[[cohort]][[j]]<-res_mdfs
  ut[[cohort]][[j]]<-res_u
  }
  
  

message(j)

}

```

```{r, fig.width=7,fig.height=7}
par(mfrow=c(2,2))
lapply(names(res_mdfs_base), function(coh){
  
  res_mdfs_base[[coh]]-> mdfs_res
  res_u_base[[coh]]-> u_res
  lapply(names(mdfs_res), function(mdv){
    
    print(sprintf("%s, mdfs: %s, original data n_rel=%d",coh,
                  substr(mdv,5,8), length(mdfs_res[[mdv]]$rel_set)  ))
    length(mdfs_res[[mdv]]$rel_set)-> n_orig
    print("n_rel variability on bootstrap resampled data: ")
    sapply(mdfs[[coh]], function(x) x[[mdv]]$rel_set |> length())-> n_bs
    print(summary(n_bs))
    list(variant= substr(mdv,5,8),
         n_orig=n_orig,
         n_bs=n_bs
         )
  })-> results_varaiants_mdfs
  u_t_Results<- list(variant="u_test",
  n_orig=u_res$rel_set |> length(),
  n_bs= sapply(ut[[coh]], function(x) x$rel_set |> length()  ) )
  fs_list<-c( list(u_t_Results), results_varaiants_mdfs)
  do.call( cbind,
    #c(list(u_t_Results$n_bs),
    #lapply(results_varaiants_mdfs, 
    #       function(x) x$n_bs
    #       ))
    lapply(fs_list, function(x) x$n_bs )
    )-> n_bs_method
  colnames(n_bs_method)<- sapply(fs_list, function(x) x$variant)
  boxplot(n_bs_method,main=coh, ylim=c(-20,130))
  points( 1:5, sapply(fs_list, function(x) x$n_orig ), pch=4, cex=3, col="red" )
  text(1:5, sapply(fs_list, function(x) x$n_orig )-15, labels=sapply(fs_list, function(x) x$n_orig),
                                                                    col='red' )
  invisible()
  
})

```


### Integrate two types of information and prepare data for base resampling procedure


```{r}
common_names<- intersect(rownames(metadata), rownames(tdata))
tdata<- tdata[common_names,]
metadata<-metadata[common_names,]
print("# of samples left after filtering by alpha diversity (with repeating donors)")
print(length(common_names))
print("# of unique donors")
print(length(unique(metadata$host.subject.id)))
```

## Median dataset and cohort summary


```{r}
y<- 1- metadata$allergic.to.i.have.no.food.allergies.that.i.know.of 
names(y)<- rownames(metadata)
library(matrixStats)

ids<-metadata$host.subject.id
names(ids)<-rownames(metadata)

donors<-unique(ids)

taxonomy.mean<-matrix(NA,length(donors),ncol(tdata))
rownames(taxonomy.mean)<-donors
colnames(taxonomy.mean)<-colnames(tdata)
meta.mean<-as.data.frame(matrix(NA,length(donors),6))
rownames(meta.mean)<-donors
colnames(meta.mean)<-c('age','sex','weight.kg','height.cm','BMI_cat','age_cat')
decision.mean<-numeric(length(donors))
names(decision.mean)<-donors

if (!file.exists("mean_data.RData")){
for (i in 1:length(donors)) {
 donor<-donors[i]
 samples<-names(ids)[ids==donor]
 
 #decision
 decs<-y[samples]
 decision.mean[i]<-floor(median(decs))
 
 #taxa
 taxa<-tdata[samples,,drop=F]
 taxonomy.mean[i,]<-colMedians(as.matrix(taxa))
 
 #metadata
 #age
 ages<-metadata[samples,'age.years']
 ages<-ages[!is.na(ages)]
 if (length(ages)>0) meta.mean[i,1]<-round(median(ages))
 #sex
 sexes<-metadata[samples,'sex']
 sexes<-sexes[!is.na(sexes)]
 if (length(sexes)>0) meta.mean[i,2]<-names(table(sexes))[which.max(table(sexes))]
 #weight
 weights<-as.numeric(metadata[samples,'weight.kg'])
 weights<-weights[!is.na(weights)]
 if (length(weights)>0) meta.mean[i,3]<-median(weights)
 #height
 heights<-as.numeric(metadata[samples,'height.cm'])
 heights<-heights[!is.na(heights)]
 if (length(heights)>0) meta.mean[i,4]<-median(heights)
 
 
 if(!((i-1)%%500)) print(sprintf("median data computation... %d / %d done",i, length(donors)))
}

mask.meta<-rowSums(is.na(meta.mean[,1:4]))==0

meta.mean.final<-meta.mean[mask.meta,]
meta.mean.final[meta.mean.final[1]<15,6]<-'0-14'
meta.mean.final[meta.mean.final[1]>=15 & meta.mean.final[1]<64,6]<-'15-64'
meta.mean.final[meta.mean.final[1]>=64,6]<-'65+'
bmi<-meta.mean.final[,'weight.kg']/meta.mean.final[,'height.cm']^2*10000
meta.mean.final[bmi<18.5,5]<-'Underweight'
meta.mean.final[bmi>=18.5 & bmi<25,5]<-'Normal'
meta.mean.final[bmi>=25 & bmi<30,5]<-'Overweight'
meta.mean.final[bmi>=30,5]<-'Obese'


decision.mean.final<-decision.mean[mask.meta]
taxonomy.mean.final<-taxonomy.mean[mask.meta,]
taxonomy.mean.final<-taxonomy.mean.final[,colSums(taxonomy.mean.final>0)>20]
taxonomy.mean.final<-as.data.frame(taxonomy.mean.final/rowSums(taxonomy.mean.final)*10000)

binary.mean.final<-taxonomy.mean.final*0
for (i in 1:ncol(binary.mean.final)) binary.mean.final[,i]<-taxonomy.mean.final[,i]>median(taxonomy.mean.final[,i])

save(meta.mean.final,decision.mean.final,taxonomy.mean.final,binary.mean.final,file='mean_data.RData')
} else {load("mean_data.RData")}


#Table 1 
table(decision.mean.final)

table(meta.mean.final[decision.mean.final==0,2])
table(meta.mean.final[decision.mean.final==1,2])

fisher.test(rbind(table(meta.mean.final[decision.mean.final==0,2]),
            table(meta.mean.final[decision.mean.final==1,2])))
            

table(meta.mean.final[decision.mean.final==0,6])
table(meta.mean.final[decision.mean.final==1,6])

fisher.test(rbind(table(meta.mean.final[decision.mean.final==0,6]),
                  table(meta.mean.final[decision.mean.final==1,6])))#,simulate.p.value = T)


table(meta.mean.final[decision.mean.final==0,5])
table(meta.mean.final[decision.mean.final==1,5])

fisher.test(rbind(table(meta.mean.final[decision.mean.final==0,5]),
                  table(meta.mean.final[decision.mean.final==1,5])))



```

## Base resamples construction

Function `draw_once_per_host` does following things:

- draws one sample from each unique donor which has submitted more than one sample

- binarizes taxa by their median value, setting values bigger than median to 1

- filters out sparse taxa according to `min_minority_class_taxa`

```{r}
source("draw_once_per_host2.R")
library(matrixStats)
host_id<- metadata$host.subject.id
names(host_id)<- rownames(metadata)
base_resamples<-list()
save(y,tdata,host_id,file="clean_data_before_resampling.RData")
if (!file.exists("base_resamples.rds")){
for (i in 1:30){
  set.seed(i)
draw_once_per_host(taxonomy=tdata, disease = y, host_id = host_id,
                   min_minority_class_taxa =20, min_minority_class_dis = 30,print_summary = FALSE,
                   report_progess = FALSE)->base_resamples[[i]]
message(sprintf("%d/30 done",i))
}
saveRDS(base_resamples, "base_resamples.rds") } else {
  base_resamples<-readRDS("base_resamples.rds")
}
```


## Feature selection

Perform discrete variant of MDFS in 1D and 2D mode on each of the prepared base resamples.

```{r}
library(MDFS)
if (!file.exists("rel_MDFS_group.RData")) {
MDFS_1D<-MDFS_2D<-MDFS_1D_relnames<-MDFS_2D_relnames<-MDFS_1D2D_relnames<-list()
for (i in 1:30){current_seed=i
gc()
  set.seed(current_seed)
  # Perform MDFS with 1D
  MDFS_1D_result <- MDFS.discrete(
    data = base_resamples[[i]]$taxa_binary,
    decision = base_resamples[[i]]$disease_status,
    dimensions = 1,
    seed= current_seed,  # Set the seed for reproducibility
    level = 0.05
  )

  MDFS_1D[[i]] <- MDFS_1D_result
  MDFS_1D_relnames[[i]] <- colnames(base_resamples[[i]]$taxa_binary)[MDFS_1D_result$relevant.variables]
gc()
set.seed(current_seed)
  # Perform MDFS with 2D
  MDFS_2D_result <- MDFS.discrete(
    data = base_resamples[[i]]$taxa_binary,
    decision = base_resamples[[i]]$disease_status,
    dimensions = 2,
    seed = current_seed,
    level = 0.05
  )
  MDFS_2D[[i]] <- MDFS_2D_result
  MDFS_2D_relnames[[i]] <- colnames(base_resamples[[i]]$taxa_binary)[MDFS_2D_result$relevant.variables]

  # Combine 1D and 2D relevant variables
  MDFS_1D2D_relnames[[i]] <- union(MDFS_1D_relnames[[i]], MDFS_2D_relnames[[i]])
message(sprintf("%d/30 done",i))
}

# Combine results into lists of lists
MDFS_object_lists <- list(MDFS_1D = MDFS_1D, MDFS_2D = MDFS_2D)
relnames_lists <- list(MDFS_1D_rel = MDFS_1D_relnames, 
                       MDFS_2D_rel = MDFS_2D_relnames, 
                       MDFS_1D2D_rel = MDFS_1D2D_relnames)
# Save results
save(relnames_lists, MDFS_object_lists, 
     file = "rel_MDFS_group.RData")
} else { message("loading data");load("rel_MDFS_group.RData")}
```

## Integrate results from base resamples 

```{r}
#names rel. either in 1D or 2D in each of the trials
any_times_relevant_taxa<- Reduce(union, relnames_lists$MDFS_1D2D_rel)


```

### Estabilish robust set of relevant features from base resampling

#### Calculate frequencies of appearance as relevant

```{r}
#containers for frequencies
rel_freq<-rel_freq_1D<-rel_freq_2D<-rep(0, length(any_times_relevant_taxa))
names(rel_freq)<-names(rel_freq_1D)<-names(rel_freq_2D)<-any_times_relevant_taxa
for (i in seq_along(relnames_lists[[1]])) {
 rel_freq<- rel_freq + ( any_times_relevant_taxa %in% relnames_lists$MDFS_1D2D_rel[[i]] )*1. 
 rel_freq_1D<- rel_freq_1D + ( any_times_relevant_taxa %in% relnames_lists$MDFS_1D_rel[[i]] )*1. 
 rel_freq_2D<- rel_freq_2D + ( any_times_relevant_taxa %in% relnames_lists$MDFS_2D_rel[[i]] )*1. 
  
}
```

#### Reduce the set to taxa that appeared relevant 30 times in either 1D or 2D

```{r}
which_stay<-(rel_freq==30)
base_relevant_set<- any_times_relevant_taxa[which_stay]
rel_freq<- rel_freq[which_stay]
rel_freq_1D<-rel_freq_1D[which_stay]
rel_freq_2D<-rel_freq_2D[which_stay]
```

### Find interaction partners for each of 2D relevant taxa

Function `get_interaction_partner` finds the best partners of each variable in `dataset` determined by index in `interesting.vars`, according to the Information Gain (IG) on `decision`.
Here:

- `dataset` will be binarized taxa, 

- `decision` is disease status,

- `interesting.vars` will be variables relevant in 2D analysis,

... in each of the 30 base resamples.


```{r}

get_interaction_partner<- function(dataset, decision, interesting.vars, ...){

if (!(all(interesting.vars %in% 1:ncol(dataset))))
        stop("interesting.vars must be in 1:ncol(dataset)")

if (is.null(colnames(dataset)))
        stop("datatset should have column names (taxa names)")

best.tuples <- ComputeInterestingTuplesDiscrete(dataset,
                                        decision,
                                        interesting.vars =interesting.vars,                                         ...
                                          )
do.call(rbind,
       lapply(interesting.vars, function(V){

               V_subset<- best.tuples$Var == V
               V_which.max<- which.max( best.tuples[ V_subset,]$IG )
              m_t1<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.1"]]
              m_t2<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.2"]]
              p_IDX<- if( V== m_t1) m_t2 else m_t1
              data.frame( rel_IDX= V, partner_IDX= p_IDX, rel_name = colnames(dataset)[[V]],                                                                             partner_name= colnames(dataset)[[p_IDX]],
                 rel_IG= best.tuples[ V_subset, ][V_which.max,][["IG"]] )
              }
             )
       )
}


```


#### Apply the function on each of the base resamples:

```{r}

partners_per_run<- list()
i_set<-1
for (i_set in seq_along(base_resamples))
{
partners_per_run[[i_set]] <-
get_interaction_partner(dataset=base_resamples[[i_set]]$taxa_binary,
                         decision=base_resamples[[i_set]]$disease_status,
                     interesting.vars=MDFS_object_lists[[2]][[i_set]]$relevant.variables ,
                         dimensions=2)

}



```

Function returns data.frame of names of relevant variables (taxa), their positions in each set and the same of their partners.
We can inspect output from one run, for context. Auxiliary function shortens taxa names to the deepest available classification:

```{r}

partners_per_run[[1]]-> example_out

get_deepest_taxonomy_lvl<- function(taxa_name){
strsplit(taxa_name,"\\.")-> splitted
splitted[[1]][[ length(splitted[[1]]) ]]
}
example_out$rel_name<- unlist(lapply(example_out$rel_name, get_deepest_taxonomy_lvl))
example_out$partner_name<- unlist(lapply(example_out$partner_name, get_deepest_taxonomy_lvl))

example_out[order(example_out$rel_IG, decreasing=TRUE),] %>% head

```

#### Aggregate the results from all resamples

We calculate mean IG for each synergistic pair over all base resamples it appears in.

Then, for each relevant variable in 2D, we take its "definitive" partner as the one that had maximum mean IG over all base resamples.

```{r}
#mean IG
do.call(rbind, partners_per_run)-> partners_all_runs #all runs together
#aggregate(partners_all_runs$rel_IG, #value to aggregate
#          list(rel=partners_all_runs$rel_name,       #factors over which to group
#              partner=partners_all_runs$partner_name),
#          mean #how to aggregate
#          )-> partner_IG_tabulation

data.frame(rel= partners_all_runs$rel_name, 
           partner=partners_all_runs$partner_name,
       pair=interaction(partners_all_runs$rel_name, partners_all_runs$partner_name) |> as.character(),
       IG=partners_all_runs$rel_IG)-> partner_IG_tabulation




do.call(rbind,lapply(base_relevant_set[rel_freq_2D==30], function(taxon)
{
        taxon_subset<- partner_IG_tabulation$rel == taxon
        if (any(taxon_subset))
        {
              #print(sum(taxon_subset))
                taxon_partners<-partner_IG_tabulation[ taxon_subset, ,drop=FALSE]
                pairCounts<-table(taxon_partners$pair)
                pairCounts<- pairCounts[ order(pairCounts, decreasing = TRUE) ]
                partners_names_only<- partner_IG_tabulation[,-ncol(partner_IG_tabulation)]
                partners_names_only<- partners_names_only[!duplicated(partners_names_only),]
                partners_names_only$partner[ partners_names_only$pair == names(pairCounts)[[1]] ] -> most_freq
                #print(sprintf("relevant taxon name= %s", get_deepest_taxonomy_lvl(taxon ) ))
                #print (sprintf("frequency of %s =  %d ", get_deepest_taxonomy_lvl(most_freq),  pairCounts[[1]]))
                result<- data.frame(rel=taxon,partner=most_freq, freq=pairCounts[[1]])
                if (pairCounts[[1]]>15) { result<-result } else { result<- result}
                  #result<- "tie" }
                #taxon_partners$partner[[ which.max(taxon_partners$IG) ]]
                 result
        } else NA

}       )) -> rel2D_partner_freq_df
  
  best_partners_baseRelSet<-rel2D_partner_freq_df$partner

names(best_partners_baseRelSet)<- base_relevant_set[rel_freq_2D==30]

viz_rel2<- rel2D_partner_freq_df
for (j in 1:2) viz_rel2[,j]<- sapply(viz_rel2[,j], get_deepest_taxonomy_lvl)

```


#### Use mean IG to estabilish true synergies

We calculate mean IG of all selected taxa so far (relevant 30 times in 1D or 2D + best partners for 2D relevant ones) to estabilish criteria for synergy:

- if the increase of IG in 2D of the 2D relevant variable is bigger than the minimal IG in 1D analysis. 


```{r}
#truly relevant (30 times in 1D or 3D) + partners
union(base_relevant_set, unname(best_partners_baseRelSet))-> overall_rel_list
  
#ugly, but necessary check:
##ensure that all resamples contain all taxa in overall_rel_list
stopifnot(
 lapply(base_resamples, function(x) 
   all(overall_rel_list %in% colnames(x$taxa_binary)) 
   ) |> unlist()  |> all() 
)


```

```{r}

mean_IG_overRuns<- function(MDFS_objects, taxa_subset, taxa_names_in_resamples){
  do.call( rbind, mapply( function(mdfs,taxa_names) 
                            mdfs$statistic[ match(taxa_subset,taxa_names) ],
                          MDFS_objects, taxa_names_in_resamples, SIMPLIFY = FALSE
                          )
          ) |> colMeans()
}

base_resamples_present_taxa<- lapply(base_resamples, function(x)
                                      colnames(x$taxa_binary))

overall_rel_IG1D<- mean_IG_overRuns(MDFS_object_lists[[1]],
                                    overall_rel_list,
                                    base_resamples_present_taxa
                                    )
overall_rel_IG2D<- mean_IG_overRuns(MDFS_object_lists[[2]],
                                    overall_rel_list,
                                    base_resamples_present_taxa
                                    )
names(overall_rel_IG1D)<-names(overall_rel_IG2D)<-overall_rel_list
```

```{r}
# union(base_relevant_set, unname(best_partners_baseRelSet))-> overall_rel_list
# 
# #containers of mean IG
# overall_rel_IG1D<- rep(0, length(overall_rel_list))
# overall_rel_IG2D<- rep(0, length(overall_rel_list))
# names(overall_rel_IG1D)<-names(overall_rel_IG2D)<-overall_rel_list
# rel_1D_names<- names(rel_freq[rel_freq_1D==30])
# rel_2D_names<- names(rel_freq[rel_freq_2D==30])
# 
# get_IG_from_rel_names<- function(taxa_statistic, taxa_names,
#                           rel_subset_names){
#   names(taxa_statistic)<- taxa_names
#   taxa_statistic[rel_subset_names]
# }
# 
# 
# 
# for (i in seq_along(MDFS_object_lists[[1]])){
#   #taxa present in run "i"
#   resample_present_taxa<-colnames(base_resamples[[i]]$taxa_binary)
#   #found relevant in "i" and relevant 30 times overall
#   intersect(resample_present_taxa, relnames_lists[[1]][[i]]) -> rel1Dtaxa_thisRun
#   intersect(rel1Dtaxa_thisRun, rel_1D_names)-> rel1Dtaxa_thisRun
#   intersect(resample_present_taxa, relnames_lists[[2]][[i]]) -> rel2Dtaxa_thisRun
#   intersect(rel2Dtaxa_thisRun, rel_2D_names)-> rel2Dtaxa_thisRun
#   #their position in run "i"
#   match( rel1Dtaxa_thisRun, resample_present_taxa)-> rel_1D_idx
#   match( rel2Dtaxa_thisRun, resample_present_taxa)-> rel_2D_idx
#   #their IG 
#    MDFS_object_lists[[1]][[i]]$statistic[ rel_1D_idx ] -> IG_1D_resample
#    MDFS_object_lists[[2]][[i]]$statistic[ rel_2D_idx ] -> IG_2D_resample
#    stopifnot(all(rel1Dtaxa_thisRun %in% names(overall_rel_IG1D))) 
#    stopifnot(all(rel2Dtaxa_thisRun %in% names(overall_rel_IG2D))) 
#    #increase sums only for relevant variables from that run
#    overall_rel_IG1D[ rel1Dtaxa_thisRun ] = overall_rel_IG1D[ rel1Dtaxa_thisRun ] + IG_1D_resample
#    overall_rel_IG2D[ rel2Dtaxa_thisRun ] = overall_rel_IG2D[ rel2Dtaxa_thisRun ] + IG_2D_resample
# }
# #divide overall_rel_IG by the times each variable was found relevant
# times_rel_overall<- rep(1, length(overall_rel_list))
# names(times_rel_overall)<-overall_rel_list
# times_rel_overall[ names(rel_freq) ] = rel_freq
# overall_rel_IG1D<- overall_rel_IG1D/times_rel_overall
# overall_rel_IG2D<- overall_rel_IG2D/times_rel_overall
# 
# #overall_rel_IG1D[ !(overall_rel_list %in% names(rel_freq_1D)[rel_freq_1D==30]) ] =0
# #overall_rel_IG2D[ !(overall_rel_list %in% names(rel_freq_2D)[rel_freq_2D==30]) ] =0
```

```{r}
data.frame( name=overall_rel_list,
            IG1D=overall_rel_IG1D, IG2D= overall_rel_IG2D)-> ig_df
ig_df$rel_1D<- rel_freq_1D[ ig_df$name ]
ig_df$rel_2D<- rel_freq_2D[ ig_df$name ]
ig_df$rel_1D[ is.na(ig_df$rel_1D) ] = 0
ig_df$rel_2D[ is.na(ig_df$rel_2D) ] = 0
ig_df$partner_name<- best_partners_baseRelSet[ ig_df$name ]
ig_df$partner_only<- ig_df$name %in% setdiff(best_partners_baseRelSet, base_relevant_set)
synergy_thr<- min(ig_df$IG1D[ig_df$rel_1D==30])
print("minimal increase of IG in 2D analysis for estabilishing synergy:")
print(synergy_thr)
IG_increase= ig_df$IG2D - ig_df$IG1D
# find the true synergies using the thredhold and IG_increase of primary 2D rel. variable:
true_synergistic_partners<-vector(mode="character")
for (partner_only in ig_df$name[ig_df$partner_only])
{
  if (max(IG_increase[which(ig_df$partner_name== partner_only) ]) > synergy_thr)
    true_synergistic_partners[[ length(true_synergistic_partners)+1 ]] = partner_only
}

#for the rest of the analysis:
# keep taxa that were relevant 30 times in 2D or 1D and true synergistic partners.
taxa_to_keep_mask<- (ig_df$name %in% true_synergistic_partners) | 
                      (ig_df$rel_1D==30 ) | 
                      (ig_df$rel_2D==30)
ig_df<- ig_df[ taxa_to_keep_mask,]
ig_df<- ig_df[ order(-ig_df$IG2D),]
```

## Interaction plots

Based on median dataset and results of above computations, we show plots of abundance of Bergeyella vs abundance of Neisseria.

Due to zero inflation, to make the "absence" state more visble, plot visualizes zeroes (samples where one of the bacteria is absent) as values evenly distributed on a small interval around 0 (signified by grey bands).

```{r}

last.name<-function(x,sep='\\.',n=1) {
 return(unlist(lapply(strsplit(x,sep),FUN=function(x) tail(x,n))))
}

decision<-decision.mean.final

taxa_pairlist<- list(c(
'sk__Bacteria.k__.p__Bacteroidetes.c__Flavobacteriia.o__Flavobacteriales.f__Flavobacteriaceae.g__Bergeyella',
'sk__Bacteria.k__.p__Proteobacteria.c__Betaproteobacteria.o__Neisseriales.f__Neisseriaceae.g__Neisseria'
),
c('sk__Bacteria.k__.p__Bacteroidetes.c__Flavobacteriia.o__Flavobacteriales.f__Flavobacteriaceae.g__Bergeyella',
  'sk__Bacteria.k__.p__Proteobacteria.c__Betaproteobacteria.o__Neisseriales.f__Neisseriaceae'
),
ig_df[grep( "g__Pseudomonas", ig_df$name),c("name","partner_name")] |> unlist() |> unname()
)

for (tp in taxa_pairlist) {
  taxon1=tp[1]
  taxon2=tp[2]

 X1<-taxonomy.mean.final[,taxon1]
 short1<-last.name(taxon1)

 X2<-taxonomy.mean.final[,taxon2]
 short2<-last.name(taxon2)

 min1<-min(X1[X1>0])
 max1<-max(X1)
 min2<-min(X2[X2>0])
 max2<-max(X2)

 min1r<-10^floor(log10(min1))
 max1r<-10^ceiling(log10(max1))
 min2r<-10^floor(log10(min2))
 max2r<-10^ceiling(log10(max2))
 tx1<-10^(log10(min1r):log10(max1r))
 tx2<-10^(log10(min2r):log10(max2r))

 add1<-min(X1[X1>0])/2
 add2<-min(X2[X2>0])/2

 add1m<-add1/sqrt(10)
 add2m<-add2/sqrt(10)

 prop000<-sum(X1==0 & X2==0 & decision==0)/sum(X1==0 & X2==0)
 prop001<-sum(X1==0 & X2==0 & decision==1)/sum(X1==0 & X2==0)
 prop010<-sum(X1==0 & X2>0 & decision==0)/sum(X1==0 & X2>0)
 prop011<-sum(X1==0 & X2>0 & decision==1)/sum(X1==0 & X2>0)
 prop100<-sum(X1>0 & X2==0 & decision==0)/sum(X1>0 & X2==0)
 prop101<-sum(X1>0 & X2==0 & decision==1)/sum(X1>0 & X2==0)
 prop110<-sum(X1>0 & X2>0 & decision==0)/sum(X1>0 & X2>0)
prop111<-sum(X1>0 & X2>0 & decision==1)/sum(X1>0 & X2>0)
 
 x1<-X1
 x2<-X2
 x1[X1==0]<-x1[X1==0]+exp(log(add1/9)+(log(add1)-log(add1/9))*runif(length(X1[X1==0]))^(2*(!decision[X1==0])+0.5*decision[X1==0]))
 x2[X2==0]<-x2[X2==0]+exp(log(add2/9)+(log(add2)-log(add2/9))*runif(length(X2[X2==0]))^(2*(!decision[X2==0])+0.5*decision[X2==0]))
 x1[X1>0]<-x1[X1>0]+exp(runif(length(X1[X1>0]),log(add1/9),log(add1)))
 x2[X2>0]<-x2[X2>0]+exp(runif(length(X2[X2>0]),log(add2/9),log(add2)))


 bg.h<-'cyan3'
 bg.d<-'red'
 tx.h<-'black'
 tx.d<-'black'
 par(mar=c(5,5,1,1))
 plot(x1,x2,col=1+decision,type='n',log='xy',cex=1,cex.lab=1.5,
      xlim=c(add1/20,max1r),ylim=c(add2/20,max2r*2),
      xlab=short1,ylab=short2,axes=F)
 axis(1,at=c(0,tx1)+add1m,labels = c(0,tx1),cex.axis=1)
 axis(2,at=c(0,tx2)+add2m,labels = c(0,tx2),cex.axis=1)
 rect(add1/9,add2/9,add1,max2r,col='lightgray',border=NA)
 rect(add1/9,add2/9,max1r,add2,col='lightgray',border=NA)

 rect(add1,add2/25,max1r,add2/10,col=bg.d,border=NA)
 rect(add1,add2/25,max1r^prop100*add1^prop101,add2/10,col=bg.h,border=NA)
 text(sqrt(add1*max1r^prop100*add1^prop101),add2/10/sqrt(2.5),sum(X1>0 & X2==0 & decision==0),col=tx.h,cex=1)
 text(sqrt(max1r*max1r^prop100*add1^prop101),add2/10/sqrt(2.5),sum(X1>0 & X2==0 & decision==1),col=tx.d,cex=1)

 rect(add1/10,add2/25,add1,add2/10,col=bg.d,border=NA)
 rect(add1/10,add2/25,add1^prop000*(add1/10)^(prop001),add2/10,col=bg.h,border=NA)
 text(sqrt(add1/10*add1^prop000*(add1/10)^prop001),add2/10/sqrt(2.5),sum(X1==0 & X2==0 & decision==0),col=tx.h,cex=1)
 text(sqrt(add1*add1^prop000*(add1/10)^prop001),add2/10/sqrt(2.5),sum(X1==0 & X2==0 & decision==1),col=tx.d,cex=1)

 rect(add1/25,add2,add1/10,max2r,col=bg.d,border=NA)
 rect(add1/25,add2,add1/10,max2r^prop010*add2^prop011,col=bg.h,border=NA)
 text(add1/10/sqrt(2.5),sqrt(add2*add2^prop011*max2r^prop010),sum(X1==0 & X2>0 & decision==0),col=tx.h,cex=1,srt=90)
 text(add1/10/sqrt(2.5),sqrt(max2r*add2^prop011*max2r^prop010),sum(X1==0 & X2>0 & decision==1),col=tx.d,cex=1,srt=90)

 rect(add1,max2r,max1r,max2r*2.5,col=bg.d,border=NA)
 rect(add1,max2r,max1r^prop110*add1^prop111,max2r*2.5,col=bg.h,border=NA)
 text(sqrt(add1*max1r^prop110*add1^prop111),max2r*sqrt(2.5),sum(X1>0 & X2>0 & decision==0),col=tx.h,cex=1)
 text(sqrt(max1r*max1r^prop110*add1^prop111),max2r*sqrt(2.5),sum(X1>0 & X2>0 & decision==1),col=tx.d,cex=1)

 points(x1,x2,col=c(bg.h,bg.d)[1+decision],pch=19,cex=0.66)
 
  OR_01<-(sum(X1>0 & X2==0 & decision==1)/sum(X1>0 & X2==0 & decision==0))/
  (sum(!(X1>0 & X2==0) & decision==1)/sum(!(X1>0 & X2==0) & decision==0))

 print(paste('Odds ratio for',short1,'and',short2,OR_01))
}

```


## mean presence and abundance of selected taxons across 30 trials

```{r}
summary_df<- ig_df
summary_df$name-> interesting_taxa
#ensure all base_resamples have same number of rows 
stopifnot( all(
        (lapply(base_resamples, function(x) nrow(x$taxa_abundance)) %>%
            unlist() )== nrow(base_resamples[[1]]$taxa_abundance) 
              )
         )

#common basis for all interesting taxa
# (containers for sums)
A_h<-A_d<-P_h<-P_d<-P<-A<- rep(0, length(interesting_taxa))
names(P)<-names(A)<-interesting_taxa
names(P_d)<-names(A_d)<-interesting_taxa
names(P_h)<-names(A_h)<-interesting_taxa

#sum means over resamples
for (i in seq_along(base_resamples)){
    
    intr_present_resample<- intersect(interesting_taxa,
                                colnames(base_resamples[[i]]$taxa_abundance)
                                    )

    P_rsmp<-base_resamples[[i]]$taxa_binary[, intr_present_resample]
    A_rsmp<-base_resamples[[i]]$taxa_abundance[, intr_present_resample]
    y_rsmp<-base_resamples[[i]]$disease_status

    P[ intr_present_resample ] =  P[ intr_present_resample ] +
            colMeans(P_rsmp)
    A[ intr_present_resample ] =  A[ intr_present_resample ] +
            colMeans(A_rsmp)

    P_d[ intr_present_resample ] =  P_d[ intr_present_resample ] +
            colMeans(P_rsmp[y_rsmp==1,])
    A_d[ intr_present_resample ] =  A_d[ intr_present_resample ] +
            colMeans(A_rsmp[y_rsmp==1,])

    P_h[ intr_present_resample ] =  P_h[ intr_present_resample ] +
            colMeans(P_rsmp[y_rsmp==0,])
    A_h[ intr_present_resample ] =  A_h[ intr_present_resample ] +
            colMeans(A_rsmp[y_rsmp==0,])
}
#.. and divide by 30
P<-P/30
A<-A/30
P_h<-P_h/30
A_h<-A_h/30
P_d<-P_d/30
A_d<-A_d/30
summary_df$freq= P
summary_df$ab= A
summary_df$freq_d= P_d
summary_df$ab_d= A_d
summary_df$freq_h= P_h
summary_df$ab_h= A_h
viz_ig_df<- summary_df
viz_ig_df$name<- unlist(lapply(viz_ig_df$name, get_deepest_taxonomy_lvl))
viz_ig_df$partner_name<- unlist(lapply(viz_ig_df$partner_name, get_deepest_taxonomy_lvl))
rownames(viz_ig_df)<- 1:nrow(viz_ig_df)
viz_ig_df[,c(2:3) ]<-round(viz_ig_df[,c(2:3)])
viz_ig_df[,c("ab_h","ab_d","ab")]=viz_ig_df[,c("ab_h","ab_d","ab")]*10000
viz_ig_df[,8:13]=round(viz_ig_df[,8:13],2)
viz_ig_df$name[[ which(
viz_ig_df$name=="s__gamma_proteobacterium_symbiont_of_Gonopsis_affinis"
)
]]="s_gp_symb_Gon_aff"
#viz_ig_df$partner_name[[ which(
#  viz_ig_df$partner_name=="s__Mediterranea_massiliensis")
#]]="s_Med_massiliensis"
```
## Browse end result

#### feature selection stats:

```{r}
viz_ig_df[,c("name","IG1D","IG2D","rel_1D","rel_2D","partner_name")]


```

#### mean abundance & frequency
```{r}
viz_ig_df[,c("name","freq_h","freq_d","freq",
             "ab_h","ab_d","ab")]


```


# Bootstrap resampling validation

Following initial selection of robust features relevant both in 1D and 2D, we validated the results by the use of bootstrap resampling on base resamples themselves.

From each base resample, we have drawn a boostrap resample and performed feature selection again and counted number of times selected features reappeared again as relevant.
Additionally, to test the usability of detected two dimensional interactions, we measured the average gain of AUC from random forest classifier, trained using only 1D relevant variables vs on the whole set of 1D and 2D relevant features.



## Preparation of bootstrap samples (by sampling indexes)

```{r}
N_TRIALS=30
keep_frac<-1

n1<-  sum(base_resamples[[1]]$disease_status==1)
n0<-  sum(base_resamples[[1]]$disease_status==0)

n1k<- ceiling(n1*keep_frac)
n0k<- ceiling(n0*keep_frac)

#list of 30
set.seed(32523)
B_idx<- lapply(1:N_TRIALS,
                       function(B)
                       {
                         y<-base_resamples[[B]]$disease_status
                         
                         idx_1= which(y==1)
                         idx_0= which(y==0)
                         c( sample(idx_1, n1k, replace=TRUE),
                        sample(idx_0, n0k, replace=TRUE)
                         )
                       }
                      )
#saveRDS(B_idx,"Bootstrap_IDX.rds")

```

## Feature selection and RF

We save results of each run in subdirectories `MDFS_results`, `RF_models` and calculate mean metrics after all computation is done.

```{r}
library(randomForest)
library(pROC)
#prepare list of seeds per each bootstrap for reproducibility
set.seed(32432)
session_seeds<- sample.int(323423,N_TRIALS)
    summary_df$name[summary_df$rel_1D==30] -> consensus_1D
    summary_df$name -> consensus_AllRelevant
for (B in 1:N_TRIALS) {
    IDX_B<-  B_idx[[B]]
    set_B<- base_resamples[[B]]
    set.seed(session_seeds[[B]])
#FS
   if (!file.exists( sprintf("MDFS_results/MDFS_replicate_%d.rds", B ) ) ) {
     gc()
    MDFS_1D<- MDFS.discrete(
    data = set_B$taxa_binary[IDX_B,],
    decision = set_B$disease_status[IDX_B],
    dimensions = 1,
    seed= session_seeds[[B]], 
    level = 0.05
    )
    rel_1D<- colnames(set_B$taxa_binary)[MDFS_1D$relevant.variables]
    # Perform MDFS with 2D
    gc()
    MDFS_2D<- MDFS.discrete(
    data = set_B$taxa_binary[IDX_B,],
    decision = set_B$disease_status[IDX_B],
    dimensions = 2,
    seed = session_seeds[[B]],
    level = 0.05
    )
    rel_2D<- colnames(set_B$taxa_binary)[MDFS_2D$relevant.variables]
    rel_1or2D<-  union( rel_1D, rel_2D)  
    FS<- list(rel_1D= rel_1D,
            rel_2D= rel_2D,
            rel_1or2D=rel_1or2D)
    saveRDS( FS, sprintf("MDFS_results/FS_replicate_%d.rds", B ) )
    saveRDS( list(MDFS_1D=MDFS_1D,
                MDFS_2D=MDFS_2D),
            sprintf("MDFS_results/MDFS_replicate_%d.rds", B ) )
	}
            

    #RF
	if ( ! file.exists( sprintf("RF_models/RF_replicate_%d.rds",B)) ) {
    unique(IDX_B)-> uqIDX_B
	  gc()
    set.seed(session_seeds[[B]])
    randomForest(x = set_B$taxa_binary[uqIDX_B, consensus_1D],
                y =  as.factor(set_B$disease_status[uqIDX_B]),
                importance = TRUE,
                keep.forest = TRUE)-> RF_1D
    gc()
    set.seed(session_seeds[[B]])
    randomForest(x = set_B$taxa_binary[uqIDX_B, consensus_AllRelevant],
                y =  as.factor(set_B$disease_status[uqIDX_B]),
                importance = TRUE,
                keep.forest = TRUE)-> RF_all
    saveRDS(list(RF_1D=RF_1D,
                RF_all=RF_all),
            sprintf("RF_models/RF_replicate_%d.rds", B)
    )
	}
    message(sprintf("%d/%d done", B, N_TRIALS))
}
```

### Aggregation of results

#### Count how many times relevant features showed up again and compute mean random forest metrics
```{r}
library(pROC)
source("balanced_decision.R")
#filename patterns for reading the results
fs_fpattern<-"MDFS_results/FS_replicate_%d.rds"
mdfs_fpattern<-"MDFS_results/MDFS_replicate_%d.rds"
rf_fpattern<- "RF_models/RF_replicate_%d.rds" 

#containers:
rel_2D_trials<-rel_1D_trials<- list()  #for indicators of relevance per each run
CM1_trials<-CMall_trials<-  list() #for confusion matrices
RF1_trials<- RFall_trials<-list() #for RF performance metrics

#auxiliary oods ratio computation
odds_ratio<- function(CM) {(CM[2,2]*CM[1,1])/(CM[1,2]*CM[2,1]) } 

for (B in 1:N_TRIALS){

B_tnames<-colnames(base_resamples[[B]]$taxa_abundance)
B_P<- base_resamples[[B]]$taxa_binary #presence
B_A<- base_resamples[[B]]$taxa_abundance #presence
B_y<- base_resamples[[B]]$disease_status


#indexes of resampled and oob subjects
B_IDX<- B_idx[[B]]
B_oob<- setdiff( 1:nrow(B_A), unique(B_IDX))

B_fs_fname<- sprintf( fs_fpattern, B)
B_FS<- readRDS( B_fs_fname)

#relevance indicators
rel_1D_trials[[B]]= 1.*(consensus_AllRelevant %in% B_FS$rel_1D)
rel_2D_trials[[B]]= 1.*(consensus_AllRelevant %in% B_FS$rel_2D)

#RF prediction on OOB

B_fs_fname<- sprintf( fs_fpattern, B)
B_rf_fname<- sprintf( rf_fpattern, B)
B_RF<- readRDS(B_rf_fname)$RF_all
B_RF1<- readRDS(B_rf_fname)$RF_1D


#predicted probabilities
B_RFall_prob<- predict( B_RF, newdata= B_P[B_oob,], type="prob")[,2]
B_RF1_prob<- predict( B_RF1, newdata= B_P[B_oob,], type="prob")[,2]


B_yoob<- B_y[B_oob]

#predicted classes
B_RFall_cl<-  balanced.decision(B_RFall_prob,as.factor(B_yoob))$decision
B_RF1_cl<- balanced.decision(B_RF1_prob,as.factor(B_yoob))$decision

#confusion matrices
cm_all<- table(Predicted=B_RFall_cl,Actual=B_yoob)
cm_1<- table(Predicted=B_RF1_cl,Actual=B_yoob)

CM1_trials[[B]]<- cm_1
CMall_trials[[B]]<- cm_all


RFall_score<- c(auc= auc(response=B_yoob, predictor= B_RFall_prob,quiet=TRUE),
		OR=odds_ratio(cm_all),
		acc= sum( B_yoob == B_RFall_cl)/length(B_yoob)
)
RF1_score<- c(auc= auc(response=B_yoob, predictor= B_RF1_prob,quiet=TRUE),
	      OR=odds_ratio(cm_1),
		acc= sum( B_yoob == B_RF1_cl)/length(B_yoob)
	      )

RF1_trials[[B]]<- RF1_score
RFall_trials[[B]]<- RFall_score
message(sprintf("%d/%d done", B, N_TRIALS))

}


print("mean stats and SDs for RF on 1D:")
print(colMeans(do.call(rbind,RF1_trials)) )
print(colSds(do.call(rbind,RF1_trials)) )
print("confustuon matrix for all trials of RF on 1D:")
mean_CM_1D<- Reduce("+", CM1_trials)
print(mean_CM_1D)

print("mean stats for RF on 1,2D and partners:")
print(colMeans(do.call(rbind,RFall_trials)) )
print(colSds(do.call(rbind,RFall_trials)) )
print("confusion matrix for all trials of RF on 1, 2D and partners:")
mean_CM_all<- Reduce("+", CMall_trials)
print(mean_CM_all)

#reappearance as relevant in BS per each feature
Reduce("+", rel_1D_trials)->times_rel1D_BS
Reduce("+", rel_2D_trials)->times_rel2D_BS

names(times_rel1D_BS)<- names(times_rel2D_BS)<- consensus_AllRelevant

```

### Check the plausibility of initial feature set:

```{r}

summary_df$BS_rel1D= times_rel1D_BS[ summary_df$name ]
summary_df$BS_rel2D= times_rel2D_BS[ summary_df$name ]
viz_df<-summary_df
viz_df$name<- unlist(lapply(summary_df$name, get_deepest_taxonomy_lvl))
rownames(viz_df)<-NULL
viz_df$name[[ which(
viz_df$name=="s__gamma_proteobacterium_symbiont_of_Gonopsis_affinis"
)
]]="s_gp_symb_Gon_aff"
viz_df[, c("name","rel_1D","BS_rel1D")]
```

```{r}

viz_df[, c("name","rel_2D","BS_rel2D")]

```

# Comparison with SOTA

We ran the similar 2-phase resampling based procedure of feature selection, taking U-test as the feature selector, utilizing the same criteria in terms of level of significance and p-value adjustment (0.05 with holm method correction).

Note that we should not expect purely synergistic taxa to appear in the result of the U-test as it is purely an univariate test.
In contrast, MDFS can identify features that are not relevant for disease status by themselves.

#### Streamlined process for U-test

Sourced script contains the essential steps needed for estabilishing feature sets found in base resamples and bootstrap validation sets and can work for any feature selection method which is formulated with the same convention as below U-test example function:

- it should accept as necessary input parameters, feature table and response vector
- it should return a list with fields `p.value`, `adjusted.p.value`, `relevant.variables` and `rel_set` (names of relevant taxa) containing the result
- optional parameters `lvl`, `p.adjust.method` should control determination of relevant features from raw p-values (if the feature selection method is a statistical filter).



```{r}
source("resample_FS_procedure.R")
U_test_FS
U_test_FS(base_resamples[[1]]$taxa_abundance, decision = base_resamples[[1]]$disease_status)->xx
```

```{r}
resample_FS_procedure(List_base_resamples = base_resamples,
                      List_bootrap_indexes = B_idx, #list of bootstrap indexes 
                      FS_function = U_test_FS,
                      FS_on_binary = FALSE, #do FS on taxa_binary or taxa_abundance
                      lvl=0.05,
                      p.adjust.method = "holm"
                      )-> U_test_rel_Taxa
```

#### Compare with MDFS

##### 'base' resamples

```{r}
union(summary_df$name, U_test_rel_Taxa$feature_name)-> taxa_by_any_method
data.frame(name=taxa_by_any_method,
           `MDFS_1D`=taxa_by_any_method %in% summary_df$name[summary_df$rel_1D==30],
           `MDFS_2D`=taxa_by_any_method %in% summary_df$name[summary_df$rel_2D==30],
            `U_test`=taxa_by_any_method %in% U_test_rel_Taxa$feature_name[U_test_rel_Taxa$n_rel_base==30])-> df_base
df_base[["MDFS_2D_only"]]= df_base[["MDFS_2D"]] & (!df_base[["MDFS_1D"]])
head(df_base)
```

First, we can see that none of the features relevant in 2D only appear in univariate U_test.



```{r}
print(sum(df_base[df_base$MDFS_2D_only,"U_test"]))
head(df_base[df_base$MDFS_2D_only,])
```


Second, we can examine the intersection between MDFS 1D, 2D and U-test:

```{r}

generate_crosstab <- function(df) {
  # Create an empty matrix to store the cross tabulation
  crosstab_matrix <- matrix(0, nrow = 4, ncol = 4)
  colnames(crosstab_matrix) <-colnames(df)
  rownames(crosstab_matrix) <- colnames(df)
  
  # Iterate over all pairs of columns
  for (col1 in colnames(df)) {
    for (col2 in colnames(df)) {
      # Calculate the number of times both columns have TRUE in the same row
      count <- sum(df[[col1]] & df[[col2]], na.rm = TRUE)
      # Update the crosstab matrix
      crosstab_matrix[col1, col2] <- count
    }
  }
  crosstab_matrix
}
  
generate_crosstab(df_base[,2:ncol(df_base)])
```
```{r}

df_base[df_base$U_test & (!(df_base$MDFS_2D | df_base$MDFS_1D)), ]$name -> U_test_only_taxa

U_test_only_taxa

data.frame(names=U_test_only_taxa,
           IG1D=MDFS_object_lists[[1]][[1]]$statistic[ match(U_test_only_taxa, colnames(base_resamples[[1]]$taxa_binary)) ],
           IG2D=MDFS_object_lists[[2]][[1]]$statistic[ match(U_test_only_taxa, colnames(base_resamples[[1]]$taxa_binary)) ],
           pvU= xx$adjusted.p.value[ match(U_test_only_taxa, colnames(base_resamples[[1]]$taxa_binary),  ) ]
           )

```


##### final resampled test

```{r}
data.frame(name=taxa_by_any_method,
           `MDFS_1D`=taxa_by_any_method %in% summary_df$name[summary_df$BS_rel1D==30],
           `MDFS_2D`=taxa_by_any_method %in% summary_df$name[summary_df$BS_rel2D==30],
            `U_test`=taxa_by_any_method %in% U_test_rel_Taxa$feature_name[U_test_rel_Taxa$n_rel_bs==30])-> df_bs
df_bs[["MDFS_2D_only"]]= df_bs[["MDFS_2D"]] & (!df_bs[["MDFS_1D"]])
generate_crosstab(df_bs[,2:ncol(df_bs)])
```

```{r}
df_bs[df_bs$U_test & (!(df_bs$MDFS_2D | df_bs$MDFS_1D)), ]$name -> U_test_only_taxa_BS

U_test_only_taxa_BS


```


# Does binarization affect the result?

```{r}
source("draw_once_per_host2.R")
y<- 1- metadata$allergic.to.i.have.no.food.allergies.that.i.know.of 
names(y)<- rownames(metadata)
library(matrixStats)
host_id<- metadata$host.subject.id
names(host_id)<- rownames(metadata)
base_resamples_0bin<-list()
if (!file.exists("base_resamples_0bin.rds")){
for (i in 1:30){
  gc()
  set.seed(i)
draw_once_per_host(taxonomy=tdata, disease = y, host_id = host_id, binarize_on_median = FALSE,
                   min_minority_class_taxa =20, min_minority_class_dis = 30,print_summary = FALSE,
                   report_progess = TRUE)->base_resamples_0bin[[i]]
message(sprintf("%d/30 done",i))
}
saveRDS(base_resamples_0bin, "base_resamples_0bin.rds") } else {
  base_resamples_0bin<-readRDS("base_resamples_0bin.rds")
}

```


```{r}
#ensure that we have the same donors in two approaches
stopifnot(all(
mapply(function(r1,r2) all(r1$host_id==r2$host_id), base_resamples,
       base_resamples_0bin)
))
```

```{r}
#do all taxa pass min. minority class filter the same?
all(
mapply(function(r1,r2) all(colnames(r1$taxa_binary)==colnames(r2$taxa_binary)), base_resamples,
       base_resamples_0bin)
)
```

```{r}
#how many variables differ betwen methods
columns_equal<- function(df1,df2) mapply(function(COL1,COL2) all(COL1==COL2),df1,df2 )
do.call(rbind,mapply(function(r1,r2) c(sum(columns_equal(r1$taxa_binary,r2$taxa_binary)),
                         ncol(r1$taxa_binary)), base_resamples,base_resamples_0bin,
       SIMPLIFY=FALSE))
```

```{r}
which.cols.differ<- function(df1,df2) mapply(function(COL1,COL2) 
   !all(COL1==COL2) ,df1,df2 )
Reduce(union,mapply(function(r1,r2) colnames(r1$taxa_binary)[which.cols.differ(r1$taxa_binary,
                                                                               r2$taxa_binary)], base_resamples,base_resamples_0bin,
       SIMPLIFY=FALSE))-> common_taxa
```

```{r}
plot(unname(colSums(tdata[,common_taxa]>0)/nrow(tdata)) |> sort(),
     main="% of non zero cells for common variables")
```



## MDFS pipeline on new binarization

```{r}
source("MDFS_analysis_pipeline.R")
#TO DO: change synergistic partners to most frequent ones
base_MDFS_end2end(baseResamples = base_resamples_0bin, variant_name = "FA_0bin")-> df_0bin_base

```

```{r}
print("total numbers found (relevant + partners):")
df_0bin_base |> nrow()
summary_df |> nrow()

df_0bin_base$name[ !df_0bin_base$partner_only ] -> relevant_in0bin
summary_df$name[ !summary_df$partner_only ] -> relevant_inMEDbin
print("relevant set sizes (excluding partners):")
print("common part size:")
length(intersect(relevant_in0bin, relevant_inMEDbin))
print("found by median method, not by 0")
length(setdiff(relevant_inMEDbin, relevant_in0bin))
print("found by 0, not by median")
length(setdiff(relevant_in0bin, relevant_inMEDbin))



```

```{r}
rbind(
df_0bin_base[df_0bin_base$name %in% setdiff(relevant_in0bin, relevant_inMEDbin),c("name","IG1D","IG2D")],
summary_df[summary_df$name %in% setdiff(relevant_inMEDbin, relevant_in0bin),c("name","IG1D","IG2D") ])->temp
rownames(temp)<-NULL
temp$name<-sapply(temp$name, get_deepest_taxonomy_lvl)
temp

```

### bootstrap resampling

```{r}
source("MDFS_analysis_pipeline.R")

bootstrap_MDFS(b_idx=B_idx,baseResamples = base_resamples_0bin,seeds=session_seeds,variant_name="FA_0bin",base_allRel = df_0bin_base$name)-> bs_0bin_reldf
```

```{r}

bs_0bin_reldf$name[ (bs_0bin_reldf$BS_rel1D==30) | (bs_0bin_reldf$BS_rel2D==30) ] -> bs_confirmed_0bin
summary_df$name[ (summary_df$BS_rel1D==30) | (summary_df$BS_rel2D==30) ] -> bs_confirmed_MEDbin

length(bs_confirmed_0bin)
length(bs_confirmed_MEDbin)

length(intersect(bs_confirmed_0bin,bs_confirmed_MEDbin))

sum(bs_confirmed_0bin%in% bs_confirmed_MEDbin)

```

```{r}
rbind(
df_0bin_base[df_0bin_base$name %in% setdiff(bs_confirmed_0bin, bs_confirmed_MEDbin),c("name","IG1D","IG2D")],
summary_df[summary_df$name %in% setdiff(bs_confirmed_MEDbin, bs_confirmed_0bin),c("name","IG1D","IG2D") ])->temp
rownames(temp)<-NULL
temp$name<-sapply(temp$name, get_deepest_taxonomy_lvl)
temp
```

# MDFS 3D test

To initial 30 base resamples of either discretization method (0 or median based) we added 90 new ones, giving 120 base resamples in total.

MDFS in 3 dimensions was run on all of those sets

```{r}
base_resamples_extended<-readRDS("extended_base_resamples.rds")
base_resamples_0binextended<-readRDS("extended_base_resamples_0bin.rds")
```

```{r}

lapply(seq_along(base_resamples_extended), function(i)
{
  x<-readRDS(sprintf("MDFS_results/MDFS_3D_i=%d.rds",i))
  x$med[c("statistic","p.value","adjusted.p.value","relevant.variables")]
}
  )->MDFS_3D_med
```

```{r}

lapply(seq_along(base_resamples_extended), function(i)
{
  x<-readRDS(sprintf("MDFS_results/MDFS_3D_i=%d.rds",i))
  x$zero[c("statistic","p.value","adjusted.p.value","relevant.variables")]
}
  )->MDFS_3D_zero
```

```{r}
get_rel_taxa_names<-function(base_resampled_set, MDFS_result){
  
  colnames(base_resampled_set$taxa_binary)[ MDFS_result$relevant.variables ]
  
}


```
```{r}

mapply(get_rel_taxa_names, base_resamples_extended, MDFS_3D_med )-> rel_taxa_3D_med
mapply(get_rel_taxa_names, base_resamples_0binextended, MDFS_3D_zero )-> rel_taxa_3D_zero

```

```{r}
selection_frequency<- function(names_list){
  all_names<- Reduce(union, names_list)
  counts<-Reduce("+",lapply(names_list, function(x) all_names %in% x ))
  names(counts)<- all_names
  counts
}
```

```{r}

freq_3D_med<- selection_frequency(rel_taxa_3D_med)
freq_3D_zero<- selection_frequency(rel_taxa_3D_zero)

```
### Are there any taxa found consistently relevant in lower dimension, but not relevant in 3D??

Yes, but their statistics are on the lower side, which means that they are not declared as relevant due to stricter criterion on the k-relevance that has  to be satisfied for 3-tuples.

```{r}
union(df_0bin_base$name[!df_0bin_base$partner_only],
  summary_df$name[!summary_df$partner_only] ) -> base_confirmed_12Drel
    
print(sprintf("%d out of %d relevant taxa found in lower dimension appear in any run of 3D",
              sum(base_confirmed_12Drel %in% union(names(freq_3D_med),names(freq_3D_zero))),
              length(base_confirmed_12Drel)
))

base_confirmed_12Drel[!(base_confirmed_12Drel %in% 
                          union(names(freq_3D_med),names(freq_3D_zero)))]-> not_found_in_3D
print("2D IGs of remaining ones are:")
summary_df$IG2D[summary_df$name %in% not_found_in_3D]

```


### 3D relevance frequency plots:

```{r}

barplot(sort(unname(freq_3D_med)), main="median based relevance frequencies")
barplot(sort(unname(freq_3D_zero)), main="zero based relevance frequencies")
```

### Are there any taxa all times 3D relevant, but not all times relevant in lower dimension?

```{r}
union(df_0bin_base$name[!df_0bin_base$partner_only],
  summary_df$name[!summary_df$partner_only] ) -> base_confirmed_12Drel
    
print(sprintf("%d out of %d relevant taxa found in 3D appear in 2D or 1D",
              sum( union(names(freq_3D_med)[freq_3D_med==120],
                        names(freq_3D_zero)[freq_3D_zero==120])  %in% base_confirmed_12Drel),
              length(union(names(freq_3D_med)[freq_3D_med==120],
                        names(freq_3D_zero)[freq_3D_zero==120]))
))

```

### Synergistic triplets

```{r}

for (i in seq_along(base_resamples_extended[1:1])){
    ComputeInterestingTuplesDiscrete(data = base_resamples_extended[[i]]$taxa_binary,
                              decision = base_resamples_extended[[i]]$disease_status,
                              dimensions = 3,
                              interesting.vars = MDFS_3D_med[[i]]$relevant.variables
                              )->y
  
}

```


```{r}
if (!file.exists("MDFS_3D_discrete.RData")){
set.seed(21312)
  MDFS.discrete(data=tb_meanMED, decision = decision.mean.final, dimensions = 3, seed=21312)-> MDFS_3D_MEDbin
set.seed(21312)
  MDFS.discrete(data=tb_mean0, decision = decision.mean.final, dimensions = 3, seed=21312)-> MDFS_3D_0bin
  save(MDFS_3D_MEDbin, MDFS_3D_0bin, file = "MDFS_3D_discrete.RData")
} else {
  load("MDFS_3D_discrete.RData")
}
```

```{r}
union(
colnames(tb_mean0)[MDFS_3D_0bin$relevant.variables],
colnames(tb_mean0)[MDFS_3D_MEDbin$relevant.variables])-> taxa_3D
length(taxa_3D)
union(summary_df$name, df_0bin_base$name)-> taxa_2D_and_partners_bothMethods
taxa_3D[ !(taxa_3D %in% taxa_2D_and_partners_bothMethods) ]-> taxa_3D_only

```


```{r}

union(taxa_3D, taxa_2D_and_partners_bothMethods)-> all_relevant_123D

MDFS_3D$statistic-> stat_3D
colnames(taxonomy.mean.final)->names(stat_3D)

taxa_1D_only<- names(rel_freq_1D)[(rel_freq_1D==30) & (rel_freq_2D<30)]
taxa_2D<- names(rel_freq_1D)[(rel_freq_2D==30)]

plot_colors<- ifelse(all_relevant_123D %in% taxa_1D_only, "red",
                     ifelse(all_relevant_123D %in% taxa_2D, "blue",
                            ifelse(all_relevant_123D %in% taxa_3D_only, "green", "gray")))

stat_3D[all_relevant_123D]-> stat_3D_plot
order(-stat_3D_plot)->order_3D
stat_3D_plot<-stat_3D_plot[order_3D]
plot_colors<-plot_colors[order_3D]

hist(stat_3D[taxa_3D_only])

names(stat_3D_plot)<- lapply(names(stat_3D_plot), get_deepest_taxonomy_lvl) |> unlist()
par(mar = c(8, 4, 4, 2))  # Adjust the margin on the bottom (first value)
barplot(stat_3D_plot[1:30], main="MDFS 3D statistics for relevant taxa",
        col = plot_colors[1:30],
        las=3,cex.names = 0.65, ylab="IG (3D)")
legend("topright", pch=15, col=c("blue","green"), legend=c("2D relevant","3D only"))
abline(h=80, lty="dotted")
abline(h=70, lty="dotted")
abline(h=90, lty="dotted")
abline(h=60, lty="dotted")
abline(h=50, lty="dotted")

```

####Compare with U-test

```{r}
intersect(setdiff(taxa_3D,any_times_relevant_taxa), xx$rel_set)-> only_3D_but_Utest
unname(cbind(stat_3D[only_3D_but_Utest],
      lapply(only_3D_but_Utest, get_deepest_taxonomy_lvl) |> unlist(),
      xx$adjusted.p.value[xx$relevant.variables][match(only_3D_but_Utest,xx$rel_set)]))->df_comparison

colnames(df_comparison)<- c("IG","taxon","U_test.adjusted.p.value")
      df_comparison


```
```{r}
x=base_resamples[[1]]$taxa_abundance[,"sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"]
 y=base_resamples[[1]]$disease_status
 x[(y==0)&(x!=0)]->x0
 x[(y==1)&(x!=0)]->x1
 range(c(x0,x1))->x01rng
 seq(from=x01rng[[1]],to=x01rng[[2]],length.out=20)->brks
 hist(x[(y==0)&(x!=0)], plot=FALSE,breaks=brks)->h1
 hist(x[(y==1)&(x!=0)], plot=FALSE,breaks=brks)->h2
 plot(h2$mids, h2$counts, lwd=2, type="line", col="green",log='y')
 lines(h1$mids, h1$counts, lwd=2, col="red")
```

#### Redo 2D analysis on median dataset

```{r}
library(MDFS)
base_resamples<-readRDS("base_resamples.rds")
 MDFS_1D_result_ab <- MDFS(
    data = base_resamples[[1]]$taxa_abundance, #taxonomy.mean.final, # 
    decision = base_resamples[[1]]$disease_status, #decision.mean.final, 
    dimensions = 1,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed = 1,
    level = 0.05
  )
  MDFS_1D_result_bin <- MDFS(
    data = base_resamples[[1]]$taxa_binary, #taxonomy.mean.final, # 
    decision = base_resamples[[1]]$disease_status, #decision.mean.final, 
    dimensions = 1,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed = 1,
    level = 0.05
  )

```

#### MDFS::Discretize at fault?

```{r}
base_data<- base_resamples[[1]]
pseudomonas_name<-"sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"

MDFS::Discretize(base_data$taxa_abundance,
                 variable.idx = which(colnames(base_data$taxa_abundance)==
                                  pseudomonas_name),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_ab_MDFS_discretized # dyskretyzowane abundance z MDFS


pseudomonas_bin_median_discr<- base_resamples[[1]]$taxa_binary[,pseudomonas_name] # dyskretyzowane binarnie z miediany


print("MDFS abundance binarized vs manual median binarized")
print(
table(pseudomonas_bin_median_discr, pseudomonas_ab_MDFS_discretized)
)



# binarny wstawiony w MDFS::Discretize
MDFS::Discretize(base_data$taxa_binary,
                 variable.idx = which(colnames(base_data$taxa_abundance)==
                                  pseudomonas_name),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_bin_MDFS_discretized # dyskretyzowane abundance z MDFS



print("MDFS::Discretize(median binarized variable) vs manual median binarized")
print(
table(pseudomonas_bin_median_discr, pseudomonas_bin_MDFS_discretized)
)



```

```{r}
pseudomonas_name %in% colnames(base_resamples[[1]]$taxa_binary)[MDFS_1D_result_ab$relevant.variables]
pseudomonas_name %in% colnames(base_resamples[[1]]$taxa_binary)[MDFS_1D_result_bin$relevant.variables]


```
```{r}
 colnames(base_resamples[[1]]$taxa_binary)-> b1_tnames
MDFS_1D_result_ab$statistic[MDFS_1D_result_ab$relevant.variables]-> b1_stat_ab
MDFS_1D_result_bin$statistic[MDFS_1D_result_ab$relevant.variables]-> b1_stat_bin
data.frame(ab=round(b1_stat_ab,4),bin=round(b1_stat_bin,4),name=lapply(b1_tnames[MDFS_1D_result_ab$relevant.variables], 
                                    get_deepest_taxonomy_lvl) |> unlist())->df_ab_vs_bin_stat

df_ab_vs_bin_stat[order(-df_ab_vs_bin_stat$ab),]

```



```{r}
MDFS::Discretize(base_resamples[[1]]$taxa_abundance,
                 variable.idx = which(colnames(base_resamples[[1]]$taxa_abundance)==
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_MDFS_discr
```

```{r}
MDFS::Discretize(base_resamples[[1]]$taxa_binary,
                 variable.idx = which(colnames(base_resamples[[1]]$taxa_abundance)==
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_bin_MDFS_discr

```


```{r}
base_resamples[[1]]$taxa_binary[,
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"]->pseudomonas_bin
```

```{r}
base_resamples[[1]]$taxa_abundance[,
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"]->pseudomonas_ab
```

```{r}

table(pseudomonas_bin, pseudomonas_MDFS_discr)
table(pseudomonas_bin, pseudomonas_bin_MDFS_discr)

```

```{r}

colnames(base_resamples[[1]]$taxa_binary)[MDFS_2D_result_mean$relevant.variables]
#colnames(taxonomy.mean.final)[MDFS_2D_result_mean$relevant.variables]


```

### Different subtypes of food allergy


Main steps of the pipeline are contained in `resampled_MDFS_analysis.R` and include:

- resampling of the dataset - picking 1 sample per each repeating donor
- adjustment for the decision variable used - removal of variables with low counts in one of the classes
- feature selection using MDFS
- selection of consistently relevant taxa
- picking of the best partners for the relevant taxa


```{r}
decisions=c("allergic_to_peanuts", "allergic_to_shellfish", "allergic_to_tree_nuts")
decision_results<- list()
source("resampled_MDFS_analysis.R")
for (i in seq_along(decisions)){
  set.seed(i)
seeds<-sample.int(343242,30)
print(sprintf("working on %s",decisions[[i]]))
resample_MDFS(metadata = metadata, taxonomy = tdata, 
              decision_colname=decisions[[i]],
			         n_resamples=30,
			         seeds=seeds,
			          host_id_colname="host.subject.id",
			            #passed to draw_once_per_host
                   	 min_minority_class_taxa =20, 
			            min_minority_class_dis = 30,
			          binarize_on_median=TRUE,
			          print_summary = FALSE,
                report_progess = TRUE)-> decision_results[[i]]
}
```
