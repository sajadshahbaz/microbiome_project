---
title: "Information Theory and Machine Learning Reveal Synergistic Interactions in
  Gut Microbiota Related to Food Allergy - data analysis pipeline"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Initial data preparation

Read the raw taxonomy abundance info and metadata from delimiter separated files.

```{r read}
metadata.filename <- "metadata.csv"
taxa.filename <- "taxa.tsv"
tdata <- as.data.frame(t(read.delim(taxa.filename, header = TRUE, sep = "\t")))
colnames(tdata) <- tdata[1,]
tdata <- tdata[-1,]

metadata<-read.csv(metadata.filename, header = TRUE, sep = ",")
rownames(metadata)<-metadata[,1]
metadata<-metadata[,-1]

```

## Filtering of erroneus data


```{r}
library(magrittr)
c("sex","height.cm","weight.kg","age.years")-> confounding_factors
confounding_factors %in% colnames(metadata)
metadata$sex[!(metadata$sex %in% c("male","female"))]<- NA
metadata$height[metadata$height.cm<38]<-NA
metadata$weight[metadata$weight.kg<1]<-NA
metadata$age_years[metadata$age.years<=0]<-NA
metadata$height[metadata$height.cm>220]<-NA
metadata$weight[metadata$weight.kg<=1]<-NA
metadata$weight[metadata$weight.kg>200]<-NA
to_remove_mask <- (metadata[,confounding_factors] %>% is.na() %>% rowSums()) > 1
metadata<-metadata[!to_remove_mask, ]
```

### Taxa table preparation 

#### Bacteria selection and stool samples filtering

```{r}
#1. skip non bacterial taxa
to_skip_IDX<- c(1:9, 1022:1028)
tdata<- tdata[,-to_skip_IDX]
print("inital number of taxa samples")
print(nrow(tdata))
metadata$env_material-> sample_source
feces_rownames<- rownames(metadata)[ sample_source=="feces" ]
tdata<-tdata[ intersect(rownames(tdata),feces_rownames),] 
print("number of taxa samples from stool")
print(nrow(tdata))
```

#### Alpha diversity analysis and normalization

Normalize abundancies and use proportions to calculate 3 versions of alpha diversity indexes. Below plots show values of alpha diversity as a function of the rank of cumulative count of each sample.
Investigation suggests a common cutoff point, which corresponds to minimum cumulative count of `3636`.

```{r}
  t_rownames<- rownames(tdata)
  tdata<- lapply(tdata, as.numeric) %>% as.data.frame()
  rownames(tdata)<- t_rownames
  lib_sizes<- rowSums(tdata) 
  t_props<-( tdata
            )/lib_sizes #due to R recycling, each row gets divided by its sum
  shannon_div<- -rowSums((t_props+1e-10)*log(t_props+1e-10))
  simpson_index<- rowSums ( 1 - t_props^2  )
  inverse_simp<- 1/rowSums( t_props^2 )
  size_order<-order(lib_sizes)

  taxa_min_lib_size= 3636 
  crit_rank= which.min(abs(lib_sizes[size_order] - taxa_min_lib_size))

  plot(shannon_div[size_order],type='l')
  abline(v = crit_rank, col="red",lwd=2) 
  plot(simpson_index[size_order],type='l')
  abline(v = crit_rank, col="red",lwd=2) 
  plot(inverse_simp[size_order],type='l')
  abline(v = crit_rank, col="red",lwd=2) 


  tdata<- tdata[ rowSums(tdata) >= taxa_min_lib_size, ]
  tdata<- tdata/rowSums(tdata)
```

### Integrate two types of information and prepare data for base resampling procedure


```{r}
common_names<- intersect(rownames(metadata), rownames(tdata))
tdata<- tdata[common_names,]
metadata<-metadata[common_names,]
print("# of samples left after filtering by alpha diversity (with repeating donors)")
print(length(common_names))
print("# of unique donors")
print(length(unique(metadata$host.subject.id)))
#saveRDS(taxonomy, "taxonomy_with_repeats.rds")
#saveRDS(host_id, "host_id_with_repeats.rds")
#saveRDS(disease, "disease_vector_with_repeats.rds")
```


## Base resamples construction

Function `draw_once_per_host` does following things:

- draws one sample from each unique donor which has submitted more than one sample

- binarizes taxa by their median value, setting values bigger than median to 1

- filters out sparse taxa according to `min_minority_class_taxa`

```{r}
library(matrixStats)
source("draw_once_per_host2.R")
#y= 1 - as.numeric(metadata$allergic.to.i.have.no.food.allergies.that.i.know.of)
#names(y)<-rownames(metadata)
y= readRDS("ANY_FOOD_ALLERGY_DECISION.rds")
host_id<- metadata$host.subject.id
names(host_id)<- rownames(metadata)
#base_resamples<- list()
#start<-Sys.time()
#for (i in 1:30){
#  set.seed(i)
#draw_once_per_host(taxonomy=tdata, disease = y, host_id = host_id,
#                   min_minority_class_taxa =20, min_minority_class_dis = 30,print_summary = FALSE,
#                   report_progess = FALSE)->base_resamples[[i]]
#message(sprintf("%d/30 done",i))
#}
#print(Sys.time()-start)
#saveRDS(base_resamples, "base_resamples.rds")
```


## Feature selection

Perform MDFS in 1D and 2D mode on each of the prepared base resamples.

```{r}
#base_resamples<-readRDS("base_resamples.rds")
load("../randomdataset.RData")
lapply(randomdataset, function(x) x$agp_sample) -> base_resamples
library(MDFS)
MDFS_1D<-MDFS_2D<-MDFS_1D_relnames<-MDFS_2D_relnames<-MDFS_1D2D_relnames<-list()
for (i in 1:30){current_seed=i
  set.seed(current_seed)
  # Perform MDFS with 1D
  MDFS_1D_result <- MDFS(
    data = base_resamples[[i]]$taxa_binary,
    decision = base_resamples[[i]]$disease_status,
    dimensions = 1,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed= current_seed,  # Set the seed for reproducibility
    level = 0.05
  )

  MDFS_1D[[i]] <- MDFS_1D_result
  MDFS_1D_relnames[[i]] <- colnames(base_resamples[[i]]$taxa_binary)[MDFS_1D_result$relevant.variables]

  # Perform MDFS with 2D
  MDFS_2D_result <- MDFS(
    data = base_resamples[[i]]$taxa_binary,
    decision = base_resamples[[i]]$disease_status,
    dimensions = 2,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed = current_seed,
    level = 0.05
  )
  MDFS_2D[[i]] <- MDFS_2D_result
  MDFS_2D_relnames[[i]] <- colnames(base_resamples[[i]]$taxa_binary)[MDFS_2D_result$relevant.variables]

  # Combine 1D and 2D relevant variables
  MDFS_1D2D_relnames[[i]] <- union(MDFS_1D_relnames[[i]], MDFS_2D_relnames[[i]])
message(sprintf("%d/30 done",i))
}

# Combine results into lists of lists
MDFS_object_lists <- list(MDFS_1D = MDFS_1D, MDFS_2D = MDFS_2D)
relnames_lists <- list(MDFS_1D_rel = MDFS_1D_relnames, 
                       MDFS_2D_rel = MDFS_2D_relnames, 
                       MDFS_1D2D_rel = MDFS_1D2D_relnames)
# Save results
save(relnames_lists, MDFS_object_lists, 
     file = "rel_MDFS_group.RData")
```

## Integrate results from base resamples 

```{r}
#names rel. either in 1D or 2D in each of the trials
any_times_relevant_taxa<- Reduce(union, relnames_lists$MDFS_1D2D_rel)


```

### Estabilish robust set of relevant features from base resampling

#### Calculate frequencies of appearance as relevant

```{r}
#containers for frequencies
rel_freq<-rel_freq_1D<-rel_freq_2D<-rep(0, length(any_times_relevant_taxa))
names(rel_freq)<-names(rel_freq_1D)<-names(rel_freq_2D)<-any_times_relevant_taxa
for (i in seq_along(relnames_lists[[1]])) {
 rel_freq<- rel_freq + ( any_times_relevant_taxa %in% relnames_lists$MDFS_1D2D_rel[[i]] )*1. 
 rel_freq_1D<- rel_freq_1D + ( any_times_relevant_taxa %in% relnames_lists$MDFS_1D_rel[[i]] )*1. 
 rel_freq_2D<- rel_freq_2D + ( any_times_relevant_taxa %in% relnames_lists$MDFS_2D_rel[[i]] )*1. 
  
}
```

#### Reduce the set to taxa that appeared relevant 30 times in either 1D or 2D

```{r}
which_stay<-(rel_freq==30)
base_relevant_set<- any_times_relevant_taxa[which_stay]
rel_freq<- rel_freq[which_stay]
rel_freq_1D<-rel_freq_1D[which_stay]
rel_freq_2D<-rel_freq_2D[which_stay]
```

### Find interaction partners for each of 2D relevant taxa

Function `get_interaction_partner` finds the best partners of each variable in `dataset` determined by index in `interesting.vars`, according to the Information Gain (IG) on `decision`.
Here:

- `dataset` will be binarized taxa, 

- `decision` is disease status,

- `interesting.vars` will be variables relevant in 2D analysis,

... in each of the 30 base resamples.


```{r}

get_interaction_partner<- function(dataset, decision, interesting.vars, ...){

if (!(all(interesting.vars %in% 1:ncol(dataset))))
        stop("interesting.vars must be in 1:ncol(dataset)")

if (is.null(colnames(dataset)))
        stop("datatset should have column names (taxa names)")

best.tuples <- ComputeInterestingTuples(dataset,
                                        decision,
                                        interesting.vars =interesting.vars,                                         ...
                                          )
do.call(rbind,
       lapply(interesting.vars, function(V){

               V_subset<- best.tuples$Var == V
               V_which.max<- which.max( best.tuples[ V_subset,]$IG )
              m_t1<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.1"]]
              m_t2<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.2"]]
              p_IDX<- if( V== m_t1) m_t2 else m_t1
              data.frame( rel_IDX= V, partner_IDX= p_IDX, rel_name = colnames(dataset)[[V]],                                                                             partner_name= colnames(dataset)[[p_IDX]],
                 rel_IG= best.tuples[ V_subset, ][V_which.max,][["IG"]] )
              }
             )
       )
}


```


#### Apply the function on each of the base resamples:

```{r}

partners_per_run<- list()
i_set<-1
for (i_set in seq_along(base_resamples))
{
partners_per_run[[i_set]] <-
get_interaction_partner(dataset=base_resamples[[i_set]]$taxa_binary,
                         decision=base_resamples[[i_set]]$disease_status,
                     interesting.vars=MDFS_object_lists[[2]][[i_set]]$relevant.variables ,
                        range=0, dimensions=2)

}



```

Function returns data.frame of names of relevant variables (taxa), their positions in each set and the same of their partners.
We can inspect output from one run, for context. Auxiliary function shortens taxa names to the deepest available classification:

```{r}

partners_per_run[[1]]-> example_out

get_deepest_taxonomy_lvl<- function(taxa_name){
strsplit(taxa_name,";")-> splitted
splitted[[1]][[ length(splitted[[1]]) ]]
}
example_out$rel_name<- unlist(lapply(example_out$rel_name, get_deepest_taxonomy_lvl))
example_out$partner_name<- unlist(lapply(example_out$partner_name, get_deepest_taxonomy_lvl))

example_out[order(example_out$rel_IG, decreasing=TRUE),] %>% head

```

#### Aggregate the results from all resamples

We calculate mean IG for each synergistic pair over all base resamples it appears in.

Then, for each relevant variable in 2D, we take its "definitive" partner as the one that had maximum mean IG over all base resamples.

```{r}
#mean IG
do.call(rbind, partners_per_run)-> partners_all_runs #all runs together
aggregate(partners_all_runs$rel_IG, #value to aggregate
          list(rel=partners_all_runs$rel_name,       #factors over which to group
              partner=partners_all_runs$partner_name),
          mean #how to aggregate
          )-> partner_IG_tabulation


lapply(base_relevant_set[rel_freq_2D==30], function(taxon)
{
        taxon_subset<- partner_IG_tabulation$rel == taxon
        if (any(taxon_subset))
        {
                taxon_partners<-partner_IG_tabulation[ taxon_subset, ,drop=FALSE]
                taxon_partners$partner[[ which.max(taxon_partners$x) ]]
        } else NA

}       ) %>% unlist() -> best_partners_baseRelSet

names(best_partners_baseRelSet)<- base_relevant_set[rel_freq_2D==30]

```


#### Use mean IG to estabilish true synergies

We calculate mean IG of all selected taxa so far (relevant 30 times in 1D or 2D + best partners for 2D relevant ones) to estabilish criteria for synergy:

- if the increase of IG in 2D of the 2D relevant variable is bigger than the minimal IG in 1D analysis. 


```{r}
union(base_relevant_set, unname(best_partners_baseRelSet))-> overall_rel_list

#containers of mean IG
overall_rel_IG1D<- rep(0, length(overall_rel_list))
overall_rel_IG2D<- rep(0, length(overall_rel_list))
names(overall_rel_IG1D)<-names(overall_rel_IG2D)<-overall_rel_list
rel_1D_names<- names(rel_freq[rel_freq_1D==30])
rel_2D_names<- names(rel_freq[rel_freq_2D==30])
for (i in seq_along(MDFS_object_lists[[1]])){
  #taxa present in run "i"
  resample_present_taxa<-colnames(base_resamples[[i]]$taxa_binary)
  #found relevant in "i" and relevant 30 times overall
  intersect(resample_present_taxa, relnames_lists[[1]][[i]]) -> rel1Dtaxa_thisRun
  intersect(rel1Dtaxa_thisRun, rel_1D_names)-> rel1Dtaxa_thisRun
  intersect(resample_present_taxa, relnames_lists[[2]][[i]]) -> rel2Dtaxa_thisRun
  intersect(rel2Dtaxa_thisRun, rel_2D_names)-> rel2Dtaxa_thisRun
  #their position in run "i"
  match( rel1Dtaxa_thisRun, resample_present_taxa)-> rel_1D_idx
  match( rel2Dtaxa_thisRun, resample_present_taxa)-> rel_2D_idx
  #their IG 
   MDFS_object_lists[[1]][[i]]$statistic[ rel_1D_idx ] -> IG_1D_resample
   MDFS_object_lists[[2]][[i]]$statistic[ rel_2D_idx ] -> IG_2D_resample
   stopifnot(all(rel1Dtaxa_thisRun %in% names(overall_rel_IG1D))) 
   stopifnot(all(rel2Dtaxa_thisRun %in% names(overall_rel_IG2D))) 
   #increase sums only for relevant variables from that run
   overall_rel_IG1D[ rel1Dtaxa_thisRun ] = overall_rel_IG1D[ rel1Dtaxa_thisRun ] + IG_1D_resample
   overall_rel_IG2D[ rel2Dtaxa_thisRun ] = overall_rel_IG2D[ rel2Dtaxa_thisRun ] + IG_2D_resample
}
#divide overall_rel_IG by the times each variable was found relevant
times_rel_overall<- rep(1, length(overall_rel_list))
names(times_rel_overall)<-overall_rel_list
times_rel_overall[ names(rel_freq) ] = rel_freq
overall_rel_IG1D<- overall_rel_IG1D/times_rel_overall
overall_rel_IG2D<- overall_rel_IG2D/times_rel_overall

#overall_rel_IG1D[ !(overall_rel_list %in% names(rel_freq_1D)[rel_freq_1D==30]) ] =0
#overall_rel_IG2D[ !(overall_rel_list %in% names(rel_freq_2D)[rel_freq_2D==30]) ] =0
```

```{r}
data.frame( name=overall_rel_list,
            IG1D=overall_rel_IG1D, IG2D= overall_rel_IG2D)-> ig_df
ig_df$rel_1D<- rel_freq_1D[ ig_df$name ]
ig_df$rel_2D<- rel_freq_2D[ ig_df$name ]
ig_df$rel_1D[ is.na(ig_df$rel_1D) ] = 0
ig_df$rel_2D[ is.na(ig_df$rel_2D) ] = 0
ig_df$partner_name<- best_partners_baseRelSet[ ig_df$name ]
ig_df$partner_only<- ig_df$name %in% setdiff(best_partners_baseRelSet, base_relevant_set)
synergy_thr<- min(ig_df$IG1D[ig_df$rel_1D==30])
print("minimal increase of IG in 2D analysis for estabilishing synergy:")
print(synergy_thr)
IG_increase= ig_df$IG2D - ig_df$IG1D
# find the true synergies using the thredhold and IG_increase of primary 2D rel. variable:
true_synergistic_partners<-vector(mode="character")
for (partner_only in ig_df$name[ig_df$partner_only])
{
  if (max(IG_increase[which(ig_df$partner_name== partner_only) ]) > synergy_thr)
    true_synergistic_partners[[ length(true_synergistic_partners)+1 ]] = partner_only
}

#for the rest of the analysis:
# keep taxa that were relevant 30 times in 2D or 1D and true synergistic partners.
taxa_to_keep_mask<- (ig_df$name %in% true_synergistic_partners) | 
                      (ig_df$rel_1D==30 ) | 
                      (ig_df$rel_2D==30)
ig_df<- ig_df[ taxa_to_keep_mask,]
ig_df<- ig_df[ order(-ig_df$IG2D),]
viz_ig_df<- ig_df
viz_ig_df$name<- unlist(lapply(viz_ig_df$name, get_deepest_taxonomy_lvl))
viz_ig_df$partner_name<- unlist(lapply(viz_ig_df$partner_name, get_deepest_taxonomy_lvl))
rownames(viz_ig_df)<- 1:nrow(viz_ig_df)
viz_ig_df[,2:3]<-round(viz_ig_df[,2:3])
viz_ig_df
```

## mean presence and abundance of selected taxons across 30 trials

```{r}
summary_df<- ig_df
summary_df$name-> interesting_taxa
#ensure all base_resamples have same number of rows 
stopifnot( all(
        (lapply(base_resamples, function(x) nrow(x$taxa_abundance)) %>%
            unlist() )== nrow(base_resamples[[1]]$taxa_abundance) 
              )
         )

#common basis for all interesting taxa
# (containers for sums)
A_h<-A_d<-P_h<-P_d<-P<-A<- rep(0, length(interesting_taxa))
names(P)<-names(A)<-interesting_taxa
names(P_d)<-names(A_d)<-interesting_taxa
names(P_h)<-names(A_h)<-interesting_taxa

#sum means over resamples
for (i in seq_along(base_resamples)){
    
    intr_present_resample<- intersect(interesting_taxa,
                                colnames(base_resamples[[i]]$taxa_abundance)
                                    )

    P_rsmp<-base_resamples[[i]]$taxa_binary[, intr_present_resample]
    A_rsmp<-base_resamples[[i]]$taxa_abundance[, intr_present_resample]
    y_rsmp<-base_resamples[[i]]$disease_status

    P[ intr_present_resample ] =  P[ intr_present_resample ] +
            colMeans(P_rsmp)
    A[ intr_present_resample ] =  A[ intr_present_resample ] +
            colMeans(A_rsmp)

    P_d[ intr_present_resample ] =  P_d[ intr_present_resample ] +
            colMeans(P_rsmp[y_rsmp==1,])
    A_d[ intr_present_resample ] =  A_d[ intr_present_resample ] +
            colMeans(A_rsmp[y_rsmp==1,])

    P_h[ intr_present_resample ] =  P_h[ intr_present_resample ] +
            colMeans(P_rsmp[y_rsmp==0,])
    A_h[ intr_present_resample ] =  A_h[ intr_present_resample ] +
            colMeans(A_rsmp[y_rsmp==0,])
}
#.. and divide by 30
P<-P/30
A<-A/30
P_h<-P_h/30
A_h<-A_h/30
P_d<-P_d/30
A_d<-A_d/30
summary_df$freq= P
summary_df$ab= A
summary_df$freq_d= P_d
summary_df$ab_d= A_d
summary_df$freq_h= P_h
summary_df$ab_h= A_h

```
# Bootstrap resampling validation

Following initial selection of robust features relevant both in 1D and 2D, we validated the results by the use of bootstrap resampling on base resamples themselves.

From each base resample, we have drawn a boostrap resample and performed feature selection again and counted number of times selected features reappeared again as relevant.
Additionally, to test the usability of detected two dimensional interactions, we measured the average gain of AUC from random forest classifier, trained using only 1D relevant variables vs on the whole set of 1D and 2D relevant features.



## Preparation if bootstrap samples (by sampling indexes)

```{r}
N_TRIALS=30
keep_frac<-1

n1<-  sum(base_resamples[[1]]$disease_status==1)
n0<-  sum(base_resamples[[1]]$disease_status==0)

n1k<- ceiling(n1*keep_frac)
n0k<- ceiling(n0*keep_frac)

#list of 30
set.seed(32523)
B_idx<- lapply(1:N_TRIALS,
                       function(B)
                       {
                         y<-base_resamples[[B]]$disease_status
                         
                         idx_1= which(y==1)
                         idx_0= which(y==0)
                         c( sample(idx_1, n1k, replace=TRUE),
                        sample(idx_0, n0k, replace=TRUE)
                         )
                       }
                      )
saveRDS(B_idx,"Bootstrap_IDX.rds")

```

## Feature selection and RF

We save results of each run in subdirectories `MDFS_results`, `RF_models` and calculate mean metrics after all computation is done.

```{r}
library(randomForest)
library(pROC)
#prepare list of seeds per each bootstrap for reproducibility
set.seed(32432)
session_seeds<- sample.int(323423,N_TRIALS)
    summary_df$name[summary_df$rel_1D==30] -> consensus_1D
    summary_df$name -> consensus_AllRelevant
for (B in 1:N_TRIALS) {
    IDX_B<-  B_idx[[B]]
    set_B<- base_resamples[[B]]
    set.seed(session_seeds[[B]])
#FS
   if (!file.exists( sprintf("MDFS_results/MDFS_replicate_%d.rds", B ) ) ) {
    MDFS_1D<- MDFS(
    data = set_B$taxa_binary[IDX_B,],
    decision = set_B$disease_status[IDX_B],
    dimensions = 1,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed= session_seeds[[B]], 
    level = 0.05
    )
    rel_1D<- colnames(set_B$taxa_binary)[MDFS_1D$relevant.variables]
    # Perform MDFS with 2D
    MDFS_2D<- MDFS(
    data = set_B$taxa_binary[IDX_B,],
    decision = set_B$disease_status[IDX_B],
    dimensions = 2,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed = session_seeds[[B]],
    level = 0.05
    )
    rel_2D<- colnames(set_B$taxa_binary)[MDFS_2D$relevant.variables]
    rel_1or2D<-  union( rel_1D, rel_2D)  
    FS<- list(rel_1D= rel_1D,
            rel_2D= rel_2D,
            rel_1or2D=rel_1or2D)
    saveRDS( FS, sprintf("MDFS_results/FS_replicate_%d.rds", B ) )
    saveRDS( list(MDFS_1D=MDFS_1D,
                MDFS_2D=MDFS_2D),
            sprintf("MDFS_results/MDFS_replicate_%d.rds", B ) )
	}
            

    #RF
	if ( ! file.exists( sprintf("RF_models/RF_replicate_%d.rds",B)) ) {
    unique(IDX_B)-> uqIDX_B
    set.seed(session_seeds[[B]])
    randomForest(x = set_B$taxa_binary[uqIDX_B, consensus_1D],
                y =  as.factor(set_B$disease_status[uqIDX_B]),
                importance = TRUE,
                keep.forest = TRUE)-> RF_1D
    randomForest(x = set_B$taxa_binary[uqIDX_B, consensus_AllRelevant],
                y =  as.factor(set_B$disease_status[uqIDX_B]),
                importance = TRUE,
                keep.forest = TRUE)-> RF_all
    saveRDS(list(RF_1D=RF_1D,
                RF_all=RF_all),
            sprintf("RF_models/RF_replicate_%d.rds", B)
    )
	}
    message(sprintf("%d/%d done", B, N_TRIALS))
}
```

### Aggregation of results

#### Count how many times relevant features showed up again and compute mean random forest metrics
```{r}
library(pROC)

#filename patterns for reading the results
fs_fpattern<-"MDFS_results/FS_replicate_%d.rds"
mdfs_fpattern<-"MDFS_results/MDFS_replicate_%d.rds"
rf_fpattern<- "RF_models/RF_replicate_%d.rds" 

#containers:
rel_2D_trials<-rel_1D_trials<- list()  #for indicators of relevance per each run
CM1_trials<-CMall_trials<-  list() #for confusion matrices
RF1_trials<- RFall_trials<-list() #for RF performance metrics

#auxiliary oods ratio computation
odds_ratio<- function(CM) {(CM[2,2]*CM[1,1])/(CM[1,2]*CM[2,1]) } 

for (B in 1:N_TRIALS){

B_tnames<-colnames(base_resamples[[B]]$taxa_abundance)
B_P<- base_resamples[[B]]$taxa_binary #presence
B_A<- base_resamples[[B]]$taxa_abundance #presence
B_y<- base_resamples[[B]]$disease_status


#indexes of resampled and oob subjects
B_IDX<- B_idx[[B]]
B_oob<- setdiff( 1:nrow(B_A), unique(B_IDX))

B_fs_fname<- sprintf( fs_fpattern, B)
B_FS<- readRDS( B_fs_fname)

#relevance indicators
rel_1D_trials[[B]]= 1.*(consensus_AllRelevant %in% B_FS$rel_1D)
rel_2D_trials[[B]]= 1.*(consensus_AllRelevant %in% B_FS$rel_2D)

#RF prediction on OOB

B_fs_fname<- sprintf( fs_fpattern, B)
B_rf_fname<- sprintf( rf_fpattern, B)
B_RF<- readRDS(B_rf_fname)$RF_all
B_RF1<- readRDS(B_rf_fname)$RF_1D


#predicted probabilities
B_RFall_prob<- predict( B_RF, newdata= B_P[B_oob,], type="prob")[,2]
B_RF1_prob<- predict( B_RF1, newdata= B_P[B_oob,], type="prob")[,2]

#predicted classes
B_RFall_cl<-  B_RFall_prob>0.5
B_RF1_cl<- B_RF1_prob>0.5

B_yoob<- B_y[B_oob]

#confusion matrices
cm_all<- table(Predicted=B_RFall_cl,Actual=B_yoob)
cm_1<- table(Predicted=B_RF1_cl,Actual=B_yoob)

CM1_trials[[B]]<- cm_1
CMall_trials[[B]]<- cm_all


RFall_score<- c(auc= auc(response=B_yoob, predictor= B_RFall_prob),
		OR=odds_ratio(cm_all),
		acc= sum( B_yoob == B_RFall_cl)/length(B_yoob)
)
RF1_score<- c(auc= auc(response=B_yoob, predictor= B_RF1_prob),
	      OR=odds_ratio(cm_1),
		acc= sum( B_yoob == B_RF1_cl)/length(B_yoob)
	      )

RF1_trials[[B]]<- RF1_score
RFall_trials[[B]]<- RFall_score


}


print("mean stats and SDs for RF on 1D:")
print(colMeans(do.call(rbind,RF1_trials)) )
print(colSds(do.call(rbind,RF1_trials)) )
print("confustuon matrix for all trials of RF on 1D:")
mean_CM_1D<- Reduce("+", CM1_trials)
print(mean_CM_1D)

print("mean stats for RF on 1,2D and partners:")
print(colMeans(do.call(rbind,RFall_trials)) )
print(colSds(do.call(rbind,RFall_trials)) )
print("confusion matrix for all trials of RF on 1, 2D and partners:")
mean_CM_all<- Reduce("+", CMall_trials)
print(mean_CM_all)

#reappearance as relevant in BS per each feature
Reduce("+", rel_1D_trials)->times_rel1D_BS
Reduce("+", rel_2D_trials)->times_rel2D_BS

names(times_rel1D_BS)<- names(times_rel2D_BS)<- consensus_AllRelevant

```

### Check the plausibility of initial feature set:

```{r}

summary_df$BS_rel1D= times_rel1D_BS[ summary_df$name ]
summary_df$BS_rel2D= times_rel2D_BS[ summary_df$name ]
viz_df<-summary_df
viz_df$name<- unlist(lapply(summary_df$name, get_deepest_taxonomy_lvl))
rownames(viz_df)<-NULL
viz_df[, c("name","rel_1D","BS_rel1D")]
```

```{r}

viz_df[, c("name","rel_2D","BS_rel2D")]

```
