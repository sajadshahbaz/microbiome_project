---
title: "Information Theory and Machine Learning Reveal Synergistic Interactions in
  Gut Microbiota Related to Food Allergy - data analysis pipeline"
output:
  html_document:
    toc: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Initial data preparation

Read the raw taxonomy abundance info and metadata from delimiter separated files.

```{r read}
metadata.filename <- "metadata.csv"
taxa.filename <- "taxa.tsv"
tdata <- as.data.frame(t(read.delim(taxa.filename, header = TRUE, sep = "\t")))
colnames(tdata) <- tdata[1,]
tdata <- tdata[-1,]

metadata<-read.csv(metadata.filename, header = TRUE, sep = ",")
rownames(metadata)<-metadata[,1]
metadata<-metadata[,-1]

```

## Filtering of erroneus data


```{r}
library(magrittr)
c("sex","height.cm","weight.kg","age.years")-> confounding_factors
confounding_factors %in% colnames(metadata)
metadata$sex[!(metadata$sex %in% c("male","female"))]<- NA
metadata$height[metadata$height.cm<38]<-NA
metadata$weight[metadata$weight.kg<1]<-NA
metadata$age_years[metadata$age.years<=0]<-NA
metadata$height[metadata$height.cm>220]<-NA
metadata$weight[metadata$weight.kg<=1]<-NA
metadata$weight[metadata$weight.kg>200]<-NA
to_remove_mask <- (metadata[,confounding_factors] %>% is.na() %>% rowSums()) > 0
metadata<-metadata[!to_remove_mask, ]
```

### Taxa table preparation 

#### Bacteria selection and stool samples filtering

```{r}
#1. skip non bacterial taxa
tdata<- tdata[, grep('sk__Bacteria', colnames(tdata)) ]
print("inital number of taxa samples")
print(nrow(tdata))
#2. keep stool samples
metadata$env_material-> sample_source
feces_rownames<- rownames(metadata)[ sample_source=="feces" ]
tdata<-tdata[ intersect(rownames(tdata),feces_rownames),] 
print("number of taxa samples from stool")
print(nrow(tdata))
```

#### Alpha diversity analysis and normalization

Normalize abundancies and use proportions to calculate 3 versions of alpha diversity indexes. Below plots show values of alpha diversity as a function of the rank of cumulative count of each sample.
Investigation suggests a common cutoff point, which corresponds to minimum cumulative count of `3636`.

```{r}
  t_rownames<- rownames(tdata)
  tdata<- lapply(tdata, as.numeric) %>% as.data.frame()
  rownames(tdata)<- t_rownames
  lib_sizes<- rowSums(tdata) 
  t_props<-( tdata
            )/lib_sizes #due to R recycling, each row gets divided by its sum
  shannon_div<- -rowSums((t_props+1e-10)*log(t_props+1e-10))
  simpson_index<- rowSums ( 1 - t_props^2  )
  inverse_simp<- 1/rowSums( t_props^2 )
  size_order<-order(lib_sizes)

  taxa_min_lib_size= 3636 
  crit_rank= which.min(abs(lib_sizes[size_order] - taxa_min_lib_size))

  plot(shannon_div[size_order],type='l')
  abline(v = crit_rank, col="red",lwd=2) 
  plot(simpson_index[size_order],type='l')
  abline(v = crit_rank, col="red",lwd=2) 
  plot(inverse_simp[size_order],type='l')
  abline(v = crit_rank, col="red",lwd=2) 


  tdata<- tdata[ rowSums(tdata) >= taxa_min_lib_size, ]
  tdata<- tdata/rowSums(tdata)
```

### Integrate two types of information and prepare data for base resampling procedure


```{r}
common_names<- intersect(rownames(metadata), rownames(tdata))
tdata<- tdata[common_names,]
metadata<-metadata[common_names,]
print("# of samples left after filtering by alpha diversity (with repeating donors)")
print(length(common_names))
print("# of unique donors")
print(length(unique(metadata$host.subject.id)))
```

## Median dataset and cohort summary


```{r}
y<- 1- metadata$allergic.to.i.have.no.food.allergies.that.i.know.of 
names(y)<- rownames(metadata)
library(matrixStats)

ids<-metadata$host.subject.id
names(ids)<-rownames(metadata)

donors<-unique(ids)

taxonomy.mean<-matrix(NA,length(donors),ncol(tdata))
rownames(taxonomy.mean)<-donors
colnames(taxonomy.mean)<-colnames(tdata)
meta.mean<-as.data.frame(matrix(NA,length(donors),6))
rownames(meta.mean)<-donors
colnames(meta.mean)<-c('age','sex','weight.kg','height.cm','BMI_cat','age_cat')
decision.mean<-numeric(length(donors))
names(decision.mean)<-donors

if (!file.exists("mean_data.RData")){
for (i in 1:length(donors)) {
 donor<-donors[i]
 samples<-names(ids)[ids==donor]
 
 #decision
 decs<-y[samples]
 decision.mean[i]<-floor(median(decs))
 
 #taxa
 taxa<-tdata[samples,,drop=F]
 taxonomy.mean[i,]<-colMedians(as.matrix(taxa))
 
 #metadata
 #age
 ages<-metadata[samples,'age.years']
 ages<-ages[!is.na(ages)]
 if (length(ages)>0) meta.mean[i,1]<-round(median(ages))
 #sex
 sexes<-metadata[samples,'sex']
 sexes<-sexes[!is.na(sexes)]
 if (length(sexes)>0) meta.mean[i,2]<-names(table(sexes))[which.max(table(sexes))]
 #weight
 weights<-as.numeric(metadata[samples,'weight.kg'])
 weights<-weights[!is.na(weights)]
 if (length(weights)>0) meta.mean[i,3]<-median(weights)
 #height
 heights<-as.numeric(metadata[samples,'height.cm'])
 heights<-heights[!is.na(heights)]
 if (length(heights)>0) meta.mean[i,4]<-median(heights)
 
 
 if(!((i-1)%%500)) print(sprintf("median data computation... %d / %d done",i, length(donors)))
}

mask.meta<-rowSums(is.na(meta.mean[,1:4]))==0

meta.mean.final<-meta.mean[mask.meta,]
meta.mean.final[meta.mean.final[1]<15,6]<-'0-14'
meta.mean.final[meta.mean.final[1]>=15 & meta.mean.final[1]<64,6]<-'15-64'
meta.mean.final[meta.mean.final[1]>=64,6]<-'65+'
bmi<-meta.mean.final[,'weight.kg']/meta.mean.final[,'height.cm']^2*10000
meta.mean.final[bmi<18.5,5]<-'Underweight'
meta.mean.final[bmi>=18.5 & bmi<25,5]<-'Normal'
meta.mean.final[bmi>=25 & bmi<30,5]<-'Overweight'
meta.mean.final[bmi>=30,5]<-'Obese'


decision.mean.final<-decision.mean[mask.meta]
taxonomy.mean.final<-taxonomy.mean[mask.meta,]
taxonomy.mean.final<-taxonomy.mean.final[,colSums(taxonomy.mean.final>0)>20]
taxonomy.mean.final<-as.data.frame(taxonomy.mean.final/rowSums(taxonomy.mean.final)*10000)

binary.mean.final<-taxonomy.mean.final*0
for (i in 1:ncol(binary.mean.final)) binary.mean.final[,i]<-taxonomy.mean.final[,i]>median(taxonomy.mean.final[,i])

save(meta.mean.final,decision.mean.final,taxonomy.mean.final,binary.mean.final,file='mean_data.RData')
} else {load("mean_data.RData")}


#Table 1 
table(decision.mean.final)

table(meta.mean.final[decision.mean.final==0,2])
table(meta.mean.final[decision.mean.final==1,2])

fisher.test(rbind(table(meta.mean.final[decision.mean.final==0,2]),
            table(meta.mean.final[decision.mean.final==1,2])))
            

table(meta.mean.final[decision.mean.final==0,6])
table(meta.mean.final[decision.mean.final==1,6])

fisher.test(rbind(table(meta.mean.final[decision.mean.final==0,6]),
                  table(meta.mean.final[decision.mean.final==1,6])))#,simulate.p.value = T)


table(meta.mean.final[decision.mean.final==0,5])
table(meta.mean.final[decision.mean.final==1,5])

fisher.test(rbind(table(meta.mean.final[decision.mean.final==0,5]),
                  table(meta.mean.final[decision.mean.final==1,5])))



```

## Base resamples construction

Function `draw_once_per_host` does following things:

- draws one sample from each unique donor which has submitted more than one sample

- binarizes taxa by their median value, setting values bigger than median to 1

- filters out sparse taxa according to `min_minority_class_taxa`

```{r}
source("draw_once_per_host2.R")
library(matrixStats)
host_id<- metadata$host.subject.id
names(host_id)<- rownames(metadata)
base_resamples<-list()
if (!file.exists("base_resamples.rds")){
for (i in 1:30){
  set.seed(i)
draw_once_per_host(taxonomy=tdata, disease = y, host_id = host_id,
                   min_minority_class_taxa =20, min_minority_class_dis = 30,print_summary = FALSE,
                   report_progess = FALSE)->base_resamples[[i]]
message(sprintf("%d/30 done",i))
}
saveRDS(base_resamples, "base_resamples.rds") } else {
  base_resamples<-readRDS("base_resamples.rds")
}
```


## Feature selection

Perform discrete variant of MDFS in 1D and 2D mode on each of the prepared base resamples.

```{r}
library(MDFS)
if (!file.exists("rel_MDFS_group.RData")) {
MDFS_1D<-MDFS_2D<-MDFS_1D_relnames<-MDFS_2D_relnames<-MDFS_1D2D_relnames<-list()
for (i in 1:30){current_seed=i
gc()
  set.seed(current_seed)
  # Perform MDFS with 1D
  MDFS_1D_result <- MDFS.discrete(
    data = base_resamples[[i]]$taxa_binary,
    decision = base_resamples[[i]]$disease_status,
    dimensions = 1,
    seed= current_seed,  # Set the seed for reproducibility
    level = 0.05
  )

  MDFS_1D[[i]] <- MDFS_1D_result
  MDFS_1D_relnames[[i]] <- colnames(base_resamples[[i]]$taxa_binary)[MDFS_1D_result$relevant.variables]
gc()
set.seed(current_seed)
  # Perform MDFS with 2D
  MDFS_2D_result <- MDFS.discrete(
    data = base_resamples[[i]]$taxa_binary,
    decision = base_resamples[[i]]$disease_status,
    dimensions = 2,
    seed = current_seed,
    level = 0.05
  )
  MDFS_2D[[i]] <- MDFS_2D_result
  MDFS_2D_relnames[[i]] <- colnames(base_resamples[[i]]$taxa_binary)[MDFS_2D_result$relevant.variables]

  # Combine 1D and 2D relevant variables
  MDFS_1D2D_relnames[[i]] <- union(MDFS_1D_relnames[[i]], MDFS_2D_relnames[[i]])
message(sprintf("%d/30 done",i))
}

# Combine results into lists of lists
MDFS_object_lists <- list(MDFS_1D = MDFS_1D, MDFS_2D = MDFS_2D)
relnames_lists <- list(MDFS_1D_rel = MDFS_1D_relnames, 
                       MDFS_2D_rel = MDFS_2D_relnames, 
                       MDFS_1D2D_rel = MDFS_1D2D_relnames)
# Save results
save(relnames_lists, MDFS_object_lists, 
     file = "rel_MDFS_group.RData")
} else { message("loading data");load("rel_MDFS_group.RData")}
```

## Integrate results from base resamples 

```{r}
#names rel. either in 1D or 2D in each of the trials
any_times_relevant_taxa<- Reduce(union, relnames_lists$MDFS_1D2D_rel)


```

### Estabilish robust set of relevant features from base resampling

#### Calculate frequencies of appearance as relevant

```{r}
#containers for frequencies
rel_freq<-rel_freq_1D<-rel_freq_2D<-rep(0, length(any_times_relevant_taxa))
names(rel_freq)<-names(rel_freq_1D)<-names(rel_freq_2D)<-any_times_relevant_taxa
for (i in seq_along(relnames_lists[[1]])) {
 rel_freq<- rel_freq + ( any_times_relevant_taxa %in% relnames_lists$MDFS_1D2D_rel[[i]] )*1. 
 rel_freq_1D<- rel_freq_1D + ( any_times_relevant_taxa %in% relnames_lists$MDFS_1D_rel[[i]] )*1. 
 rel_freq_2D<- rel_freq_2D + ( any_times_relevant_taxa %in% relnames_lists$MDFS_2D_rel[[i]] )*1. 
  
}
```

#### Reduce the set to taxa that appeared relevant 30 times in either 1D or 2D

```{r}
which_stay<-(rel_freq==30)
base_relevant_set<- any_times_relevant_taxa[which_stay]
rel_freq<- rel_freq[which_stay]
rel_freq_1D<-rel_freq_1D[which_stay]
rel_freq_2D<-rel_freq_2D[which_stay]
```

### Find interaction partners for each of 2D relevant taxa

Function `get_interaction_partner` finds the best partners of each variable in `dataset` determined by index in `interesting.vars`, according to the Information Gain (IG) on `decision`.
Here:

- `dataset` will be binarized taxa, 

- `decision` is disease status,

- `interesting.vars` will be variables relevant in 2D analysis,

... in each of the 30 base resamples.


```{r}

get_interaction_partner<- function(dataset, decision, interesting.vars, ...){

if (!(all(interesting.vars %in% 1:ncol(dataset))))
        stop("interesting.vars must be in 1:ncol(dataset)")

if (is.null(colnames(dataset)))
        stop("datatset should have column names (taxa names)")

best.tuples <- ComputeInterestingTuplesDiscrete(dataset,
                                        decision,
                                        interesting.vars =interesting.vars,                                         ...
                                          )
do.call(rbind,
       lapply(interesting.vars, function(V){

               V_subset<- best.tuples$Var == V
               V_which.max<- which.max( best.tuples[ V_subset,]$IG )
              m_t1<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.1"]]
              m_t2<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.2"]]
              p_IDX<- if( V== m_t1) m_t2 else m_t1
              data.frame( rel_IDX= V, partner_IDX= p_IDX, rel_name = colnames(dataset)[[V]],                                                                             partner_name= colnames(dataset)[[p_IDX]],
                 rel_IG= best.tuples[ V_subset, ][V_which.max,][["IG"]] )
              }
             )
       )
}


```


#### Apply the function on each of the base resamples:

```{r}

partners_per_run<- list()
i_set<-1
for (i_set in seq_along(base_resamples))
{
partners_per_run[[i_set]] <-
get_interaction_partner(dataset=base_resamples[[i_set]]$taxa_binary,
                         decision=base_resamples[[i_set]]$disease_status,
                     interesting.vars=MDFS_object_lists[[2]][[i_set]]$relevant.variables ,
                         dimensions=2)

}



```

Function returns data.frame of names of relevant variables (taxa), their positions in each set and the same of their partners.
We can inspect output from one run, for context. Auxiliary function shortens taxa names to the deepest available classification:

```{r}

partners_per_run[[1]]-> example_out

get_deepest_taxonomy_lvl<- function(taxa_name){
strsplit(taxa_name,"\\.")-> splitted
splitted[[1]][[ length(splitted[[1]]) ]]
}
example_out$rel_name<- unlist(lapply(example_out$rel_name, get_deepest_taxonomy_lvl))
example_out$partner_name<- unlist(lapply(example_out$partner_name, get_deepest_taxonomy_lvl))

example_out[order(example_out$rel_IG, decreasing=TRUE),] %>% head

```

#### Aggregate the results from all resamples

We calculate mean IG for each synergistic pair over all base resamples it appears in.

Then, for each relevant variable in 2D, we take its "definitive" partner as the one that had maximum mean IG over all base resamples.

```{r}
#mean IG
do.call(rbind, partners_per_run)-> partners_all_runs #all runs together
aggregate(partners_all_runs$rel_IG, #value to aggregate
          list(rel=partners_all_runs$rel_name,       #factors over which to group
              partner=partners_all_runs$partner_name),
          mean #how to aggregate
          )-> partner_IG_tabulation


lapply(base_relevant_set[rel_freq_2D==30], function(taxon)
{
        taxon_subset<- partner_IG_tabulation$rel == taxon
        if (any(taxon_subset))
        {
                taxon_partners<-partner_IG_tabulation[ taxon_subset, ,drop=FALSE]
                taxon_partners$partner[[ which.max(taxon_partners$x) ]]
        } else NA

}       ) %>% unlist() -> best_partners_baseRelSet

names(best_partners_baseRelSet)<- base_relevant_set[rel_freq_2D==30]

```


#### Use mean IG to estabilish true synergies

We calculate mean IG of all selected taxa so far (relevant 30 times in 1D or 2D + best partners for 2D relevant ones) to estabilish criteria for synergy:

- if the increase of IG in 2D of the 2D relevant variable is bigger than the minimal IG in 1D analysis. 


```{r}
#truly relevant (30 times in 1D or 3D) + partners
union(base_relevant_set, unname(best_partners_baseRelSet))-> overall_rel_list
  
#ugly, but necessary check:
##ensure that all resamples contain all taxa in overall_rel_list
stopifnot(
 lapply(base_resamples, function(x) 
   all(overall_rel_list %in% colnames(x$taxa_binary)) 
   ) |> unlist()  |> all() 
)


```

```{r}

mean_IG_overRuns<- function(MDFS_objects, taxa_subset, taxa_names_in_resamples){
  do.call( rbind, mapply( function(mdfs,taxa_names) 
                            mdfs$statistic[ match(overall_rel_list,taxa_names) ],
                          MDFS_objects, taxa_names_in_resamples, SIMPLIFY = FALSE
                          )
          ) |> colMeans()
}

base_resamples_present_taxa<- lapply(base_resamples, function(x)
                                      colnames(x$taxa_binary))

overall_rel_IG1D<- mean_IG_overRuns(MDFS_object_lists[[1]],
                                    overall_rel_list,
                                    base_resamples_present_taxa
                                    )
overall_rel_IG2D<- mean_IG_overRuns(MDFS_object_lists[[2]],
                                    overall_rel_list,
                                    base_resamples_present_taxa
                                    )
names(overall_rel_IG1D)<-names(overall_rel_IG2D)<-overall_rel_list
```

```{r}
# union(base_relevant_set, unname(best_partners_baseRelSet))-> overall_rel_list
# 
# #containers of mean IG
# overall_rel_IG1D<- rep(0, length(overall_rel_list))
# overall_rel_IG2D<- rep(0, length(overall_rel_list))
# names(overall_rel_IG1D)<-names(overall_rel_IG2D)<-overall_rel_list
# rel_1D_names<- names(rel_freq[rel_freq_1D==30])
# rel_2D_names<- names(rel_freq[rel_freq_2D==30])
# 
# get_IG_from_rel_names<- function(taxa_statistic, taxa_names,
#                           rel_subset_names){
#   names(taxa_statistic)<- taxa_names
#   taxa_statistic[rel_subset_names]
# }
# 
# 
# 
# for (i in seq_along(MDFS_object_lists[[1]])){
#   #taxa present in run "i"
#   resample_present_taxa<-colnames(base_resamples[[i]]$taxa_binary)
#   #found relevant in "i" and relevant 30 times overall
#   intersect(resample_present_taxa, relnames_lists[[1]][[i]]) -> rel1Dtaxa_thisRun
#   intersect(rel1Dtaxa_thisRun, rel_1D_names)-> rel1Dtaxa_thisRun
#   intersect(resample_present_taxa, relnames_lists[[2]][[i]]) -> rel2Dtaxa_thisRun
#   intersect(rel2Dtaxa_thisRun, rel_2D_names)-> rel2Dtaxa_thisRun
#   #their position in run "i"
#   match( rel1Dtaxa_thisRun, resample_present_taxa)-> rel_1D_idx
#   match( rel2Dtaxa_thisRun, resample_present_taxa)-> rel_2D_idx
#   #their IG 
#    MDFS_object_lists[[1]][[i]]$statistic[ rel_1D_idx ] -> IG_1D_resample
#    MDFS_object_lists[[2]][[i]]$statistic[ rel_2D_idx ] -> IG_2D_resample
#    stopifnot(all(rel1Dtaxa_thisRun %in% names(overall_rel_IG1D))) 
#    stopifnot(all(rel2Dtaxa_thisRun %in% names(overall_rel_IG2D))) 
#    #increase sums only for relevant variables from that run
#    overall_rel_IG1D[ rel1Dtaxa_thisRun ] = overall_rel_IG1D[ rel1Dtaxa_thisRun ] + IG_1D_resample
#    overall_rel_IG2D[ rel2Dtaxa_thisRun ] = overall_rel_IG2D[ rel2Dtaxa_thisRun ] + IG_2D_resample
# }
# #divide overall_rel_IG by the times each variable was found relevant
# times_rel_overall<- rep(1, length(overall_rel_list))
# names(times_rel_overall)<-overall_rel_list
# times_rel_overall[ names(rel_freq) ] = rel_freq
# overall_rel_IG1D<- overall_rel_IG1D/times_rel_overall
# overall_rel_IG2D<- overall_rel_IG2D/times_rel_overall
# 
# #overall_rel_IG1D[ !(overall_rel_list %in% names(rel_freq_1D)[rel_freq_1D==30]) ] =0
# #overall_rel_IG2D[ !(overall_rel_list %in% names(rel_freq_2D)[rel_freq_2D==30]) ] =0
```

```{r}
data.frame( name=overall_rel_list,
            IG1D=overall_rel_IG1D, IG2D= overall_rel_IG2D)-> ig_df
ig_df$rel_1D<- rel_freq_1D[ ig_df$name ]
ig_df$rel_2D<- rel_freq_2D[ ig_df$name ]
ig_df$rel_1D[ is.na(ig_df$rel_1D) ] = 0
ig_df$rel_2D[ is.na(ig_df$rel_2D) ] = 0
ig_df$partner_name<- best_partners_baseRelSet[ ig_df$name ]
ig_df$partner_only<- ig_df$name %in% setdiff(best_partners_baseRelSet, base_relevant_set)
synergy_thr<- min(ig_df$IG1D[ig_df$rel_1D==30])
print("minimal increase of IG in 2D analysis for estabilishing synergy:")
print(synergy_thr)
IG_increase= ig_df$IG2D - ig_df$IG1D
# find the true synergies using the thredhold and IG_increase of primary 2D rel. variable:
true_synergistic_partners<-vector(mode="character")
for (partner_only in ig_df$name[ig_df$partner_only])
{
  if (max(IG_increase[which(ig_df$partner_name== partner_only) ]) > synergy_thr)
    true_synergistic_partners[[ length(true_synergistic_partners)+1 ]] = partner_only
}

#for the rest of the analysis:
# keep taxa that were relevant 30 times in 2D or 1D and true synergistic partners.
taxa_to_keep_mask<- (ig_df$name %in% true_synergistic_partners) | 
                      (ig_df$rel_1D==30 ) | 
                      (ig_df$rel_2D==30)
ig_df<- ig_df[ taxa_to_keep_mask,]
ig_df<- ig_df[ order(-ig_df$IG2D),]
```

## Interaction plots

Based on median dataset and results of above computations, we show plots of abundance of Bergeyella vs abundance of Neisseria.

Due to zero inflation, to make the "absence" state more visble, plot visualizes zeroes (samples where one of the bacteria is absent) as values evenly distributed on a small interval around 0 (signified by grey bands).

```{r}

last.name<-function(x,sep='\\.',n=1) {
 return(unlist(lapply(strsplit(x,sep),FUN=function(x) tail(x,n))))
}

decision<-decision.mean.final

taxon2<-'sk__Bacteria.k__.p__Bacteroidetes.c__Flavobacteriia.o__Flavobacteriales.f__Flavobacteriaceae.g__Bergeyella'

for (taxon1 in c(
 'sk__Bacteria.k__.p__Proteobacteria.c__Betaproteobacteria.o__Neisseriales.f__Neisseriaceae.g__Neisseria',
 'sk__Bacteria.k__.p__Proteobacteria.c__Betaproteobacteria.o__Neisseriales.f__Neisseriaceae')
 ) {

 X1<-taxonomy.mean.final[,taxon1]
 short1<-last.name(taxon1)

 X2<-taxonomy.mean.final[,taxon2]
 short2<-last.name(taxon2)

 min1<-min(X1[X1>0])
 max1<-max(X1)
 min2<-min(X2[X2>0])
 max2<-max(X2)

 min1r<-10^floor(log10(min1))
 max1r<-10^ceiling(log10(max1))
 min2r<-10^floor(log10(min2))
 max2r<-10^ceiling(log10(max2))
 tx1<-10^(log10(min1r):log10(max1r))
 tx2<-10^(log10(min2r):log10(max2r))

 add1<-min(X1[X1>0])/2
 add2<-min(X2[X2>0])/2

 add1m<-add1/sqrt(10)
 add2m<-add2/sqrt(10)

 prop000<-sum(X1==0 & X2==0 & decision==0)/sum(X1==0 & X2==0)
 prop001<-sum(X1==0 & X2==0 & decision==1)/sum(X1==0 & X2==0)
 prop010<-sum(X1==0 & X2>0 & decision==0)/sum(X1==0 & X2>0)
 prop011<-sum(X1==0 & X2>0 & decision==1)/sum(X1==0 & X2>0)
 prop100<-sum(X1>0 & X2==0 & decision==0)/sum(X1>0 & X2==0)
 prop101<-sum(X1>0 & X2==0 & decision==1)/sum(X1>0 & X2==0)
 prop110<-sum(X1>0 & X2>0 & decision==0)/sum(X1>0 & X2>0)
prop111<-sum(X1>0 & X2>0 & decision==1)/sum(X1>0 & X2>0)
 
 x1<-X1
 x2<-X2
 x1[X1==0]<-x1[X1==0]+exp(log(add1/9)+(log(add1)-log(add1/9))*runif(length(X1[X1==0]))^(2*(!decision[X1==0])+0.5*decision[X1==0]))
 x2[X2==0]<-x2[X2==0]+exp(log(add2/9)+(log(add2)-log(add2/9))*runif(length(X2[X2==0]))^(2*(!decision[X2==0])+0.5*decision[X2==0]))
 x1[X1>0]<-x1[X1>0]+exp(runif(length(X1[X1>0]),log(add1/9),log(add1)))
 x2[X2>0]<-x2[X2>0]+exp(runif(length(X2[X2>0]),log(add2/9),log(add2)))


 bg.h<-'cyan3'
 bg.d<-'red'
 tx.h<-'black'
 tx.d<-'black'
 par(mar=c(5,5,1,1))
 plot(x1,x2,col=1+decision,type='n',log='xy',cex=1,cex.lab=1.5,
      xlim=c(add1/20,max1r),ylim=c(add2/20,max2r*2),
      xlab=short1,ylab=short2,axes=F)
 axis(1,at=c(0,tx1)+add1m,labels = c(0,tx1),cex.axis=1)
 axis(2,at=c(0,tx2)+add2m,labels = c(0,tx2),cex.axis=1)
 rect(add1/9,add2/9,add1,max2r,col='lightgray',border=NA)
 rect(add1/9,add2/9,max1r,add2,col='lightgray',border=NA)

 rect(add1,add2/25,max1r,add2/10,col=bg.d,border=NA)
 rect(add1,add2/25,max1r^prop100*add1^prop101,add2/10,col=bg.h,border=NA)
 text(sqrt(add1*max1r^prop100*add1^prop101),add2/10/sqrt(2.5),sum(X1>0 & X2==0 & decision==0),col=tx.h,cex=1)
 text(sqrt(max1r*max1r^prop100*add1^prop101),add2/10/sqrt(2.5),sum(X1>0 & X2==0 & decision==1),col=tx.d,cex=1)

 rect(add1/10,add2/25,add1,add2/10,col=bg.d,border=NA)
 rect(add1/10,add2/25,add1^prop000*(add1/10)^(prop001),add2/10,col=bg.h,border=NA)
 text(sqrt(add1/10*add1^prop000*(add1/10)^prop001),add2/10/sqrt(2.5),sum(X1==0 & X2==0 & decision==0),col=tx.h,cex=1)
 text(sqrt(add1*add1^prop000*(add1/10)^prop001),add2/10/sqrt(2.5),sum(X1==0 & X2==0 & decision==1),col=tx.d,cex=1)

 rect(add1/25,add2,add1/10,max2r,col=bg.d,border=NA)
 rect(add1/25,add2,add1/10,max2r^prop010*add2^prop011,col=bg.h,border=NA)
 text(add1/10/sqrt(2.5),sqrt(add2*add2^prop011*max2r^prop010),sum(X1==0 & X2>0 & decision==0),col=tx.h,cex=1,srt=90)
 text(add1/10/sqrt(2.5),sqrt(max2r*add2^prop011*max2r^prop010),sum(X1==0 & X2>0 & decision==1),col=tx.d,cex=1,srt=90)

 rect(add1,max2r,max1r,max2r*2.5,col=bg.d,border=NA)
 rect(add1,max2r,max1r^prop110*add1^prop111,max2r*2.5,col=bg.h,border=NA)
 text(sqrt(add1*max1r^prop110*add1^prop111),max2r*sqrt(2.5),sum(X1>0 & X2>0 & decision==0),col=tx.h,cex=1)
 text(sqrt(max1r*max1r^prop110*add1^prop111),max2r*sqrt(2.5),sum(X1>0 & X2>0 & decision==1),col=tx.d,cex=1)

 points(x1,x2,col=c(bg.h,bg.d)[1+decision],pch=19,cex=0.66)
 
  OR_01<-(sum(X1>0 & X2==0 & decision==1)/sum(X1>0 & X2==0 & decision==0))/
  (sum(!(X1>0 & X2==0) & decision==1)/sum(!(X1>0 & X2==0) & decision==0))

 print(paste('Odds ratio for',short1,'and',short2,OR_01))
}

```


## mean presence and abundance of selected taxons across 30 trials

```{r}
summary_df<- ig_df
summary_df$name-> interesting_taxa
#ensure all base_resamples have same number of rows 
stopifnot( all(
        (lapply(base_resamples, function(x) nrow(x$taxa_abundance)) %>%
            unlist() )== nrow(base_resamples[[1]]$taxa_abundance) 
              )
         )

#common basis for all interesting taxa
# (containers for sums)
A_h<-A_d<-P_h<-P_d<-P<-A<- rep(0, length(interesting_taxa))
names(P)<-names(A)<-interesting_taxa
names(P_d)<-names(A_d)<-interesting_taxa
names(P_h)<-names(A_h)<-interesting_taxa

#sum means over resamples
for (i in seq_along(base_resamples)){
    
    intr_present_resample<- intersect(interesting_taxa,
                                colnames(base_resamples[[i]]$taxa_abundance)
                                    )

    P_rsmp<-base_resamples[[i]]$taxa_binary[, intr_present_resample]
    A_rsmp<-base_resamples[[i]]$taxa_abundance[, intr_present_resample]
    y_rsmp<-base_resamples[[i]]$disease_status

    P[ intr_present_resample ] =  P[ intr_present_resample ] +
            colMeans(P_rsmp)
    A[ intr_present_resample ] =  A[ intr_present_resample ] +
            colMeans(A_rsmp)

    P_d[ intr_present_resample ] =  P_d[ intr_present_resample ] +
            colMeans(P_rsmp[y_rsmp==1,])
    A_d[ intr_present_resample ] =  A_d[ intr_present_resample ] +
            colMeans(A_rsmp[y_rsmp==1,])

    P_h[ intr_present_resample ] =  P_h[ intr_present_resample ] +
            colMeans(P_rsmp[y_rsmp==0,])
    A_h[ intr_present_resample ] =  A_h[ intr_present_resample ] +
            colMeans(A_rsmp[y_rsmp==0,])
}
#.. and divide by 30
P<-P/30
A<-A/30
P_h<-P_h/30
A_h<-A_h/30
P_d<-P_d/30
A_d<-A_d/30
summary_df$freq= P
summary_df$ab= A
summary_df$freq_d= P_d
summary_df$ab_d= A_d
summary_df$freq_h= P_h
summary_df$ab_h= A_h
viz_ig_df<- summary_df
viz_ig_df$name<- unlist(lapply(viz_ig_df$name, get_deepest_taxonomy_lvl))
viz_ig_df$partner_name<- unlist(lapply(viz_ig_df$partner_name, get_deepest_taxonomy_lvl))
rownames(viz_ig_df)<- 1:nrow(viz_ig_df)
viz_ig_df[,c(2:3) ]<-round(viz_ig_df[,c(2:3)])
viz_ig_df[,c("ab_h","ab_d","ab")]=viz_ig_df[,c("ab_h","ab_d","ab")]*10000
viz_ig_df[,8:13]=round(viz_ig_df[,8:13],2)
viz_ig_df$name[[ which(
viz_ig_df$name=="s__gamma_proteobacterium_symbiont_of_Gonopsis_affinis"
)
]]="s_gp_symb_Gon_aff"
viz_ig_df$partner_name[[ which(
  viz_ig_df$partner_name=="s__Mediterranea_massiliensis")
]]="s_Med_massiliensis"
```
## Browse end result

#### feature selection stats:

```{r}
viz_ig_df[,c("name","IG1D","IG2D","rel_1D","rel_2D","partner_name")]


```

#### mean abundance & frequency
```{r}
viz_ig_df[,c("name","freq_h","freq_d","freq",
             "ab_h","ab_d","ab")]


```


# Bootstrap resampling validation

Following initial selection of robust features relevant both in 1D and 2D, we validated the results by the use of bootstrap resampling on base resamples themselves.

From each base resample, we have drawn a boostrap resample and performed feature selection again and counted number of times selected features reappeared again as relevant.
Additionally, to test the usability of detected two dimensional interactions, we measured the average gain of AUC from random forest classifier, trained using only 1D relevant variables vs on the whole set of 1D and 2D relevant features.



## Preparation of bootstrap samples (by sampling indexes)

```{r}
N_TRIALS=30
keep_frac<-1

n1<-  sum(base_resamples[[1]]$disease_status==1)
n0<-  sum(base_resamples[[1]]$disease_status==0)

n1k<- ceiling(n1*keep_frac)
n0k<- ceiling(n0*keep_frac)

#list of 30
set.seed(32523)
B_idx<- lapply(1:N_TRIALS,
                       function(B)
                       {
                         y<-base_resamples[[B]]$disease_status
                         
                         idx_1= which(y==1)
                         idx_0= which(y==0)
                         c( sample(idx_1, n1k, replace=TRUE),
                        sample(idx_0, n0k, replace=TRUE)
                         )
                       }
                      )
#saveRDS(B_idx,"Bootstrap_IDX.rds")

```

## Feature selection and RF

We save results of each run in subdirectories `MDFS_results`, `RF_models` and calculate mean metrics after all computation is done.

```{r}
library(randomForest)
library(pROC)
#prepare list of seeds per each bootstrap for reproducibility
set.seed(32432)
session_seeds<- sample.int(323423,N_TRIALS)
    summary_df$name[summary_df$rel_1D==30] -> consensus_1D
    summary_df$name -> consensus_AllRelevant
for (B in 1:N_TRIALS) {
    IDX_B<-  B_idx[[B]]
    set_B<- base_resamples[[B]]
    set.seed(session_seeds[[B]])
#FS
   if (!file.exists( sprintf("MDFS_results/MDFS_replicate_%d.rds", B ) ) ) {
     gc()
    MDFS_1D<- MDFS.discrete(
    data = set_B$taxa_binary[IDX_B,],
    decision = set_B$disease_status[IDX_B],
    dimensions = 1,
    seed= session_seeds[[B]], 
    level = 0.05
    )
    rel_1D<- colnames(set_B$taxa_binary)[MDFS_1D$relevant.variables]
    # Perform MDFS with 2D
    gc()
    MDFS_2D<- MDFS(
    data = set_B$taxa_binary[IDX_B,],
    decision = set_B$disease_status[IDX_B],
    dimensions = 2,
    seed = session_seeds[[B]],
    level = 0.05
    )
    rel_2D<- colnames(set_B$taxa_binary)[MDFS_2D$relevant.variables]
    rel_1or2D<-  union( rel_1D, rel_2D)  
    FS<- list(rel_1D= rel_1D,
            rel_2D= rel_2D,
            rel_1or2D=rel_1or2D)
    saveRDS( FS, sprintf("MDFS_results/FS_replicate_%d.rds", B ) )
    saveRDS( list(MDFS_1D=MDFS_1D,
                MDFS_2D=MDFS_2D),
            sprintf("MDFS_results/MDFS_replicate_%d.rds", B ) )
	}
            

    #RF
	if ( ! file.exists( sprintf("RF_models/RF_replicate_%d.rds",B)) ) {
    unique(IDX_B)-> uqIDX_B
	  gc()
    set.seed(session_seeds[[B]])
    randomForest(x = set_B$taxa_binary[uqIDX_B, consensus_1D],
                y =  as.factor(set_B$disease_status[uqIDX_B]),
                importance = TRUE,
                keep.forest = TRUE)-> RF_1D
    gc()
    set.seed(session_seeds[[B]])
    randomForest(x = set_B$taxa_binary[uqIDX_B, consensus_AllRelevant],
                y =  as.factor(set_B$disease_status[uqIDX_B]),
                importance = TRUE,
                keep.forest = TRUE)-> RF_all
    saveRDS(list(RF_1D=RF_1D,
                RF_all=RF_all),
            sprintf("RF_models/RF_replicate_%d.rds", B)
    )
	}
    message(sprintf("%d/%d done", B, N_TRIALS))
}
```

### Aggregation of results

#### Count how many times relevant features showed up again and compute mean random forest metrics
```{r}
library(pROC)
source("balanced_decision.R")
#filename patterns for reading the results
fs_fpattern<-"MDFS_results/FS_replicate_%d.rds"
mdfs_fpattern<-"MDFS_results/MDFS_replicate_%d.rds"
rf_fpattern<- "RF_models/RF_replicate_%d.rds" 

#containers:
rel_2D_trials<-rel_1D_trials<- list()  #for indicators of relevance per each run
CM1_trials<-CMall_trials<-  list() #for confusion matrices
RF1_trials<- RFall_trials<-list() #for RF performance metrics

#auxiliary oods ratio computation
odds_ratio<- function(CM) {(CM[2,2]*CM[1,1])/(CM[1,2]*CM[2,1]) } 

for (B in 1:N_TRIALS){

B_tnames<-colnames(base_resamples[[B]]$taxa_abundance)
B_P<- base_resamples[[B]]$taxa_binary #presence
B_A<- base_resamples[[B]]$taxa_abundance #presence
B_y<- base_resamples[[B]]$disease_status


#indexes of resampled and oob subjects
B_IDX<- B_idx[[B]]
B_oob<- setdiff( 1:nrow(B_A), unique(B_IDX))

B_fs_fname<- sprintf( fs_fpattern, B)
B_FS<- readRDS( B_fs_fname)

#relevance indicators
rel_1D_trials[[B]]= 1.*(consensus_AllRelevant %in% B_FS$rel_1D)
rel_2D_trials[[B]]= 1.*(consensus_AllRelevant %in% B_FS$rel_2D)

#RF prediction on OOB

B_fs_fname<- sprintf( fs_fpattern, B)
B_rf_fname<- sprintf( rf_fpattern, B)
B_RF<- readRDS(B_rf_fname)$RF_all
B_RF1<- readRDS(B_rf_fname)$RF_1D


#predicted probabilities
B_RFall_prob<- predict( B_RF, newdata= B_P[B_oob,], type="prob")[,2]
B_RF1_prob<- predict( B_RF1, newdata= B_P[B_oob,], type="prob")[,2]


B_yoob<- B_y[B_oob]

#predicted classes
B_RFall_cl<-  balanced.decision(B_RFall_prob,as.factor(B_yoob))$decision
B_RF1_cl<- balanced.decision(B_RF1_prob,as.factor(B_yoob))$decision

#confusion matrices
cm_all<- table(Predicted=B_RFall_cl,Actual=B_yoob)
cm_1<- table(Predicted=B_RF1_cl,Actual=B_yoob)

CM1_trials[[B]]<- cm_1
CMall_trials[[B]]<- cm_all


RFall_score<- c(auc= auc(response=B_yoob, predictor= B_RFall_prob,quiet=TRUE),
		OR=odds_ratio(cm_all),
		acc= sum( B_yoob == B_RFall_cl)/length(B_yoob)
)
RF1_score<- c(auc= auc(response=B_yoob, predictor= B_RF1_prob,quiet=TRUE),
	      OR=odds_ratio(cm_1),
		acc= sum( B_yoob == B_RF1_cl)/length(B_yoob)
	      )

RF1_trials[[B]]<- RF1_score
RFall_trials[[B]]<- RFall_score
message(sprintf("%d/%d done", B, N_TRIALS))

}


print("mean stats and SDs for RF on 1D:")
print(colMeans(do.call(rbind,RF1_trials)) )
print(colSds(do.call(rbind,RF1_trials)) )
print("confustuon matrix for all trials of RF on 1D:")
mean_CM_1D<- Reduce("+", CM1_trials)
print(mean_CM_1D)

print("mean stats for RF on 1,2D and partners:")
print(colMeans(do.call(rbind,RFall_trials)) )
print(colSds(do.call(rbind,RFall_trials)) )
print("confusion matrix for all trials of RF on 1, 2D and partners:")
mean_CM_all<- Reduce("+", CMall_trials)
print(mean_CM_all)

#reappearance as relevant in BS per each feature
Reduce("+", rel_1D_trials)->times_rel1D_BS
Reduce("+", rel_2D_trials)->times_rel2D_BS

names(times_rel1D_BS)<- names(times_rel2D_BS)<- consensus_AllRelevant

```

### Check the plausibility of initial feature set:

```{r}

summary_df$BS_rel1D= times_rel1D_BS[ summary_df$name ]
summary_df$BS_rel2D= times_rel2D_BS[ summary_df$name ]
viz_df<-summary_df
viz_df$name<- unlist(lapply(summary_df$name, get_deepest_taxonomy_lvl))
rownames(viz_df)<-NULL
viz_df$name[[ which(
viz_df$name=="s__gamma_proteobacterium_symbiont_of_Gonopsis_affinis"
)
]]="s_gp_symb_Gon_aff"
viz_df[, c("name","rel_1D","BS_rel1D")]
```

```{r}

viz_df[, c("name","rel_2D","BS_rel2D")]

```

# Comparison with SOTA

We ran the similar 2-phase resampling based procedure of feature selection, taking U-test as the feature selector, utilizing the same criteria in terms of level of significance and p-value adjustment (0.05 with holm method correction).

Note that we should not expect purely synergistic taxa to appear in the result of the U-test as it is purely an univariate test.
In contrast, MDFS can identify features that are not relevant for disease status by themselves.

#### Streamlined process for U-test

Sourced script contains the essential steps needed for estabilishing feature sets found in base resamples and bootstrap validation sets and can work for any feature selection method which is formulated with the same convention as below U-test example function:

- it should accept as necessary input parameters, feature table and response vector
- it should return a list with fields `p.value`, `adjusted.p.value`, `relevant.variables` and `rel_set` (names of relevant taxa) containing the result
- optional parameters `lvl`, `p.adjust.method` should control determination of relevant features from raw p-values (if the feature selection method is a statistical filter).



```{r}
source("resample_FS_procedure.R")
U_test_FS
U_test_FS(base_resamples[[1]]$taxa_abundance, decision = base_resamples[[1]]$disease_status)->xx
```

```{r}
resample_FS_procedure(List_base_resamples = base_resamples,
                      List_bootrap_indexes = B_idx, #list of bootstrap indexes 
                      FS_function = U_test_FS,
                      FS_on_binary = FALSE, #do FS on taxa_binary or taxa_abundance
                      lvl=0.05,
                      p.adjust.method = "holm"
                      )-> U_test_rel_Taxa
```

#### Compare with MDFS

```{r}
union(summary_df$name, U_test_rel_Taxa$feature_name)-> taxa_by_any_method
data.frame(name=taxa_by_any_method,
           `MDFS_1D`=taxa_by_any_method %in% summary_df$name[summary_df$rel_1D==30],
           `MDFS_2D`=taxa_by_any_method %in% summary_df$name[summary_df$rel_2D==30],
            `U_test`=taxa_by_any_method %in% U_test_rel_Taxa$feature_name[U_test_rel_Taxa$n_rel_base==30])-> df_base
df_base[["MDFS_2D_only"]]= df_base[["MDFS_2D"]] & (!df_base[["MDFS_1D"]])
head(df_base)
```

First, we can see that none of the features relevant in 2D only appear in univariate U_test.



```{r}
print(sum(df_base[df_base$MDFS_2D_only,"U_test"]))
head(df_base[df_base$MDFS_2D_only,])
```


Second, we can examine the intersection between MDFS 1D, 2D and U-test:

```{r}

generate_crosstab <- function(df) {
  # Create an empty matrix to store the cross tabulation
  crosstab_matrix <- matrix(0, nrow = 4, ncol = 4)
  colnames(crosstab_matrix) <-colnames(df)
  rownames(crosstab_matrix) <- colnames(df)
  
  # Iterate over all pairs of columns
  for (col1 in colnames(df)) {
    for (col2 in colnames(df)) {
      # Calculate the number of times both columns have TRUE in the same row
      count <- sum(df[[col1]] & df[[col2]], na.rm = TRUE)
      # Update the crosstab matrix
      crosstab_matrix[col1, col2] <- count
    }
  }
  crosstab_matrix
}
  
generate_crosstab(df_base[,2:ncol(df_base)])
```

```{r}
df_bs<- df_base[,1:(ncol(df_base)-1)]
print(nrow(df_bs))
df_bs<- df_bs[ rowSums(df_bs[,2:ncol(df_bs)])>0 ,]
print(nrow(df_bs))
for (name in colnames(df_bs)[2:ncol(df_bs)]) df_bs[[name]]= 0

sdf<-summary_df[summary_df$name %in% df_bs$name, ]
 df_bs[["MDFS_1D"]][ 
  match(sdf$name,df_bs$name) ]= sdf$rel_1D
 df_bs[["MDFS_2D"]][ 
  match(sdf$name,df_bs$name) ]= sdf$rel_2D
 
 udf<-U_test_rel_Taxa[U_test_rel_Taxa$feature_name %in% df_bs$name,]
 df_bs[["U_test"]][
   match(udf$feature_name,df_bs$name)
 ]= udf$n_rel_bs


crosstab_at_thr<- function(df, thr1,thr2=NULL){
  df<-df[,2:ncol(df)]
  df_b<-df
  df_b[,]=FALSE
  df_b[df>=thr1]= TRUE
  if (!is.null(thr2)) df_b[ df >= thr2 ] = FALSE
  df_b[["MDFS_2D_only"]]=df_b[["MDFS_2D"]] & (!df_b[["MDFS_1D"]])
  generate_crosstab(df_b)
}
print("confirmed set:")
crosstab_at_thr(df_bs,30)
print("plausible set:")
crosstab_at_thr(df_bs,27,30)
print("rejected set:")
crosstab_at_thr(df_bs,1,27)
```


### Does binarization affect the result?

```{r}
source("draw_once_per_host2.R")
y<- 1- metadata$allergic.to.i.have.no.food.allergies.that.i.know.of 
names(y)<- rownames(metadata)
library(matrixStats)
host_id<- metadata$host.subject.id
names(host_id)<- rownames(metadata)
base_resamples_0bin<-list()
if (!file.exists("base_resamples_0bin.rds")){
for (i in 1:30){
  gc()
  set.seed(i)
draw_once_per_host(taxonomy=tdata, disease = y, host_id = host_id, binarize_on_median = FALSE,
                   min_minority_class_taxa =20, min_minority_class_dis = 30,print_summary = FALSE,
                   report_progess = TRUE)->base_resamples_0bin[[i]]
message(sprintf("%d/30 done",i))
}
saveRDS(base_resamples_0bin, "base_resamples_0bin.rds") } else {
  base_resamples_0bin<-readRDS("base_resamples_0bin.rds")
}

```


```{r}
#ensure that we have the same donors in two approaches
stopifnot(all(
mapply(function(r1,r2) all(r1$host_id==r2$host_id), base_resamples,
       base_resamples_0bin)
))
```

```{r}
#do all taxa pass min. minority class filter the same?
all(
mapply(function(r1,r2) all(colnames(r1$taxa_binary)==colnames(r2$taxa_binary)), base_resamples,
       base_resamples_0bin)
)
```

```{r}
#how many variables differ betwen methods
columns_equal<- function(df1,df2) mapply(function(COL1,COL2) all(COL1==COL2),df1,df2 )
do.call(rbind,mapply(function(r1,r2) c(sum(columns_equal(r1$taxa_binary,r2$taxa_binary)),
                         ncol(r1$taxa_binary)), base_resamples,base_resamples_0bin,
       SIMPLIFY=FALSE))
```

```{r}
which_cols_differ<- function(df1,df2) mapply(function(COL1,COL2) 
   !all(COL1==COL2) ,df1,df2 )
Reduce(union,mapply(function(r1,r2) colnames(r1$taxa_binary)[which_cols_differ(r1$taxa_binary,
                                                                               r2$taxa_binary)], base_resamples,base_resamples_0bin,
       SIMPLIFY=FALSE))-> common_taxa
```

```{r}
plot(unname(colSums(tdata[,common_taxa]>0)/nrow(tdata)) |> sort(),
     main="% of non zero cells for common variables")
```

```{r}
unname(-colSums(tdata[,common_taxa]>0)+nrow(tdata))
```

### MDFS 3D test

Run on median dataset, done on HPC cluster using `mdfs_3d_test.R` script.

```{r}
readRDS("MDFS_3D_result.rds")-> MDFS_3D

colnames(taxonomy.mean.final)[MDFS_3D$relevant.variables]-> taxa_3D

setdiff(taxa_3D,any_times_relevant_taxa)-> taxa_3D_ONLY
```

```{r}

union(taxa_3D, base_relevant_set)-> all_relevant_123D

MDFS_3D$statistic-> stat_3D
colnames(taxonomy.mean.final)->names(stat_3D)

rel_1D_only<- names(rel_freq_1D)[(rel_freq_1D==30) & (rel_freq_2D<30)]
rel_2D_only<- names(rel_freq_1D)[(rel_freq_2D==30)]
rel_3D_only<- setdiff(all_relevant_123D, any_times_relevant_taxa)

plot_colors<- ifelse(all_relevant_123D %in% rel_1D_only, "red",
                     ifelse(all_relevant_123D %in% rel_2D_only, "blue",
                            ifelse(all_relevant_123D %in% rel_3D_only, "green", "gray")))

stat_3D[all_relevant_123D]-> stat_3D_plot
order(-stat_3D_plot)->order_3D
stat_3D_plot<-stat_3D_plot[order_3D]
plot_colors<-plot_colors[order_3D]

names(stat_3D_plot)<- lapply(names(stat_3D_plot), get_deepest_taxonomy_lvl) |> unlist()
par(mar = c(8, 4, 4, 2))  # Adjust the margin on the bottom (first value)
barplot(stat_3D_plot[1:30], main="MDFS 3D statistics for relevant taxa",
        col = plot_colors[1:30],
        las=3,cex.names = 0.65, ylab="IG (3D)")
legend("topright", pch=15, col=c("blue","green"), legend=c("2D relevant","3D only"))
abline(h=80, lty="dotted")
abline(h=70, lty="dotted")
abline(h=90, lty="dotted")
abline(h=60, lty="dotted")
abline(h=50, lty="dotted")

```

####Compare with U-test

```{r}
intersect(setdiff(taxa_3D,any_times_relevant_taxa), xx$rel_set)-> only_3D_but_Utest
unname(cbind(stat_3D[only_3D_but_Utest],
      lapply(only_3D_but_Utest, get_deepest_taxonomy_lvl) |> unlist(),
      xx$adjusted.p.value[xx$relevant.variables][match(only_3D_but_Utest,xx$rel_set)]))->df_comparison

colnames(df_comparison)<- c("IG","taxon","U_test.adjusted.p.value")
      df_comparison


```
```{r}
x=base_resamples[[1]]$taxa_abundance[,"sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"]
 y=base_resamples[[1]]$disease_status
 x[(y==0)&(x!=0)]->x0
 x[(y==1)&(x!=0)]->x1
 range(c(x0,x1))->x01rng
 seq(from=x01rng[[1]],to=x01rng[[2]],length.out=20)->brks
 hist(x[(y==0)&(x!=0)], plot=FALSE,breaks=brks)->h1
 hist(x[(y==1)&(x!=0)], plot=FALSE,breaks=brks)->h2
 plot(h2$mids, h2$counts, lwd=2, type="line", col="green",log='y')
 lines(h1$mids, h1$counts, lwd=2, col="red")
```

#### Redo 2D analysis on median dataset

```{r}
library(MDFS)
base_resamples<-readRDS("base_resamples.rds")
 MDFS_1D_result_ab <- MDFS(
    data = base_resamples[[1]]$taxa_abundance, #taxonomy.mean.final, # 
    decision = base_resamples[[1]]$disease_status, #decision.mean.final, 
    dimensions = 1,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed = 1,
    level = 0.05
  )
  MDFS_1D_result_bin <- MDFS(
    data = base_resamples[[1]]$taxa_binary, #taxonomy.mean.final, # 
    decision = base_resamples[[1]]$disease_status, #decision.mean.final, 
    dimensions = 1,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed = 1,
    level = 0.05
  )

```

#### MDFS::Discretize at fault?

```{r}
base_data<- base_resamples[[1]]
pseudomonas_name<-"sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"

MDFS::Discretize(base_data$taxa_abundance,
                 variable.idx = which(colnames(base_data$taxa_abundance)==
                                  pseudomonas_name),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_ab_MDFS_discretized # dyskretyzowane abundance z MDFS


pseudomonas_bin_median_discr<- base_resamples[[1]]$taxa_binary[,pseudomonas_name] # dyskretyzowane binarnie z miediany


print("MDFS abundance binarized vs manual median binarized")
print(
table(pseudomonas_bin_median_discr, pseudomonas_ab_MDFS_discretized)
)



# binarny wstawiony w MDFS::Discretize
MDFS::Discretize(base_data$taxa_binary,
                 variable.idx = which(colnames(base_data$taxa_abundance)==
                                  pseudomonas_name),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_bin_MDFS_discretized # dyskretyzowane abundance z MDFS



print("MDFS::Discretize(median binarized variable) vs manual median binarized")
print(
table(pseudomonas_bin_median_discr, pseudomonas_bin_MDFS_discretized)
)



```

```{r}
pseudomonas_name %in% colnames(base_resamples[[1]]$taxa_binary)[MDFS_1D_result_ab$relevant.variables]
pseudomonas_name %in% colnames(base_resamples[[1]]$taxa_binary)[MDFS_1D_result_bin$relevant.variables]


```
```{r}
 colnames(base_resamples[[1]]$taxa_binary)-> b1_tnames
MDFS_1D_result_ab$statistic[MDFS_1D_result_ab$relevant.variables]-> b1_stat_ab
MDFS_1D_result_bin$statistic[MDFS_1D_result_ab$relevant.variables]-> b1_stat_bin
data.frame(ab=round(b1_stat_ab,4),bin=round(b1_stat_bin,4),name=lapply(b1_tnames[MDFS_1D_result_ab$relevant.variables], 
                                    get_deepest_taxonomy_lvl) |> unlist())->df_ab_vs_bin_stat

df_ab_vs_bin_stat[order(-df_ab_vs_bin_stat$ab),]

```



```{r}
MDFS::Discretize(base_resamples[[1]]$taxa_abundance,
                 variable.idx = which(colnames(base_resamples[[1]]$taxa_abundance)==
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_MDFS_discr
```

```{r}
MDFS::Discretize(base_resamples[[1]]$taxa_binary,
                 variable.idx = which(colnames(base_resamples[[1]]$taxa_abundance)==
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_bin_MDFS_discr

```


```{r}
base_resamples[[1]]$taxa_binary[,
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"]->pseudomonas_bin
```

```{r}
base_resamples[[1]]$taxa_abundance[,
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"]->pseudomonas_ab
```

```{r}

table(pseudomonas_bin, pseudomonas_MDFS_discr)
table(pseudomonas_bin, pseudomonas_bin_MDFS_discr)

```

```{r}

colnames(base_resamples[[1]]$taxa_binary)[MDFS_2D_result_mean$relevant.variables]
#colnames(taxonomy.mean.final)[MDFS_2D_result_mean$relevant.variables]


```

### Different subtypes of food allergy


Main steps of the pipeline are contained in `resampled_MDFS_analysis.R` and include:

- resampling of the dataset - picking 1 sample per each repeating donor
- adjustment for the decision variable used - removal of variables with low counts in one of the classes
- feature selection using MDFS
- selection of consistently relevant taxa
- picking of the best partners for the relevant taxa


```{r}
decisions=c("allergic_to_peanuts", "allergic_to_shellfish", "allergic_to_tree_nuts")
decision_results<- list()
source("resampled_MDFS_analysis.R")
for (i in seq_along(decisions)){
  set.seed(i)
seeds<-sample.int(343242,30)
print(sprintf("working on %s",decisions[[i]]))
resample_MDFS(metadata = metadata, taxonomy = tdata, 
              decision_colname=decisions[[i]],
			         n_resamples=30,
			         seeds=seeds,
			          host_id_colname="host.subject.id",
			            #passed to draw_once_per_host
                   	 min_minority_class_taxa =20, 
			            min_minority_class_dis = 30,
			          binarize_on_median=TRUE,
			          print_summary = FALSE,
                report_progess = TRUE)-> decision_results[[i]]
}
```