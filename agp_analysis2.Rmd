---
title: "Information Theory and Machine Learning Reveal Synergistic Interactions in
  Gut Microbiota Related to Food Allergy - data analysis pipeline"
output:
  html_document:
    toc: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Initial data preparation

Read the raw taxonomy abundance info and metadata from delimiter separated files.

```{r read}
metadata.filename <- "metadata.csv"
taxa.filename <- "taxa.tsv"
tdata <- as.data.frame(t(read.delim(taxa.filename, header = TRUE, sep = "\t")))
colnames(tdata) <- tdata[1,]
tdata <- tdata[-1,]

metadata<-read.csv(metadata.filename, header = TRUE, sep = ",")
rownames(metadata)<-metadata[,1]
metadata<-metadata[,-1]

```

## Filtering of erroneus data


```{r}
library(magrittr)
c("sex","height.cm","weight.kg","age.years")-> confounding_factors
confounding_factors %in% colnames(metadata)
metadata$sex[!(metadata$sex %in% c("male","female"))]<- NA
metadata$height[metadata$height.cm<38]<-NA
metadata$weight[metadata$weight.kg<1]<-NA
metadata$age_years[metadata$age.years<=0]<-NA
metadata$height[metadata$height.cm>220]<-NA
metadata$weight[metadata$weight.kg<=1]<-NA
metadata$weight[metadata$weight.kg>200]<-NA
to_remove_mask <- (metadata[,confounding_factors] %>% is.na() %>% rowSums()) > 0
metadata<-metadata[!to_remove_mask, ]
```

### Taxa table preparation 

#### Bacteria selection and stool samples filtering

```{r}
#1. skip non bacterial taxa
tdata<- tdata[, grep('sk__Bacteria', colnames(tdata)) ]
print("inital number of taxa samples")
print(nrow(tdata))
#2. keep stool samples
metadata$env_material-> sample_source
feces_rownames<- rownames(metadata)[ sample_source=="feces" ]
tdata<-tdata[ intersect(rownames(tdata),feces_rownames),] 
print("number of taxa samples from stool")
print(nrow(tdata))
```

#### Alpha diversity analysis and normalization

Normalize abundancies and use proportions to calculate 3 versions of alpha diversity indexes. Below plots show values of alpha diversity as a function of the rank of cumulative count of each sample.
Investigation suggests a common cutoff point, which corresponds to minimum cumulative count of `3636`.

```{r}
  t_rownames<- rownames(tdata)
  tdata<- lapply(tdata, as.numeric) %>% as.data.frame()
  rownames(tdata)<- t_rownames
  lib_sizes<- rowSums(tdata) 
  t_props<-( tdata
            )/lib_sizes #due to R recycling, each row gets divided by its sum
  shannon_div<- -rowSums((t_props+1e-10)*log(t_props+1e-10))
  simpson_index<- rowSums ( 1 - t_props^2  )
  inverse_simp<- 1/rowSums( t_props^2 )
  size_order<-order(lib_sizes)

  taxa_min_lib_size= 3636 
  crit_rank= which.min(abs(lib_sizes[size_order] - taxa_min_lib_size))

  plot(shannon_div[size_order],type='l')
  abline(v = crit_rank, col="red",lwd=2) 
  plot(simpson_index[size_order],type='l')
  abline(v = crit_rank, col="red",lwd=2) 
  plot(inverse_simp[size_order],type='l')
  abline(v = crit_rank, col="red",lwd=2) 


  tdata<- tdata[ rowSums(tdata) >= taxa_min_lib_size, ]
  tdata<- tdata/rowSums(tdata)
```

### Integrate two types of information and prepare data for base resampling procedure


```{r}
common_names<- intersect(rownames(metadata), rownames(tdata))
tdata<- tdata[common_names,]
metadata<-metadata[common_names,]
print("# of samples left after filtering by alpha diversity (with repeating donors)")
print(length(common_names))
print("# of unique donors")
print(length(unique(metadata$host.subject.id)))
```

## Median dataset and cohort summary


```{r}
y<- 1- metadata$allergic.to.i.have.no.food.allergies.that.i.know.of 
names(y)<- rownames(metadata)
library(matrixStats)

ids<-metadata$host.subject.id
names(ids)<-rownames(metadata)

donors<-unique(ids)

taxonomy.mean<-matrix(NA,length(donors),ncol(tdata))
rownames(taxonomy.mean)<-donors
colnames(taxonomy.mean)<-colnames(tdata)
meta.mean<-as.data.frame(matrix(NA,length(donors),6))
rownames(meta.mean)<-donors
colnames(meta.mean)<-c('age','sex','weight.kg','height.cm','BMI_cat','age_cat')
decision.mean<-numeric(length(donors))
names(decision.mean)<-donors

if (!file.exists("mean_data.RData")){
for (i in 1:length(donors)) {
 donor<-donors[i]
 samples<-names(ids)[ids==donor]
 
 #decision
 decs<-y[samples]
 decision.mean[i]<-floor(median(decs))
 
 #taxa
 taxa<-tdata[samples,,drop=F]
 taxonomy.mean[i,]<-colMedians(as.matrix(taxa))
 
 #metadata
 #age
 ages<-metadata[samples,'age.years']
 ages<-ages[!is.na(ages)]
 if (length(ages)>0) meta.mean[i,1]<-round(median(ages))
 #sex
 sexes<-metadata[samples,'sex']
 sexes<-sexes[!is.na(sexes)]
 if (length(sexes)>0) meta.mean[i,2]<-names(table(sexes))[which.max(table(sexes))]
 #weight
 weights<-as.numeric(metadata[samples,'weight.kg'])
 weights<-weights[!is.na(weights)]
 if (length(weights)>0) meta.mean[i,3]<-median(weights)
 #height
 heights<-as.numeric(metadata[samples,'height.cm'])
 heights<-heights[!is.na(heights)]
 if (length(heights)>0) meta.mean[i,4]<-median(heights)
 
 
 if(!((i-1)%%500)) print(sprintf("median data computation... %d / %d done",i, length(donors)))
}

mask.meta<-rowSums(is.na(meta.mean[,1:4]))==0

meta.mean.final<-meta.mean[mask.meta,]
meta.mean.final[meta.mean.final[1]<15,6]<-'0-14'
meta.mean.final[meta.mean.final[1]>=15 & meta.mean.final[1]<64,6]<-'15-64'
meta.mean.final[meta.mean.final[1]>=64,6]<-'65+'
bmi<-meta.mean.final[,'weight.kg']/meta.mean.final[,'height.cm']^2*10000
meta.mean.final[bmi<18.5,5]<-'Underweight'
meta.mean.final[bmi>=18.5 & bmi<25,5]<-'Normal'
meta.mean.final[bmi>=25 & bmi<30,5]<-'Overweight'
meta.mean.final[bmi>=30,5]<-'Obese'


decision.mean.final<-decision.mean[mask.meta]
taxonomy.mean.final<-taxonomy.mean[mask.meta,]
taxonomy.mean.final<-taxonomy.mean.final[,colSums(taxonomy.mean.final>0)>20]
taxonomy.mean.final<-as.data.frame(taxonomy.mean.final/rowSums(taxonomy.mean.final)*10000)

binary.mean.final<-taxonomy.mean.final*0
for (i in 1:ncol(binary.mean.final)) binary.mean.final[,i]<-taxonomy.mean.final[,i]>median(taxonomy.mean.final[,i])

save(meta.mean.final,decision.mean.final,taxonomy.mean.final,binary.mean.final,file='mean_data.RData')
} else {load("mean_data.RData")}


#Table 1 
table(decision.mean.final)

table(meta.mean.final[decision.mean.final==0,2])
table(meta.mean.final[decision.mean.final==1,2])

fisher.test(rbind(table(meta.mean.final[decision.mean.final==0,2]),
            table(meta.mean.final[decision.mean.final==1,2])))
            

table(meta.mean.final[decision.mean.final==0,6])
table(meta.mean.final[decision.mean.final==1,6])

fisher.test(rbind(table(meta.mean.final[decision.mean.final==0,6]),
                  table(meta.mean.final[decision.mean.final==1,6])))#,simulate.p.value = T)


table(meta.mean.final[decision.mean.final==0,5])
table(meta.mean.final[decision.mean.final==1,5])

fisher.test(rbind(table(meta.mean.final[decision.mean.final==0,5]),
                  table(meta.mean.final[decision.mean.final==1,5])))



```

## Base resamples construction

Function `draw_once_per_host` does following things:

- draws one sample from each unique donor which has submitted more than one sample

- binarizes taxa by their median value, setting values bigger than median to 1

- filters out sparse taxa according to `min_minority_class_taxa`

```{r}
source("subsample_nonrepeating_donors.R")
host_id<- metadata$host.subject.id
names(host_id)<- rownames(metadata)
subsample<-list()
n_repeats=500
if (!file.exists("agp_subsamples.rds")){
for (i in 1:n_repeats){
  set.seed(i)
  subsample_donors(taxonomy=tdata, disease=y,
                   host_id=host_id,
                   subsampleSize = 0.8,
                   print_summary = FALSE
                   )-> subsample[[i]]
if (i%% 50==0) message(sprintf("%d/500 done",i))
}
  invisible()
saveRDS(subsample, "agp_subsamples.rds") 
} else {
  subsample<-readRDS("agp_subsamples.rds")
}
```


## Feature selection

### MDFS

Perform discrete variant of MDFS in 1D and 2D mode on each of the prepared base resamples.

whole procedure from discretization up to feature selection is encapsulated in one function `MDFS_FS`, that performs discrete version of MDFS in 2D and 1D on either of the binarization methods (by zero `0` or by median `m`). 
Respective results are stored in the sublists:

- `res_1D0`, `res_2D0`, `res_2Dm`, `res_1Dm`.

Results include also a set of "synergistic partners" - taxa that were found to contribute to the information gain of other taxa relevant in 2D analysis, but not relevant by themselves.
For practical pruposes, we limit this set by thresholding on increase of IG of the taxa the pure partners were found relevant with, as we go from 1D to 2D statistic. 
Specifically, we report only those that had increased IG of their 2D relevant partners by at least the minimum value of 1D IG observed among the taxa relevant in 1D.

### U-test

Similar wrapper was prepared for Wilcoxon's test (`U_test_FS` function). Obviously, we do not have any 2D interactions here.

### Resampling validation

We validate the results of feature selection by multiple repeats (500) of leave x% out subsampling (jackknife). 
For each of the subsampled datasets $\mathbf{X^*}, y^*$, where $\mathbf{X^*}$ are taxa abundances and $y^*$ is the disease status of interest, we perform U-test and MDFS based feature selection.
The taxa from the selection procedure are then used to train the random forest classifiers, which are then evaluated on left out data (from this specific realisation of subsampling).

For MDFS analysis, we compare 3 sets of features per repeat:

- variables relevant in 1D only,
- relevant in 2D and 1D,
- relevant in 1D and 2D + synergistic partners.

We say here that a feature is relevant if it was found by a test based on either of discretization methods, by median or by zero.

Below code executes the validation for both of the procedures (takes around 6h to evaluate). 
Detailed steps of MDFS pipeline implemented in `MDFS_FS()` function are described later, using one example repeat of the validation.


```{r}
subsample<- readRDS("agp_subsamples63.rds")
n_repeats=500
library(MDFS)
source("FS_functions.R")
features_file_string="features/agp_features_selected_lop=%.2f.rds"
lop= 0.37 #leave out percentage
library(randomForest)

#if feature selection was not performed yet, set up the lists
fs_fname=sprintf(features_file_string,lop)
if (!file.exists(fs_fname)) {
features<- list(md1D=list(),
                md12D=list(),
                md12Dp=list(),
                u=list()
                )

} else { # otherwise load the saved result
  features<-readRDS(fs_fname)
}

set.seed(123)
seeds= sample.int(234234,n_repeats)

fs_j_pattern="features/agp_fs_set_j=%d_lop=%.2f.rds"
 full_MDFSres<- full_Ures<-list()
for (j in 1:n_repeats){
  fs_j_fname= sprintf(fs_j_pattern,j,lop)
  if(!file.exists(fs_j_fname)){
    message(fs_j_fname)
      set.seed(seeds[[j]])
      MDFS_FS(X= tdata[ subsample[[j]]$keep, ], 
              y= y[ subsample[[j]]$keep ], lvl=0.05, p.adjust.method = "holm",
              seed= seeds[[j]],
              mc=30 #minimum allowed class size of binarized taxa abundance
              )-> all_mdfs_j
      U_test_FS(X=tdata[ subsample[[j]]$keep, ],
                y = y[ subsample[[j]]$keep ],
                lvl = 0.05,
                p.adjust.method = "holm")->u_j
      fs_j=list(mdfs=all_mdfs_j, u=u_j)
      saveRDS(fs_j, fs_j_fname)
      } else {
        fs_j=readRDS(fs_j_fname)
        all_mdfs_j=fs_j$mdfs
        u_j=fs_j$u
  }
  
  full_MDFSres[[j]]=all_mdfs_j
  full_Ures[[j]]=u_j
  if (!file.exists(features_file_string)){
            features$u[[j]]=u_j$rel_set
            features$md1D[[j]]=union(all_mdfs_j$res_1Dm$rel_set, all_mdfs_j$res_1D0$rel_set)
            features$md12D[[j]]=Reduce(union, list(all_mdfs_j$res_2Dm$rel_set, 
                                                  all_mdfs_j$res_2D0$rel_set,
                                                  features$md1D[[j]]))
            features$md12Dp[[j]]=Reduce(union, list(all_mdfs_j$res_2Dm$partner_set, 
                                                  all_mdfs_j$res_2D0$partner_set,
                                                  features$md12D[[j]]))
          }
  model_file_string="RF_models/agp_j=%d_fs=%s_lop=%.2f.rds"
  for (fs_method in c(names(features),"md12DpInt" )){
    fname=sprintf(model_file_string,j,fs_method,lop)
    if (!file.exists(fname)){
        message(fname)
        set.seed(seeds[[j]])
      RF_fs_j=NA # set NA by default, immediately replaced by resulting model if
                 # fs_method found anything
      f_key<- if (fs_method=="md12DpInt") "md12Dp" else fs_method
      if (length(features[[f_key]][[j]])) {
      X_keep<-tdata[ subsample[[j]]$keep, ,
                                      drop=FALSE
                                      ]
      X_keep_sel<- X_keep[, features[[f_key]][[j]], drop=FALSE]
      X_rf<- X_keep_sel
      if (fs_method=="md12DpInt")
      {
              #if any true synergies were found, interaction_data has length == 4
              if (length(full_MDFSres[[j]]$res_2Dm$interaction_data)>1){
                    interaction_xm<- generate_interaction_variables(X_keep, full_MDFSres[[j]]$res_2Dm$interaction_data)
                    X_rf<- cbind(X_rf, interaction_xm)
              } 
                if (length(full_MDFSres[[j]]$res_2D0$interaction_data)>1) {
                  interaction_x0<- generate_interaction_variables(X_keep, full_MDFSres[[j]]$res_2D0$interaction_data) 
                  X_rf<- cbind(X_rf, interaction_x0)
              } 
      } 
      
      y_rf<-  y[   subsample[[j]]$keep ] |> as.factor() 
      RF_fs_j= randomForest(x= X_rf,
                            y= y_rf)
      }
      
      saveRDS(RF_fs_j, file=fname)                      
    }
    
    #RF_models[[fs_method]][[j]]=RF_fs_j
  }
  
  message(sprintf("%d /%d done",j,n_repeats))
  
}

```


```{r}
library(pROC)
n_repeats=500
#n_repeats=30
source("balanced_decision.R")
METHODS=c(names(features),"md12DpInt")
METRICS=c("AUC","OR")
odds_ratio<- function(y_pred, y){
 # if(length(unique(y_pred))<2){
    #print(sprintf("bad table %s %s",method, cohort));
  #  return(1)}
  stopifnot(length(unique(y))==2)
  CM= matrix(nrow=2,ncol=2)
  CM[1,1]=sum( (y_pred==0) & (y==0))
  CM[2,1]=sum( (y_pred==1) & (y==0))
  CM[1,2]=sum( (y_pred==0) & (y==1))
  CM[2,2]=sum( (y_pred==1) & (y==1))
  if (any(CM==0)) CM= CM + 1
  (CM[2,2]*CM[1,1])/(CM[1,2]*CM[2,1])
}
if (!file.exists("performance_agp.rds")) {
performance=array(dim = c(length(METHODS),length(METRICS), n_repeats),
                  dimnames = list(
                                  METHODS,
                                  METRICS,
                                  NULL  #500 repeats
                                  )
                  )

pred_thr= array(NA, dim= c( length(METHODS),n_repeats),
                 dimnames = list(
                                  METHODS,
                                  NULL  #500 repeats
                                  )
)

for (j in 1:n_repeats){
  for (method in METHODS){
    fname=sprintf(model_file_string,j,method,lop)
  RF_mj<- readRDS(fname)
  no_features<- (length(RF_mj)==1)
    if (no_features){ 
      print(sprintf("null %s %s",method))
      performance[method,"AUC",j]=0.5
      performance[method,"OR",j]=1
    } else {
    f_key= if (method %in% names(features)) method else "md12Dp"
    X_test<- tdata[ subsample[[j]]$leave, ,drop=FALSE]
    X_rf<- X_test[, features[[f_key]][[j]], drop=FALSE ]
    if (method=="md12DpInt"){
      if (length(full_MDFSres[[j]]$res_2Dm$interaction_data)>1){
                    interaction_xm<- generate_interaction_variables(X_test, full_MDFSres[[j]]$res_2Dm$interaction_data)
                    X_rf<- cbind(X_rf, interaction_xm)
              } 
      if (length(full_MDFSres[[j]]$res_2D0$interaction_data)>1){
                    interaction_x0<- generate_interaction_variables(X_test, full_MDFSres[[j]]$res_2D0$interaction_data)
                    X_rf<- cbind(X_rf, interaction_x0)
      } 
    X_rf_ref<-X_rf
    }
    test_pred= predict(RF_mj, newdata=  X_rf,
                      type="prob"  )[,2]
    y_thr= balanced.decision(x = RF_mj$votes[,2], 
                             y= y[   subsample[[j]]$keep ] )$threshold
    pred_thr[method,j]=y_thr
    y_pbin<- (test_pred >= y_thr)
    confusion=table(Predicted=y_pbin,Actual= y[   subsample[[j]]$leave ] )
    performance[method,"AUC",j]= auc(response=y[   subsample[[j]]$leave ],
                                        predictor=test_pred,quiet=TRUE)|> as.numeric() 
    performance[method,"OR",j]=  odds_ratio(y_pbin, y[   subsample[[j]]$leave ])
    
    }
  }
  j_= j-1
  if (j_==0) message(paste0(rep("_",n_repeats %/% 10),collapse=""))
  if ((j_>0) && (j_ %% 10 == 0)) cat("#")
}

} else {
  performance<-readRDS("performance_agp.rds")
}

```

```{r}

if (!file.exists("performance_agp.rds")) saveRDS(performance, "performance_agp.rds")


```

```{r}
install.packages("reshape2")
library(reshape2)
long_perf <- melt(performance, 
                  varnames = c("Method", "Metric", "Repeat"), value.name = "Value")


```

```{r}
#install.packages("dplyr")
```
```{r}
install.packages("ggplot2")
library(ggplot2)
#library(dplyr)
#summary_lines <- long_perf %>%
#  group_by(Metric, Method) %>%
#  summarise(
#    median = median(Value),
#    notch_lower = quantile(Value, 0.25) + 1.57 * IQR(Value) / sqrt(n()),
#    notch_upper = quantile(Value, 0.75) - 1.57 * IQR(Value) / sqrt(n()),
#    .groups = "drop"
#  )


# Violin plot to show distribution
ggplot(long_perf, aes(x = Method, y = Value, fill = Method)) +
  #geom_violin(trim = FALSE, alpha = 0.7) +
  geom_boxplot(width = 0.3, color = "black", notch = TRUE) +
   #geom_hline(data = summary_lines, aes(yintercept = median, color = Method), linetype = "solid") +

  # Add dashed lines for notches
#  geom_hline(data = summary_lines, aes(yintercept = notch_lower, color = Method), linetype = "dashed") +
 # geom_hline(data = summary_lines, aes(yintercept = notch_upper, color = Method), linetype = "dashed") +
  facet_wrap(~ Metric, scales = "free_y") +  # Separate plots for AUC and OR
  #theme_minimal() +
  labs(title = sprintf("Performance Metric Distributions by Method, l.o.frac= %.2f",lop),
       y = "Value", x = "Feature Selection Method") +
  theme(legend.position = "none")
```



```{r}

universe<- colnames(tdata)

do.call(rbind,
        lapply(features, function(method_repeats)
            Reduce("+", lapply(method_repeats, function(one_repeat_of_a_method) 
                                                    universe %in% one_repeat_of_a_method 
                                                    ),
                )
            )
        )-> feature_absence_presence

colnames(feature_absence_presence)<-universe

frequent_<- list(over95= .95*n_repeats, over90=.9*n_repeats)
feature_absence_presence[, colAnys(feature_absence_presence >= frequent_$over95)] -> features_AP_filtered95
feature_absence_presence[, colAnys(feature_absence_presence >= frequent_$over90)] -> features_AP_filtered90

```

```{r}
viz_f90<- features_AP_filtered90
colnames(viz_f90)<- sapply(strsplit(colnames(viz_f90),split="\\."), function(x) x[[length(x)]])
viz_f90<-t(viz_f90) |> as.data.frame()
viz_f90[ do.call(order, viz_f90),]
```




```{r}
# mean IG = mean over all repeats
# IG in repeat= max IG (median, zero)
# partner in repeat= one with synergy
#       if both zero and median are synergistic - arg max (IG)
#overall partner - most frequent
#only partners - overall partners but not in 1D or 2D relevant set 90% of times.
plausible<- colnames(features_AP_filtered90)

stopifnot(  #code below works if set of plausible taxons were all present in each of the
            #subsamples (might dissapear due to filtering out of sparse columns)
            #this condition catches this unlikely exception
all(sapply(full_MDFSres, function(mdfs)
              sapply(mdfs, function(x) 
                  plausible %in% x$feature_names
                )     
))
)
rel_2D<-
presence_mD<-presence_0D<-abundance_per_repD<-
presence_mH<-presence_0H<-abundance_per_repH<-
presence_m<-presence_0<-abundance_per_rep<-
IG1D<-IG2D<- matrix(nrow=n_repeats, ncol=length(plausible))

partners_m0<-partners_0<-partners_m<- matrix(0,nrow=length(plausible), ncol=ncol(tdata))

for (j in c(1:n_repeats) ){
  mdfs_j<- full_MDFSres[[j]]
  for (k in seq_along(mdfs_j)) names(mdfs_j[[k]]$statistic)<- mdfs_j[[k]]$feature_names
  
  rel_2D[j,]= plausible %in% union(mdfs_j$res_2Dm$rel_set,
                                   mdfs_j$res_2D0$rel_set
                                   )
  
  plaus_IG1Dm<- mdfs_j$res_1Dm$statistic[plausible]
  plaus_IG1D0<- mdfs_j$res_1D0$statistic[plausible]
  plaus_IG2Dm<- mdfs_j$res_2Dm$statistic[plausible]
  plaus_IG2D0<- mdfs_j$res_2D0$statistic[plausible]
  IG1D[j,]<- pmax(plaus_IG1Dm,plaus_IG1D0)
  mIG2D_bigger<- plaus_IG2Dm>plaus_IG2D0
  IG2D[j,]<- pmax(plaus_IG2Dm,plaus_IG2D0)
  
  full_MDFSres[[1]]$res_2D0$partner_df[full_MDFSres[[1]]$res_2D0$partner_df$rel_name %in% plausible,]
  pm0j<-pmj<-p0j<- matrix(nrow=length(plausible), ncol=ncol(tdata))
  for (i_p in seq_along(plausible)){
    pmj[i_p,]= colnames(tdata) %in%  mdfs_j$res_2Dm$partner_df[ mdfs_j$res_2Dm$partner_df$rel_name== plausible[[i_p]], ]$partner_name
    p0j[i_p,]= colnames(tdata) %in%  mdfs_j$res_2D0$partner_df[ mdfs_j$res_2D0$partner_df$rel_name== plausible[[i_p]], ]$partner_name
    pm0j[i_p,]= p0j[i_p,] | pmj[i_p,]
  }
  partners_0<- partners_0 + p0j
  partners_m<- partners_m + pmj
  partners_m0<- partners_m0 + pm0j
  
  #partners_0<- mdfs_j$res_2D0$partner_df
  #partners_m<- mdfs_j$res_2Dm$partner_df
  #partners_0<- partners_0[partners_0$synergy,]  #only those which are truly synergistic
  #partners_m<- partners_m[partners_m$synergy,]
  #rownames(partners_0)<-partners_0$rel_name     #to make it possible to select by rows
  #rownames(partners_m)<-partners_m$rel_name     # see partner_j filling
  #has_partner<- plausible %in% union(partners_0$rel_name, partners_m$rel_name)
  #partner_j<- rep(NA, length(plausible))
  #for each of the taxa that had a partner at j-th rep, 
  #if median based IG was bigger, use partner from partners_m,otherwise from partners_0
  #partner_j[has_partner]<- ifelse(mIG2D_bigger[has_partner], 
  #                                partners_m[plausible[has_partner],]$partner_name,
  #                                partners_0[plausible[has_partner],]$partner_name
  #                                )
  #partners_per_rep[j,]=partner_j
  
  #mean abundance & presence
  
  plausible_ab_at_j<-tdata[ subsample[[j]]$keep, plausible ]
  presence_m_at_j<-binarize_taxa(as.matrix(plausible_ab_at_j), 
                thresholds = colMedians(as.matrix(plausible_ab_at_j)) )
  presence_0_at_j<-binarize_taxa(as.matrix(plausible_ab_at_j), 
                thresholds = rep(0, ncol(plausible_ab_at_j))) 
  abundance_per_rep[j,]= colMeans(plausible_ab_at_j)
  presence_0[j,]=  colMeans(presence_0_at_j)
  presence_m[j,]=  colMeans(presence_m_at_j)
  abundance_per_repH[j,]=colMeans(plausible_ab_at_j[y[subsample[[j]]$keep]==0, ])
  abundance_per_repD[j,]=colMeans(plausible_ab_at_j[y[subsample[[j]]$keep]==1, ])
  presence_0H[j,]=colMeans(presence_0_at_j[y[subsample[[j]]$keep]==0, ])
  presence_0D[j,]=colMeans(presence_0_at_j[y[subsample[[j]]$keep]==1, ])
  presence_mH[j,]=colMeans(presence_m_at_j[y[subsample[[j]]$keep]==0, ])
  presence_mD[j,]=colMeans(presence_m_at_j[y[subsample[[j]]$keep]==1, ])
  if ((j-1) %%100==0) message(sprintf("%d/%d",j,n_repeats))
}




```

```{r fig.width=7, fig.height=6}

vpm0<- partners_m0
colnames(vpm0)<- sapply(strsplit(colnames(tdata), "\\."), function(x) x[[length(x)]])
rownames(vpm0)<-sapply(strsplit(plausible, "\\."), function(x) x[[length(x)]])
vpm0<- vpm0[,order(colSums(vpm0),decreasing=TRUE)]
vpm0<- vpm0[order(rowSums(vpm0), decreasing = TRUE),]
vpm0<- vpm0[, colSums(vpm0)>100]

vpm0_flat<-melt(vpm0)
colnames(vpm0_flat)<-c("rel","partner","freq")
ggplot(vpm0_flat, aes(x=partner,y=rel,fill=freq))+ geom_tile()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```


```{r fig.width=9, fig.height=6}

vpm0<- partners_m0
colnames(vpm0)<- sapply(strsplit(colnames(tdata), "\\."), function(x) x[[length(x)]])
rownames(vpm0)<-sapply(strsplit(plausible, "\\."), function(x) x[[length(x)]])
vpm0<- vpm0[,order(colSums(vpm0),decreasing=TRUE)]
vpm0<- vpm0[order(rowSums(vpm0), decreasing = TRUE),]
vpm0<- vpm0[, colMaxs(vpm0)>300]
vpm0<- vpm0[rowMaxs(vpm0)>200 , ]
vpm0_flat<-melt(vpm0)
colnames(vpm0_flat)<-c("rel","partner","freq")
ggplot(vpm0_flat, aes(x=partner,y=rel,fill=freq))+ geom_tile()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+
    geom_text(aes(label = freq), color = "pink")

```


```{r}

fs_df<- data.frame(taxon=plausible,
                        IG2D= colMeans(IG2D),
                        IG2D_SD= colSds(IG2D),
                        IG1D= colMeans(IG1D),
                        IG1D_SD=colSds(IG1D),
                        rel_1D= features_AP_filtered90["md1D",],
                        rel_2D= colSums(rel_2D),
                        rel_u=  features_AP_filtered90["u",]
                        )

viz_fs_df<- fs_df
rownames(viz_fs_df)<-NULL
viz_fs_df$taxon<-sapply(strsplit(fs_df$taxon,"\\."), function(x) x[[length(x)]])
viz_fs_df[,2:5]<- round(viz_fs_df[,2:5],2)
viz_fs_df[order(-viz_fs_df$IG2D) , ]
```





```{r}
pab_df<- data.frame(taxon=plausible,
                        ab= colMeans(abundance_per_rep),
                        ab_SD= colSds(abundance_per_rep),
                        abH= colMeans(abundance_per_repH),
                        abH_SD= colSds(abundance_per_repH),
                        abD= colMeans(abundance_per_repD),
                        abD_SD= colSds(abundance_per_repD),
                        pr=colMeans(presence_0),
                        pr_SD=colSds(presence_0),
                        prH=colMeans(presence_0H),
                        prH_SD=colSds(presence_0H),
                        prD=colMeans(presence_0D),
                        prD_SD=colSds(presence_0D)
                        )

viz_pab_df<- pab_df
rownames(viz_pab_df)<-NULL
viz_pab_df$taxon<-sapply(strsplit(pab_df$taxon,"\\."), function(x) x[[length(x)]])
viz_pab_df[, grep("ab",colnames(viz_pab_df))]<-10000*viz_pab_df[, grep("ab",colnames(viz_pab_df))]
viz_pab_df[,2:ncol(viz_pab_df)]<- round(viz_pab_df[,2:ncol(viz_pab_df)],2)
viz_pab_df[order(-viz_fs_df$IG2D) , ]

```
```{r}

max(partners_m0)

```



```{r}

viz_fs_df2<-viz_fs_df[,c("taxon","IG2D","IG1D","rel_1D","rel_2D")]
viz_fs_df2$best_partner=sapply(plausible,
                         function(taxon){ if (taxon %in% colnames(partners_per_rep))
                           names(table(partners_per_rep[,taxon]))[[which.max(table(partners_per_rep[,taxon]))]]
                           else "foo"
                         }
                    )

viz_fs_df2$partnership_freq=sapply(plausible,
                         function(taxon){ if (taxon %in% colnames(partners_per_rep))
                           unname(table(partners_per_rep[,taxon])[[which.max(table(partners_per_rep[,taxon]))]])
                           else "foo"
                         }
                    )
fs_df2<- viz_fs_df2
fs_df2$taxon<- fs_df$taxon
viz_fs_df2$best_partner<- sapply( strsplit(viz_fs_df2$best_partner, split='\\.'), function(x) x[[length(x)]] )
```

```{r}

viz_fs_df2

```


```{r}

rel1D2D_strong_partnerships<-fs_df2[(fs_df2$rel_2D==500) &
  (fs_df2$rel_1D==500) &
  (fs_df2$partnership_freq>=250),] 

short_taxon<-sapply( strsplit(rel1D2D_strong_partnerships$taxon, split='\\.'), function(x) x[[length(x)]] )
short_partner<-sapply( strsplit(rel1D2D_strong_partnerships$best_partner, split='\\.'), function(x) x[[length(x)]] )

for (i in 1:nrow(rel1D2D_strong_partnerships)){
  rel1D2D_strong_partnerships$taxon
  rel <- as.integer(taxonomy.mean.final[, rel1D2D_strong_partnerships$taxon[[i]]] > 0)
  partner <- as.integer(taxonomy.mean.final[, rel1D2D_strong_partnerships$best_partner[[i]] ] > 0)
 
  # Print header
  cat("\n\n---\n")
  cat(sprintf("### Pair %d: %s vs %s\n", i, short_taxon[[i]], short_partner[[i]]))
  
  # Print frequency
  cat(sprintf("**Partnering frequency**: %d\n\n", rel1D2D_strong_partnerships$partnership_freq[[i]]))
  # Tabulate
  tab <- table(Rel = rel, Partner = partner, Class = decision.mean.final)
  print("y==0 | y==1")
  print(cbind(tab[,,1], tab[,,2] ))
}
```


```{r}

n_vars <- ncol(partners_per_rep)  


ppr<- partners_per_rep
colnames(ppr)<-sapply(strsplit(colnames(partners_per_rep), "\\."),function(x) x[[length(x)]])
for (j in 1:ncol(ppr)) ppr[,j]= c( ppr[,j][is.na(ppr[,j])], sort(ppr[,j][!is.na(ppr[,j])]))
ppr<- as.data.frame(ppr)
for (j in 1:ncol(ppr)) ppr[,j]<- as.factor(ppr[,j]) |> as.integer()
ppr<- ppr[do.call(order, c(ppr, na.last=FALSE )),]
ppr<- as.matrix(ppr)
library(RColorBrewer)

n_cols <- ncol(ppr)
n_rows <- nrow(ppr)

# Function to generate colors for each column based on unique non-NA values
get_col_palette <- function(col_vals) {
  unique_vals <- sort(unique(col_vals[!is.na(col_vals)]))
  n_levels <- length(unique_vals)
  
  base_colors <- brewer.pal(min(max(n_levels, 3), 8), "Set1")
  if (n_levels > length(base_colors)) {
    base_colors <- rep(base_colors, length.out = n_levels)
  }
  
  # Map unique_vals to consecutive indices: 1, 2, 3, ...
  mapping <- setNames(seq_along(unique_vals), unique_vals)
  
  # Return list with color vector and mapping
  list(
    colors = base_colors,
    mapping = mapping
  )
}

# Create a color matrix matching ppr's entries (including NAs)
color_mat <- matrix(NA, nrow = n_rows, ncol = n_cols)

for (j in 1:n_cols) {
  pal_list <- get_col_palette(ppr[, j])
  pal_colors <- pal_list$colors
  pal_map <- pal_list$mapping
  
  for (i in 1:n_rows) {
    val <- ppr[i, j]
    if (is.na(val)) {
      color_mat[i, j] <- "grey"
    } else {
      # Use mapping to get index for color
      idx <- pal_map[as.character(val)]
      color_mat[i, j] <- pal_colors[idx]
    }
  }
}



# Plot with image()
# image() expects numeric matrix, so we map colors to numbers
# Create a vector of unique colors in color_mat for the palette

all_colors <- unique(as.vector(color_mat))
all_colors <- all_colors[!is.na(all_colors)]

# Map colors to integers for image()
color_indices <- matrix(match(color_mat, all_colors), nrow = n_rows, ncol = n_cols)

# image() plots columns from left to right and rows from bottom to top,
# so to have top rows at top, we flip rows

par(mar = c(15, 4, 1, 2) + 0.1)  # increase bottom margin to 6 lines (default is 5.1)

image(t(apply(color_indices, 2, rev)),
      col = all_colors,
      axes = FALSE,
      xlab = NA,
      ylab = "Trials",
      main = "Distinct partners per variable in each repeat")

# Add axis labels
axis(1, at = seq(0,1,length.out = n_cols), labels = colnames(ppr), las=2)
axis(2, at = seq(0,1,length.out = n_rows), labels =NA)
box()
```



```{r}
par(mar = c(5, 3, 2, 1))
rocs<-list()
model_file_string<-"RF_models/agp_j=%d_fs=%s_lop=%.2f.rds"
set.seed(3423)
r<- sample(1:n_repeats,1)
for (method in c("u","md1D","md12D","md12Dp")){

colormap<- c(u="purple",
             "md1D"="green",
             "md12D"="blue",
             "md12Dp"="red"
             )
fname=sprintf(model_file_string,r,method,lop)
RF_mr<- readRDS(fname)
predict(RF_mr, newdata= tdata[ subsample[[r]]$leave, 
                               features[[method]][[r]],
                               drop=FALSE
                               ], type="prob")[,2]->y_pred

ROC<-roc(response=y[ subsample[[r]]$leave ], 
         predictor=y_pred)
rocs[[method]]=ROC
if (method=="u")
plot(ROC,
     legacy.axes = TRUE,
     xlim = c(1, 0),        # Desired limits
     xaxs = "i",            # Prevent automatic padding
     ylim = c(0, 1),        # Optional: force y-limits too
     yaxs = "i",            # Prevent vertical padding
     asp = NA,               # Avoid forced aspect ratio
     col=colormap[[method]],
      mar = c(5, 4, 2, 2)
) else
plot.roc(ROC, main=method, add=TRUE,, col=colormap[[method]], xlim=c(1,0),
     legacy.axes=TRUE)
}
legend("bottomright",legend=c("u","md1D","md12D","md12Dp"),lwd=2,col=colormap
)
```

```{r}
lapply(rocs, auc)
roc.test(rocs$md12Dp, rocs$u)
roc.test(rocs$md12Dp, rocs$md1D)
roc.test(rocs$md12Dp, rocs$md12D)
```
```{r}

roc.test(rocs$md12Dp, rocs$md1D)


```


```{r}
library(MDFS)
source("FS_functions.R")
MDFS_FS(X=tdata[subsample[[1]]$keep,], y=y[subsample[[1]]$keep ] )-> temp


```


```{r}
library(MDFS)
if (!file.exists("rel_MDFS_group.RData")) {
MDFS_1D<-MDFS_2D<-MDFS_1D_relnames<-MDFS_2D_relnames<-MDFS_1D2D_relnames<-list()
for (i in 1:30){current_seed=i
gc()
  set.seed(current_seed)
  # Perform MDFS with 1D
  MDFS_1D_result <- MDFS.discrete(
    data = base_resamples[[i]]$taxa_binary,
    decision = base_resamples[[i]]$disease_status,
    dimensions = 1,
    seed= current_seed,  # Set the seed for reproducibility
    level = 0.05
  )

  MDFS_1D[[i]] <- MDFS_1D_result
  MDFS_1D_relnames[[i]] <- colnames(base_resamples[[i]]$taxa_binary)[MDFS_1D_result$relevant.variables]
gc()
set.seed(current_seed)
  # Perform MDFS with 2D
  MDFS_2D_result <- MDFS.discrete(
    data = base_resamples[[i]]$taxa_binary,
    decision = base_resamples[[i]]$disease_status,
    dimensions = 2,
    seed = current_seed,
    level = 0.05
  )
  MDFS_2D[[i]] <- MDFS_2D_result
  MDFS_2D_relnames[[i]] <- colnames(base_resamples[[i]]$taxa_binary)[MDFS_2D_result$relevant.variables]

  # Combine 1D and 2D relevant variables
  MDFS_1D2D_relnames[[i]] <- union(MDFS_1D_relnames[[i]], MDFS_2D_relnames[[i]])
message(sprintf("%d/30 done",i))
}

# Combine results into lists of lists
MDFS_object_lists <- list(MDFS_1D = MDFS_1D, MDFS_2D = MDFS_2D)
relnames_lists <- list(MDFS_1D_rel = MDFS_1D_relnames, 
                       MDFS_2D_rel = MDFS_2D_relnames, 
                       MDFS_1D2D_rel = MDFS_1D2D_relnames)
# Save results
save(relnames_lists, MDFS_object_lists, 
     file = "rel_MDFS_group.RData")
} else { message("loading data");load("rel_MDFS_group.RData")}
```

## Integrate results from base resamples 

```{r}
#names rel. either in 1D or 2D in each of the trials
any_times_relevant_taxa<- Reduce(union, relnames_lists$MDFS_1D2D_rel)


```

### Estabilish robust set of relevant features from base resampling

#### Calculate frequencies of appearance as relevant

```{r}
#containers for frequencies
rel_freq<-rel_freq_1D<-rel_freq_2D<-rep(0, length(any_times_relevant_taxa))
names(rel_freq)<-names(rel_freq_1D)<-names(rel_freq_2D)<-any_times_relevant_taxa
for (i in seq_along(relnames_lists[[1]])) {
 rel_freq<- rel_freq + ( any_times_relevant_taxa %in% relnames_lists$MDFS_1D2D_rel[[i]] )*1. 
 rel_freq_1D<- rel_freq_1D + ( any_times_relevant_taxa %in% relnames_lists$MDFS_1D_rel[[i]] )*1. 
 rel_freq_2D<- rel_freq_2D + ( any_times_relevant_taxa %in% relnames_lists$MDFS_2D_rel[[i]] )*1. 
  
}
```

#### Reduce the set to taxa that appeared relevant 30 times in either 1D or 2D

```{r}
which_stay<-(rel_freq==30)
base_relevant_set<- any_times_relevant_taxa[which_stay]
rel_freq<- rel_freq[which_stay]
rel_freq_1D<-rel_freq_1D[which_stay]
rel_freq_2D<-rel_freq_2D[which_stay]
```

### Find interaction partners for each of 2D relevant taxa

Function `get_interaction_partner` finds the best partners of each variable in `dataset` determined by index in `interesting.vars`, according to the Information Gain (IG) on `decision`.
Here:

- `dataset` will be binarized taxa, 

- `decision` is disease status,

- `interesting.vars` will be variables relevant in 2D analysis,

... in each of the 30 base resamples.


```{r}

get_interaction_partner<- function(dataset, decision, interesting.vars, ...){

if (!(all(interesting.vars %in% 1:ncol(dataset))))
        stop("interesting.vars must be in 1:ncol(dataset)")

if (is.null(colnames(dataset)))
        stop("datatset should have column names (taxa names)")

best.tuples <- ComputeInterestingTuplesDiscrete(dataset,
                                        decision,
                                        interesting.vars =interesting.vars,                                         ...
                                          )
do.call(rbind,
       lapply(interesting.vars, function(V){

               V_subset<- best.tuples$Var == V
               V_which.max<- which.max( best.tuples[ V_subset,]$IG )
              m_t1<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.1"]]
              m_t2<-best.tuples[ V_subset, ][V_which.max, ][["Tuple.2"]]
              p_IDX<- if( V== m_t1) m_t2 else m_t1
              data.frame( rel_IDX= V, partner_IDX= p_IDX, rel_name = colnames(dataset)[[V]],                                                                             partner_name= colnames(dataset)[[p_IDX]],
                 rel_IG= best.tuples[ V_subset, ][V_which.max,][["IG"]] )
              }
             )
       )
}


```


#### Apply the function on each of the base resamples:

```{r}

partners_per_run<- list()
i_set<-1
for (i_set in seq_along(base_resamples))
{
partners_per_run[[i_set]] <-
get_interaction_partner(dataset=base_resamples[[i_set]]$taxa_binary,
                         decision=base_resamples[[i_set]]$disease_status,
                     interesting.vars=MDFS_object_lists[[2]][[i_set]]$relevant.variables ,
                         dimensions=2)

}



```

Function returns data.frame of names of relevant variables (taxa), their positions in each set and the same of their partners.
We can inspect output from one run, for context. Auxiliary function shortens taxa names to the deepest available classification:

```{r}

partners_per_run[[1]]-> example_out

get_deepest_taxonomy_lvl<- function(taxa_name){
strsplit(taxa_name,"\\.")-> splitted
splitted[[1]][[ length(splitted[[1]]) ]]
}
example_out$rel_name<- unlist(lapply(example_out$rel_name, get_deepest_taxonomy_lvl))
example_out$partner_name<- unlist(lapply(example_out$partner_name, get_deepest_taxonomy_lvl))

example_out[order(example_out$rel_IG, decreasing=TRUE),] %>% head

```

#### Aggregate the results from all resamples

We calculate mean IG for each synergistic pair over all base resamples it appears in.

Then, for each relevant variable in 2D, we take its "definitive" partner as the one that had maximum mean IG over all base resamples.

```{r}
#mean IG
do.call(rbind, partners_per_run)-> partners_all_runs #all runs together
#aggregate(partners_all_runs$rel_IG, #value to aggregate
#          list(rel=partners_all_runs$rel_name,       #factors over which to group
#              partner=partners_all_runs$partner_name),
#          mean #how to aggregate
#          )-> partner_IG_tabulation

data.frame(rel= partners_all_runs$rel_name, 
           partner=partners_all_runs$partner_name,
       pair=interaction(partners_all_runs$rel_name, partners_all_runs$partner_name) |> as.character(),
       IG=partners_all_runs$rel_IG)-> partner_IG_tabulation




do.call(rbind,lapply(base_relevant_set[rel_freq_2D==30], function(taxon)
{
        taxon_subset<- partner_IG_tabulation$rel == taxon
        if (any(taxon_subset))
        {
              #print(sum(taxon_subset))
                taxon_partners<-partner_IG_tabulation[ taxon_subset, ,drop=FALSE]
                pairCounts<-table(taxon_partners$pair)
                pairCounts<- pairCounts[ order(pairCounts, decreasing = TRUE) ]
                partners_names_only<- partner_IG_tabulation[,-ncol(partner_IG_tabulation)]
                partners_names_only<- partners_names_only[!duplicated(partners_names_only),]
                partners_names_only$partner[ partners_names_only$pair == names(pairCounts)[[1]] ] -> most_freq
                #print(sprintf("relevant taxon name= %s", get_deepest_taxonomy_lvl(taxon ) ))
                #print (sprintf("frequency of %s =  %d ", get_deepest_taxonomy_lvl(most_freq),  pairCounts[[1]]))
                result<- data.frame(rel=taxon,partner=most_freq, freq=pairCounts[[1]])
                if (pairCounts[[1]]>15) { result<-result } else { result<- result}
                  #result<- "tie" }
                #taxon_partners$partner[[ which.max(taxon_partners$IG) ]]
                 result
        } else NA

}       )) -> rel2D_partner_freq_df
  
  best_partners_baseRelSet<-rel2D_partner_freq_df$partner

names(best_partners_baseRelSet)<- base_relevant_set[rel_freq_2D==30]

viz_rel2<- rel2D_partner_freq_df
for (j in 1:2) viz_rel2[,j]<- sapply(viz_rel2[,j], get_deepest_taxonomy_lvl)

```


#### Use mean IG to estabilish true synergies

We calculate mean IG of all selected taxa so far (relevant 30 times in 1D or 2D + best partners for 2D relevant ones) to estabilish criteria for synergy:

- if the increase of IG in 2D of the 2D relevant variable is bigger than the minimal IG in 1D analysis. 


```{r}
#truly relevant (30 times in 1D or 3D) + partners
union(base_relevant_set, unname(best_partners_baseRelSet))-> overall_rel_list
  
#ugly, but necessary check:
##ensure that all resamples contain all taxa in overall_rel_list
stopifnot(
 lapply(base_resamples, function(x) 
   all(overall_rel_list %in% colnames(x$taxa_binary)) 
   ) |> unlist()  |> all() 
)


```

```{r}

mean_IG_overRuns<- function(MDFS_objects, taxa_subset, taxa_names_in_resamples){
  do.call( rbind, mapply( function(mdfs,taxa_names) 
                            mdfs$statistic[ match(taxa_subset,taxa_names) ],
                          MDFS_objects, taxa_names_in_resamples, SIMPLIFY = FALSE
                          )
          ) |> colMeans()
}

base_resamples_present_taxa<- lapply(base_resamples, function(x)
                                      colnames(x$taxa_binary))

overall_rel_IG1D<- mean_IG_overRuns(MDFS_object_lists[[1]],
                                    overall_rel_list,
                                    base_resamples_present_taxa
                                    )
overall_rel_IG2D<- mean_IG_overRuns(MDFS_object_lists[[2]],
                                    overall_rel_list,
                                    base_resamples_present_taxa
                                    )
names(overall_rel_IG1D)<-names(overall_rel_IG2D)<-overall_rel_list
```

```{r}
# union(base_relevant_set, unname(best_partners_baseRelSet))-> overall_rel_list
# 
# #containers of mean IG
# overall_rel_IG1D<- rep(0, length(overall_rel_list))
# overall_rel_IG2D<- rep(0, length(overall_rel_list))
# names(overall_rel_IG1D)<-names(overall_rel_IG2D)<-overall_rel_list
# rel_1D_names<- names(rel_freq[rel_freq_1D==30])
# rel_2D_names<- names(rel_freq[rel_freq_2D==30])
# 
# get_IG_from_rel_names<- function(taxa_statistic, taxa_names,
#                           rel_subset_names){
#   names(taxa_statistic)<- taxa_names
#   taxa_statistic[rel_subset_names]
# }
# 
# 
# 
# for (i in seq_along(MDFS_object_lists[[1]])){
#   #taxa present in run "i"
#   resample_present_taxa<-colnames(base_resamples[[i]]$taxa_binary)
#   #found relevant in "i" and relevant 30 times overall
#   intersect(resample_present_taxa, relnames_lists[[1]][[i]]) -> rel1Dtaxa_thisRun
#   intersect(rel1Dtaxa_thisRun, rel_1D_names)-> rel1Dtaxa_thisRun
#   intersect(resample_present_taxa, relnames_lists[[2]][[i]]) -> rel2Dtaxa_thisRun
#   intersect(rel2Dtaxa_thisRun, rel_2D_names)-> rel2Dtaxa_thisRun
#   #their position in run "i"
#   match( rel1Dtaxa_thisRun, resample_present_taxa)-> rel_1D_idx
#   match( rel2Dtaxa_thisRun, resample_present_taxa)-> rel_2D_idx
#   #their IG 
#    MDFS_object_lists[[1]][[i]]$statistic[ rel_1D_idx ] -> IG_1D_resample
#    MDFS_object_lists[[2]][[i]]$statistic[ rel_2D_idx ] -> IG_2D_resample
#    stopifnot(all(rel1Dtaxa_thisRun %in% names(overall_rel_IG1D))) 
#    stopifnot(all(rel2Dtaxa_thisRun %in% names(overall_rel_IG2D))) 
#    #increase sums only for relevant variables from that run
#    overall_rel_IG1D[ rel1Dtaxa_thisRun ] = overall_rel_IG1D[ rel1Dtaxa_thisRun ] + IG_1D_resample
#    overall_rel_IG2D[ rel2Dtaxa_thisRun ] = overall_rel_IG2D[ rel2Dtaxa_thisRun ] + IG_2D_resample
# }
# #divide overall_rel_IG by the times each variable was found relevant
# times_rel_overall<- rep(1, length(overall_rel_list))
# names(times_rel_overall)<-overall_rel_list
# times_rel_overall[ names(rel_freq) ] = rel_freq
# overall_rel_IG1D<- overall_rel_IG1D/times_rel_overall
# overall_rel_IG2D<- overall_rel_IG2D/times_rel_overall
# 
# #overall_rel_IG1D[ !(overall_rel_list %in% names(rel_freq_1D)[rel_freq_1D==30]) ] =0
# #overall_rel_IG2D[ !(overall_rel_list %in% names(rel_freq_2D)[rel_freq_2D==30]) ] =0
```

```{r}
data.frame( name=overall_rel_list,
            IG1D=overall_rel_IG1D, IG2D= overall_rel_IG2D)-> ig_df
ig_df$rel_1D<- rel_freq_1D[ ig_df$name ]
ig_df$rel_2D<- rel_freq_2D[ ig_df$name ]
ig_df$rel_1D[ is.na(ig_df$rel_1D) ] = 0
ig_df$rel_2D[ is.na(ig_df$rel_2D) ] = 0
ig_df$partner_name<- best_partners_baseRelSet[ ig_df$name ]
ig_df$partner_only<- ig_df$name %in% setdiff(best_partners_baseRelSet, base_relevant_set)
synergy_thr<- min(ig_df$IG1D[ig_df$rel_1D==30])
print("minimal increase of IG in 2D analysis for estabilishing synergy:")
print(synergy_thr)
IG_increase= ig_df$IG2D - ig_df$IG1D
# find the true synergies using the thredhold and IG_increase of primary 2D rel. variable:
true_synergistic_partners<-vector(mode="character")
for (partner_only in ig_df$name[ig_df$partner_only])
{
  if (max(IG_increase[which(ig_df$partner_name== partner_only) ]) > synergy_thr)
    true_synergistic_partners[[ length(true_synergistic_partners)+1 ]] = partner_only
}

#for the rest of the analysis:
# keep taxa that were relevant 30 times in 2D or 1D and true synergistic partners.
taxa_to_keep_mask<- (ig_df$name %in% true_synergistic_partners) | 
                      (ig_df$rel_1D==30 ) | 
                      (ig_df$rel_2D==30)
ig_df<- ig_df[ taxa_to_keep_mask,]
ig_df<- ig_df[ order(-ig_df$IG2D),]
```

## Interaction plots

Based on median dataset and results of above computations, we show plots of abundance of Bergeyella vs abundance of Neisseria.

Due to zero inflation, to make the "absence" state more visble, plot visualizes zeroes (samples where one of the bacteria is absent) as values evenly distributed on a small interval around 0 (signified by grey bands).

```{r}

last.name<-function(x,sep='\\.',n=1) {
 return(unlist(lapply(strsplit(x,sep),FUN=function(x) tail(x,n))))
}

decision<-decision.mean.final

taxa_pairlist<- list(c(
'sk__Bacteria.k__.p__Bacteroidetes.c__Flavobacteriia.o__Flavobacteriales.f__Flavobacteriaceae.g__Bergeyella',
'sk__Bacteria.k__.p__Proteobacteria.c__Betaproteobacteria.o__Neisseriales.f__Neisseriaceae.g__Neisseria'
),
c('sk__Bacteria.k__.p__Bacteroidetes.c__Flavobacteriia.o__Flavobacteriales.f__Flavobacteriaceae.g__Bergeyella',
  'sk__Bacteria.k__.p__Proteobacteria.c__Betaproteobacteria.o__Neisseriales.f__Neisseriaceae'
),
ig_df[grep( "g__Pseudomonas", ig_df$name),c("name","partner_name")] |> unlist() |> unname()
)

for (tp in taxa_pairlist) {
  taxon1=tp[1]
  taxon2=tp[2]

 X1<-taxonomy.mean.final[,taxon1]
 short1<-last.name(taxon1)

 X2<-taxonomy.mean.final[,taxon2]
 short2<-last.name(taxon2)

 min1<-min(X1[X1>0])
 max1<-max(X1)
 min2<-min(X2[X2>0])
 max2<-max(X2)

 min1r<-10^floor(log10(min1))
 max1r<-10^ceiling(log10(max1))
 min2r<-10^floor(log10(min2))
 max2r<-10^ceiling(log10(max2))
 tx1<-10^(log10(min1r):log10(max1r))
 tx2<-10^(log10(min2r):log10(max2r))

 add1<-min(X1[X1>0])/2
 add2<-min(X2[X2>0])/2

 add1m<-add1/sqrt(10)
 add2m<-add2/sqrt(10)

 prop000<-sum(X1==0 & X2==0 & decision==0)/sum(X1==0 & X2==0)
 prop001<-sum(X1==0 & X2==0 & decision==1)/sum(X1==0 & X2==0)
 prop010<-sum(X1==0 & X2>0 & decision==0)/sum(X1==0 & X2>0)
 prop011<-sum(X1==0 & X2>0 & decision==1)/sum(X1==0 & X2>0)
 prop100<-sum(X1>0 & X2==0 & decision==0)/sum(X1>0 & X2==0)
 prop101<-sum(X1>0 & X2==0 & decision==1)/sum(X1>0 & X2==0)
 prop110<-sum(X1>0 & X2>0 & decision==0)/sum(X1>0 & X2>0)
prop111<-sum(X1>0 & X2>0 & decision==1)/sum(X1>0 & X2>0)
 
 x1<-X1
 x2<-X2
 x1[X1==0]<-x1[X1==0]+exp(log(add1/9)+(log(add1)-log(add1/9))*runif(length(X1[X1==0]))^(2*(!decision[X1==0])+0.5*decision[X1==0]))
 x2[X2==0]<-x2[X2==0]+exp(log(add2/9)+(log(add2)-log(add2/9))*runif(length(X2[X2==0]))^(2*(!decision[X2==0])+0.5*decision[X2==0]))
 x1[X1>0]<-x1[X1>0]+exp(runif(length(X1[X1>0]),log(add1/9),log(add1)))
 x2[X2>0]<-x2[X2>0]+exp(runif(length(X2[X2>0]),log(add2/9),log(add2)))


 bg.h<-'cyan3'
 bg.d<-'red'
 tx.h<-'black'
 tx.d<-'black'
 par(mar=c(5,5,1,1))
 plot(x1,x2,col=1+decision,type='n',log='xy',cex=1,cex.lab=1.5,
      xlim=c(add1/20,max1r),ylim=c(add2/20,max2r*2),
      xlab=short1,ylab=short2,axes=F)
 axis(1,at=c(0,tx1)+add1m,labels = c(0,tx1),cex.axis=1)
 axis(2,at=c(0,tx2)+add2m,labels = c(0,tx2),cex.axis=1)
 rect(add1/9,add2/9,add1,max2r,col='lightgray',border=NA)
 rect(add1/9,add2/9,max1r,add2,col='lightgray',border=NA)

 rect(add1,add2/25,max1r,add2/10,col=bg.d,border=NA)
 rect(add1,add2/25,max1r^prop100*add1^prop101,add2/10,col=bg.h,border=NA)
 text(sqrt(add1*max1r^prop100*add1^prop101),add2/10/sqrt(2.5),sum(X1>0 & X2==0 & decision==0),col=tx.h,cex=1)
 text(sqrt(max1r*max1r^prop100*add1^prop101),add2/10/sqrt(2.5),sum(X1>0 & X2==0 & decision==1),col=tx.d,cex=1)

 rect(add1/10,add2/25,add1,add2/10,col=bg.d,border=NA)
 rect(add1/10,add2/25,add1^prop000*(add1/10)^(prop001),add2/10,col=bg.h,border=NA)
 text(sqrt(add1/10*add1^prop000*(add1/10)^prop001),add2/10/sqrt(2.5),sum(X1==0 & X2==0 & decision==0),col=tx.h,cex=1)
 text(sqrt(add1*add1^prop000*(add1/10)^prop001),add2/10/sqrt(2.5),sum(X1==0 & X2==0 & decision==1),col=tx.d,cex=1)

 rect(add1/25,add2,add1/10,max2r,col=bg.d,border=NA)
 rect(add1/25,add2,add1/10,max2r^prop010*add2^prop011,col=bg.h,border=NA)
 text(add1/10/sqrt(2.5),sqrt(add2*add2^prop011*max2r^prop010),sum(X1==0 & X2>0 & decision==0),col=tx.h,cex=1,srt=90)
 text(add1/10/sqrt(2.5),sqrt(max2r*add2^prop011*max2r^prop010),sum(X1==0 & X2>0 & decision==1),col=tx.d,cex=1,srt=90)

 rect(add1,max2r,max1r,max2r*2.5,col=bg.d,border=NA)
 rect(add1,max2r,max1r^prop110*add1^prop111,max2r*2.5,col=bg.h,border=NA)
 text(sqrt(add1*max1r^prop110*add1^prop111),max2r*sqrt(2.5),sum(X1>0 & X2>0 & decision==0),col=tx.h,cex=1)
 text(sqrt(max1r*max1r^prop110*add1^prop111),max2r*sqrt(2.5),sum(X1>0 & X2>0 & decision==1),col=tx.d,cex=1)

 points(x1,x2,col=c(bg.h,bg.d)[1+decision],pch=19,cex=0.66)
 
  OR_01<-(sum(X1>0 & X2==0 & decision==1)/sum(X1>0 & X2==0 & decision==0))/
  (sum(!(X1>0 & X2==0) & decision==1)/sum(!(X1>0 & X2==0) & decision==0))

 print(paste('Odds ratio for',short1,'and',short2,OR_01))
}

```


## mean presence and abundance of selected taxons across 30 trials

```{r}
summary_df<- ig_df
summary_df$name-> interesting_taxa
#ensure all base_resamples have same number of rows 
stopifnot( all(
        (lapply(base_resamples, function(x) nrow(x$taxa_abundance)) %>%
            unlist() )== nrow(base_resamples[[1]]$taxa_abundance) 
              )
         )

#common basis for all interesting taxa
# (containers for sums)
A_h<-A_d<-P_h<-P_d<-P<-A<- rep(0, length(interesting_taxa))
names(P)<-names(A)<-interesting_taxa
names(P_d)<-names(A_d)<-interesting_taxa
names(P_h)<-names(A_h)<-interesting_taxa

#sum means over resamples
for (i in seq_along(base_resamples)){
    
    intr_present_resample<- intersect(interesting_taxa,
                                colnames(base_resamples[[i]]$taxa_abundance)
                                    )

    P_rsmp<-base_resamples[[i]]$taxa_binary[, intr_present_resample]
    A_rsmp<-base_resamples[[i]]$taxa_abundance[, intr_present_resample]
    y_rsmp<-base_resamples[[i]]$disease_status

    P[ intr_present_resample ] =  P[ intr_present_resample ] +
            colMeans(P_rsmp)
    A[ intr_present_resample ] =  A[ intr_present_resample ] +
            colMeans(A_rsmp)

    P_d[ intr_present_resample ] =  P_d[ intr_present_resample ] +
            colMeans(P_rsmp[y_rsmp==1,])
    A_d[ intr_present_resample ] =  A_d[ intr_present_resample ] +
            colMeans(A_rsmp[y_rsmp==1,])

    P_h[ intr_present_resample ] =  P_h[ intr_present_resample ] +
            colMeans(P_rsmp[y_rsmp==0,])
    A_h[ intr_present_resample ] =  A_h[ intr_present_resample ] +
            colMeans(A_rsmp[y_rsmp==0,])
}
#.. and divide by 30
P<-P/30
A<-A/30
P_h<-P_h/30
A_h<-A_h/30
P_d<-P_d/30
A_d<-A_d/30
summary_df$freq= P
summary_df$ab= A
summary_df$freq_d= P_d
summary_df$ab_d= A_d
summary_df$freq_h= P_h
summary_df$ab_h= A_h
viz_ig_df<- summary_df
viz_ig_df$name<- unlist(lapply(viz_ig_df$name, get_deepest_taxonomy_lvl))
viz_ig_df$partner_name<- unlist(lapply(viz_ig_df$partner_name, get_deepest_taxonomy_lvl))
rownames(viz_ig_df)<- 1:nrow(viz_ig_df)
viz_ig_df[,c(2:3) ]<-round(viz_ig_df[,c(2:3)])
viz_ig_df[,c("ab_h","ab_d","ab")]=viz_ig_df[,c("ab_h","ab_d","ab")]*10000
viz_ig_df[,8:13]=round(viz_ig_df[,8:13],2)
viz_ig_df$name[[ which(
viz_ig_df$name=="s__gamma_proteobacterium_symbiont_of_Gonopsis_affinis"
)
]]="s_gp_symb_Gon_aff"
#viz_ig_df$partner_name[[ which(
#  viz_ig_df$partner_name=="s__Mediterranea_massiliensis")
#]]="s_Med_massiliensis"
```
## Browse end result

#### feature selection stats:

```{r}
viz_ig_df[,c("name","IG1D","IG2D","rel_1D","rel_2D","partner_name")]


```

#### mean abundance & frequency
```{r}
viz_ig_df[,c("name","freq_h","freq_d","freq",
             "ab_h","ab_d","ab")]


```


# Bootstrap resampling validation

Following initial selection of robust features relevant both in 1D and 2D, we validated the results by the use of bootstrap resampling on base resamples themselves.

From each base resample, we have drawn a boostrap resample and performed feature selection again and counted number of times selected features reappeared again as relevant.
Additionally, to test the usability of detected two dimensional interactions, we measured the average gain of AUC from random forest classifier, trained using only 1D relevant variables vs on the whole set of 1D and 2D relevant features.



## Preparation of bootstrap samples (by sampling indexes)

```{r}
N_TRIALS=30
keep_frac<-1

n1<-  sum(base_resamples[[1]]$disease_status==1)
n0<-  sum(base_resamples[[1]]$disease_status==0)

n1k<- ceiling(n1*keep_frac)
n0k<- ceiling(n0*keep_frac)

#list of 30
set.seed(32523)
B_idx<- lapply(1:N_TRIALS,
                       function(B)
                       {
                         y<-base_resamples[[B]]$disease_status
                         
                         idx_1= which(y==1)
                         idx_0= which(y==0)
                         c( sample(idx_1, n1k, replace=TRUE),
                        sample(idx_0, n0k, replace=TRUE)
                         )
                       }
                      )
#saveRDS(B_idx,"Bootstrap_IDX.rds")

```

## Feature selection and RF

We save results of each run in subdirectories `MDFS_results`, `RF_models` and calculate mean metrics after all computation is done.

```{r}
library(randomForest)
library(pROC)
#prepare list of seeds per each bootstrap for reproducibility
set.seed(32432)
session_seeds<- sample.int(323423,N_TRIALS)
    summary_df$name[summary_df$rel_1D==30] -> consensus_1D
    summary_df$name -> consensus_AllRelevant
for (B in 1:N_TRIALS) {
    IDX_B<-  B_idx[[B]]
    set_B<- base_resamples[[B]]
    set.seed(session_seeds[[B]])
#FS
   if (!file.exists( sprintf("MDFS_results/MDFS_replicate_%d.rds", B ) ) ) {
     gc()
    MDFS_1D<- MDFS.discrete(
    data = set_B$taxa_binary[IDX_B,],
    decision = set_B$disease_status[IDX_B],
    dimensions = 1,
    seed= session_seeds[[B]], 
    level = 0.05
    )
    rel_1D<- colnames(set_B$taxa_binary)[MDFS_1D$relevant.variables]
    # Perform MDFS with 2D
    gc()
    MDFS_2D<- MDFS.discrete(
    data = set_B$taxa_binary[IDX_B,],
    decision = set_B$disease_status[IDX_B],
    dimensions = 2,
    seed = session_seeds[[B]],
    level = 0.05
    )
    rel_2D<- colnames(set_B$taxa_binary)[MDFS_2D$relevant.variables]
    rel_1or2D<-  union( rel_1D, rel_2D)  
    FS<- list(rel_1D= rel_1D,
            rel_2D= rel_2D,
            rel_1or2D=rel_1or2D)
    saveRDS( FS, sprintf("MDFS_results/FS_replicate_%d.rds", B ) )
    saveRDS( list(MDFS_1D=MDFS_1D,
                MDFS_2D=MDFS_2D),
            sprintf("MDFS_results/MDFS_replicate_%d.rds", B ) )
	}
            

    #RF
	if ( ! file.exists( sprintf("RF_models/RF_replicate_%d.rds",B)) ) {
    unique(IDX_B)-> uqIDX_B
	  gc()
    set.seed(session_seeds[[B]])
    randomForest(x = set_B$taxa_binary[uqIDX_B, consensus_1D],
                y =  as.factor(set_B$disease_status[uqIDX_B]),
                importance = TRUE,
                keep.forest = TRUE)-> RF_1D
    gc()
    set.seed(session_seeds[[B]])
    randomForest(x = set_B$taxa_binary[uqIDX_B, consensus_AllRelevant],
                y =  as.factor(set_B$disease_status[uqIDX_B]),
                importance = TRUE,
                keep.forest = TRUE)-> RF_all
    saveRDS(list(RF_1D=RF_1D,
                RF_all=RF_all),
            sprintf("RF_models/RF_replicate_%d.rds", B)
    )
	}
    message(sprintf("%d/%d done", B, N_TRIALS))
}
```

### Aggregation of results

#### Count how many times relevant features showed up again and compute mean random forest metrics
```{r}
library(pROC)
source("balanced_decision.R")
#filename patterns for reading the results
fs_fpattern<-"MDFS_results/FS_replicate_%d.rds"
mdfs_fpattern<-"MDFS_results/MDFS_replicate_%d.rds"
rf_fpattern<- "RF_models/RF_replicate_%d.rds" 

#containers:
rel_2D_trials<-rel_1D_trials<- list()  #for indicators of relevance per each run
CM1_trials<-CMall_trials<-  list() #for confusion matrices
RF1_trials<- RFall_trials<-list() #for RF performance metrics

#auxiliary oods ratio computation
odds_ratio<- function(CM) {(CM[2,2]*CM[1,1])/(CM[1,2]*CM[2,1]) } 

for (B in 1:N_TRIALS){

B_tnames<-colnames(base_resamples[[B]]$taxa_abundance)
B_P<- base_resamples[[B]]$taxa_binary #presence
B_A<- base_resamples[[B]]$taxa_abundance #presence
B_y<- base_resamples[[B]]$disease_status


#indexes of resampled and oob subjects
B_IDX<- B_idx[[B]]
B_oob<- setdiff( 1:nrow(B_A), unique(B_IDX))

B_fs_fname<- sprintf( fs_fpattern, B)
B_FS<- readRDS( B_fs_fname)

#relevance indicators
rel_1D_trials[[B]]= 1.*(consensus_AllRelevant %in% B_FS$rel_1D)
rel_2D_trials[[B]]= 1.*(consensus_AllRelevant %in% B_FS$rel_2D)

#RF prediction on OOB

B_fs_fname<- sprintf( fs_fpattern, B)
B_rf_fname<- sprintf( rf_fpattern, B)
B_RF<- readRDS(B_rf_fname)$RF_all
B_RF1<- readRDS(B_rf_fname)$RF_1D


#predicted probabilities
B_RFall_prob<- predict( B_RF, newdata= B_P[B_oob,], type="prob")[,2]
B_RF1_prob<- predict( B_RF1, newdata= B_P[B_oob,], type="prob")[,2]


B_yoob<- B_y[B_oob]

#predicted classes
B_RFall_cl<-  balanced.decision(B_RFall_prob,as.factor(B_yoob))$decision
B_RF1_cl<- balanced.decision(B_RF1_prob,as.factor(B_yoob))$decision

#confusion matrices
cm_all<- table(Predicted=B_RFall_cl,Actual=B_yoob)
cm_1<- table(Predicted=B_RF1_cl,Actual=B_yoob)

CM1_trials[[B]]<- cm_1
CMall_trials[[B]]<- cm_all


RFall_score<- c(auc= auc(response=B_yoob, predictor= B_RFall_prob,quiet=TRUE),
		OR=odds_ratio(cm_all),
		acc= sum( B_yoob == B_RFall_cl)/length(B_yoob)
)
RF1_score<- c(auc= auc(response=B_yoob, predictor= B_RF1_prob,quiet=TRUE),
	      OR=odds_ratio(cm_1),
		acc= sum( B_yoob == B_RF1_cl)/length(B_yoob)
	      )

RF1_trials[[B]]<- RF1_score
RFall_trials[[B]]<- RFall_score
message(sprintf("%d/%d done", B, N_TRIALS))

}


print("mean stats and SDs for RF on 1D:")
print(colMeans(do.call(rbind,RF1_trials)) )
print(colSds(do.call(rbind,RF1_trials)) )
print("confustuon matrix for all trials of RF on 1D:")
mean_CM_1D<- Reduce("+", CM1_trials)
print(mean_CM_1D)

print("mean stats for RF on 1,2D and partners:")
print(colMeans(do.call(rbind,RFall_trials)) )
print(colSds(do.call(rbind,RFall_trials)) )
print("confusion matrix for all trials of RF on 1, 2D and partners:")
mean_CM_all<- Reduce("+", CMall_trials)
print(mean_CM_all)

#reappearance as relevant in BS per each feature
Reduce("+", rel_1D_trials)->times_rel1D_BS
Reduce("+", rel_2D_trials)->times_rel2D_BS

names(times_rel1D_BS)<- names(times_rel2D_BS)<- consensus_AllRelevant

```

### Check the plausibility of initial feature set:

```{r}

summary_df$BS_rel1D= times_rel1D_BS[ summary_df$name ]
summary_df$BS_rel2D= times_rel2D_BS[ summary_df$name ]
viz_df<-summary_df
viz_df$name<- unlist(lapply(summary_df$name, get_deepest_taxonomy_lvl))
rownames(viz_df)<-NULL
viz_df$name[[ which(
viz_df$name=="s__gamma_proteobacterium_symbiont_of_Gonopsis_affinis"
)
]]="s_gp_symb_Gon_aff"
viz_df[, c("name","rel_1D","BS_rel1D")]
```

```{r}

viz_df[, c("name","rel_2D","BS_rel2D")]

```

# Comparison with SOTA

We ran the similar 2-phase resampling based procedure of feature selection, taking U-test as the feature selector, utilizing the same criteria in terms of level of significance and p-value adjustment (0.05 with holm method correction).

Note that we should not expect purely synergistic taxa to appear in the result of the U-test as it is purely an univariate test.
In contrast, MDFS can identify features that are not relevant for disease status by themselves.

#### Streamlined process for U-test

Sourced script contains the essential steps needed for estabilishing feature sets found in base resamples and bootstrap validation sets and can work for any feature selection method which is formulated with the same convention as below U-test example function:

- it should accept as necessary input parameters, feature table and response vector
- it should return a list with fields `p.value`, `adjusted.p.value`, `relevant.variables` and `rel_set` (names of relevant taxa) containing the result
- optional parameters `lvl`, `p.adjust.method` should control determination of relevant features from raw p-values (if the feature selection method is a statistical filter).



```{r}
source("resample_FS_procedure.R")
U_test_FS
U_test_FS(base_resamples[[1]]$taxa_abundance, decision = base_resamples[[1]]$disease_status)->xx
```

```{r}
resample_FS_procedure(List_base_resamples = base_resamples,
                      List_bootrap_indexes = B_idx, #list of bootstrap indexes 
                      FS_function = U_test_FS,
                      FS_on_binary = FALSE, #do FS on taxa_binary or taxa_abundance
                      lvl=0.05,
                      p.adjust.method = "holm"
                      )-> U_test_rel_Taxa
```

#### Compare with MDFS

##### 'base' resamples

```{r}
union(summary_df$name, U_test_rel_Taxa$feature_name)-> taxa_by_any_method
data.frame(name=taxa_by_any_method,
           `MDFS_1D`=taxa_by_any_method %in% summary_df$name[summary_df$rel_1D==30],
           `MDFS_2D`=taxa_by_any_method %in% summary_df$name[summary_df$rel_2D==30],
            `U_test`=taxa_by_any_method %in% U_test_rel_Taxa$feature_name[U_test_rel_Taxa$n_rel_base==30])-> df_base
df_base[["MDFS_2D_only"]]= df_base[["MDFS_2D"]] & (!df_base[["MDFS_1D"]])
head(df_base)
```

First, we can see that none of the features relevant in 2D only appear in univariate U_test.



```{r}
print(sum(df_base[df_base$MDFS_2D_only,"U_test"]))
head(df_base[df_base$MDFS_2D_only,])
```


Second, we can examine the intersection between MDFS 1D, 2D and U-test:

```{r}

generate_crosstab <- function(df) {
  # Create an empty matrix to store the cross tabulation
  crosstab_matrix <- matrix(0, nrow = 4, ncol = 4)
  colnames(crosstab_matrix) <-colnames(df)
  rownames(crosstab_matrix) <- colnames(df)
  
  # Iterate over all pairs of columns
  for (col1 in colnames(df)) {
    for (col2 in colnames(df)) {
      # Calculate the number of times both columns have TRUE in the same row
      count <- sum(df[[col1]] & df[[col2]], na.rm = TRUE)
      # Update the crosstab matrix
      crosstab_matrix[col1, col2] <- count
    }
  }
  crosstab_matrix
}
  
generate_crosstab(df_base[,2:ncol(df_base)])
```
```{r}

df_base[df_base$U_test & (!(df_base$MDFS_2D | df_base$MDFS_1D)), ]$name -> U_test_only_taxa

U_test_only_taxa

data.frame(names=U_test_only_taxa,
           IG1D=MDFS_object_lists[[1]][[1]]$statistic[ match(U_test_only_taxa, colnames(base_resamples[[1]]$taxa_binary)) ],
           IG2D=MDFS_object_lists[[2]][[1]]$statistic[ match(U_test_only_taxa, colnames(base_resamples[[1]]$taxa_binary)) ],
           pvU= xx$adjusted.p.value[ match(U_test_only_taxa, colnames(base_resamples[[1]]$taxa_binary),  ) ]
           )

```


##### final resampled test

```{r}
data.frame(name=taxa_by_any_method,
           `MDFS_1D`=taxa_by_any_method %in% summary_df$name[summary_df$BS_rel1D==30],
           `MDFS_2D`=taxa_by_any_method %in% summary_df$name[summary_df$BS_rel2D==30],
            `U_test`=taxa_by_any_method %in% U_test_rel_Taxa$feature_name[U_test_rel_Taxa$n_rel_bs==30])-> df_bs
df_bs[["MDFS_2D_only"]]= df_bs[["MDFS_2D"]] & (!df_bs[["MDFS_1D"]])
generate_crosstab(df_bs[,2:ncol(df_bs)])
```

```{r}
df_bs[df_bs$U_test & (!(df_bs$MDFS_2D | df_bs$MDFS_1D)), ]$name -> U_test_only_taxa_BS

U_test_only_taxa_BS


```


# Does binarization affect the result?

```{r}
source("draw_once_per_host2.R")
y<- 1- metadata$allergic.to.i.have.no.food.allergies.that.i.know.of 
names(y)<- rownames(metadata)
library(matrixStats)
host_id<- metadata$host.subject.id
names(host_id)<- rownames(metadata)
base_resamples_0bin<-list()
if (!file.exists("base_resamples_0bin.rds")){
for (i in 1:30){
  gc()
  set.seed(i)
draw_once_per_host(taxonomy=tdata, disease = y, host_id = host_id, binarize_on_median = FALSE,
                   min_minority_class_taxa =20, min_minority_class_dis = 30,print_summary = FALSE,
                   report_progess = TRUE)->base_resamples_0bin[[i]]
message(sprintf("%d/30 done",i))
}
saveRDS(base_resamples_0bin, "base_resamples_0bin.rds") } else {
  base_resamples_0bin<-readRDS("base_resamples_0bin.rds")
}

```


```{r}
#ensure that we have the same donors in two approaches
stopifnot(all(
mapply(function(r1,r2) all(r1$host_id==r2$host_id), base_resamples,
       base_resamples_0bin)
))
```

```{r}
#do all taxa pass min. minority class filter the same?
all(
mapply(function(r1,r2) all(colnames(r1$taxa_binary)==colnames(r2$taxa_binary)), base_resamples,
       base_resamples_0bin)
)
```

```{r}
#how many variables differ betwen methods
columns_equal<- function(df1,df2) mapply(function(COL1,COL2) all(COL1==COL2),df1,df2 )
do.call(rbind,mapply(function(r1,r2) c(sum(columns_equal(r1$taxa_binary,r2$taxa_binary)),
                         ncol(r1$taxa_binary)), base_resamples,base_resamples_0bin,
       SIMPLIFY=FALSE))
```

```{r}
which.cols.differ<- function(df1,df2) mapply(function(COL1,COL2) 
   !all(COL1==COL2) ,df1,df2 )
Reduce(union,mapply(function(r1,r2) colnames(r1$taxa_binary)[which.cols.differ(r1$taxa_binary,
                                                                               r2$taxa_binary)], base_resamples,base_resamples_0bin,
       SIMPLIFY=FALSE))-> common_taxa
```

```{r}
plot(unname(colSums(tdata[,common_taxa]>0)/nrow(tdata)) |> sort(),
     main="% of non zero cells for common variables")
```



## MDFS pipeline on new binarization

```{r}
source("MDFS_analysis_pipeline.R")
#TO DO: change synergistic partners to most frequent ones
base_MDFS_end2end(baseResamples = base_resamples_0bin, variant_name = "FA_0bin")-> df_0bin_base

```

```{r}
print("total numbers found (relevant + partners):")
df_0bin_base |> nrow()
summary_df |> nrow()

df_0bin_base$name[ !df_0bin_base$partner_only ] -> relevant_in0bin
summary_df$name[ !summary_df$partner_only ] -> relevant_inMEDbin
print("relevant set sizes (excluding partners):")
print("common part size:")
length(intersect(relevant_in0bin, relevant_inMEDbin))
print("found by median method, not by 0")
length(setdiff(relevant_inMEDbin, relevant_in0bin))
print("found by 0, not by median")
length(setdiff(relevant_in0bin, relevant_inMEDbin))



```

```{r}
rbind(
df_0bin_base[df_0bin_base$name %in% setdiff(relevant_in0bin, relevant_inMEDbin),c("name","IG1D","IG2D")],
summary_df[summary_df$name %in% setdiff(relevant_inMEDbin, relevant_in0bin),c("name","IG1D","IG2D") ])->temp
rownames(temp)<-NULL
temp$name<-sapply(temp$name, get_deepest_taxonomy_lvl)
temp

```

### bootstrap resampling

```{r}
source("MDFS_analysis_pipeline.R")

bootstrap_MDFS(b_idx=B_idx,baseResamples = base_resamples_0bin,seeds=session_seeds,variant_name="FA_0bin",base_allRel = df_0bin_base$name)-> bs_0bin_reldf
```

```{r}

bs_0bin_reldf$name[ (bs_0bin_reldf$BS_rel1D==30) | (bs_0bin_reldf$BS_rel2D==30) ] -> bs_confirmed_0bin
summary_df$name[ (summary_df$BS_rel1D==30) | (summary_df$BS_rel2D==30) ] -> bs_confirmed_MEDbin

length(bs_confirmed_0bin)
length(bs_confirmed_MEDbin)

length(intersect(bs_confirmed_0bin,bs_confirmed_MEDbin))

sum(bs_confirmed_0bin%in% bs_confirmed_MEDbin)

```

```{r}
rbind(
df_0bin_base[df_0bin_base$name %in% setdiff(bs_confirmed_0bin, bs_confirmed_MEDbin),c("name","IG1D","IG2D")],
summary_df[summary_df$name %in% setdiff(bs_confirmed_MEDbin, bs_confirmed_0bin),c("name","IG1D","IG2D") ])->temp
rownames(temp)<-NULL
temp$name<-sapply(temp$name, get_deepest_taxonomy_lvl)
temp
```

# MDFS 3D test

To initial 30 base resamples of either discretization method (0 or median based) we added 90 new ones, giving 120 base resamples in total.

MDFS in 3 dimensions was run on all of those sets

```{r}
base_resamples_extended<-readRDS("extended_base_resamples.rds")
base_resamples_0binextended<-readRDS("extended_base_resamples_0bin.rds")
```

```{r}

lapply(seq_along(base_resamples_extended), function(i)
{
  x<-readRDS(sprintf("MDFS_results/MDFS_3D_i=%d.rds",i))
  x$med[c("statistic","p.value","adjusted.p.value","relevant.variables")]
}
  )->MDFS_3D_med
```

```{r}

lapply(seq_along(base_resamples_extended), function(i)
{
  x<-readRDS(sprintf("MDFS_results/MDFS_3D_i=%d.rds",i))
  x$zero[c("statistic","p.value","adjusted.p.value","relevant.variables")]
}
  )->MDFS_3D_zero
```

```{r}
get_rel_taxa_names<-function(base_resampled_set, MDFS_result){
  
  colnames(base_resampled_set$taxa_binary)[ MDFS_result$relevant.variables ]
  
}


```
```{r}

mapply(get_rel_taxa_names, base_resamples_extended, MDFS_3D_med )-> rel_taxa_3D_med
mapply(get_rel_taxa_names, base_resamples_0binextended, MDFS_3D_zero )-> rel_taxa_3D_zero

```

```{r}
selection_frequency<- function(names_list){
  all_names<- Reduce(union, names_list)
  counts<-Reduce("+",lapply(names_list, function(x) all_names %in% x ))
  names(counts)<- all_names
  counts
}
```

```{r}

freq_3D_med<- selection_frequency(rel_taxa_3D_med)
freq_3D_zero<- selection_frequency(rel_taxa_3D_zero)

```
### Are there any taxa found consistently relevant in lower dimension, but not relevant in 3D??

Yes, but their statistics are on the lower side, which means that they are not declared as relevant due to stricter criterion on the k-relevance that has  to be satisfied for 3-tuples.

```{r}
union(df_0bin_base$name[!df_0bin_base$partner_only],
  summary_df$name[!summary_df$partner_only] ) -> base_confirmed_12Drel
    
print(sprintf("%d out of %d relevant taxa found in lower dimension appear in any run of 3D",
              sum(base_confirmed_12Drel %in% union(names(freq_3D_med),names(freq_3D_zero))),
              length(base_confirmed_12Drel)
))

base_confirmed_12Drel[!(base_confirmed_12Drel %in% 
                          union(names(freq_3D_med),names(freq_3D_zero)))]-> not_found_in_3D
print("2D IGs of remaining ones are:")
summary_df$IG2D[summary_df$name %in% not_found_in_3D]

```


### 3D relevance frequency plots:

```{r}

barplot(sort(unname(freq_3D_med)), main="median based relevance frequencies")
barplot(sort(unname(freq_3D_zero)), main="zero based relevance frequencies")
```

### Are there any taxa all times 3D relevant, but not all times relevant in lower dimension?

```{r}
union(df_0bin_base$name[!df_0bin_base$partner_only],
  summary_df$name[!summary_df$partner_only] ) -> base_confirmed_12Drel
    
print(sprintf("%d out of %d relevant taxa found in 3D appear in 2D or 1D",
              sum( union(names(freq_3D_med)[freq_3D_med==120],
                        names(freq_3D_zero)[freq_3D_zero==120])  %in% base_confirmed_12Drel),
              length(union(names(freq_3D_med)[freq_3D_med==120],
                        names(freq_3D_zero)[freq_3D_zero==120]))
))

```

### Synergistic triplets

```{r}

for (i in seq_along(base_resamples_extended[1:1])){
    ComputeInterestingTuplesDiscrete(data = base_resamples_extended[[i]]$taxa_binary,
                              decision = base_resamples_extended[[i]]$disease_status,
                              dimensions = 3,
                              interesting.vars = MDFS_3D_med[[i]]$relevant.variables
                              )->y
  
}

```


```{r}
if (!file.exists("MDFS_3D_discrete.RData")){
set.seed(21312)
  MDFS.discrete(data=tb_meanMED, decision = decision.mean.final, dimensions = 3, seed=21312)-> MDFS_3D_MEDbin
set.seed(21312)
  MDFS.discrete(data=tb_mean0, decision = decision.mean.final, dimensions = 3, seed=21312)-> MDFS_3D_0bin
  save(MDFS_3D_MEDbin, MDFS_3D_0bin, file = "MDFS_3D_discrete.RData")
} else {
  load("MDFS_3D_discrete.RData")
}
```

```{r}
union(
colnames(tb_mean0)[MDFS_3D_0bin$relevant.variables],
colnames(tb_mean0)[MDFS_3D_MEDbin$relevant.variables])-> taxa_3D
length(taxa_3D)
union(summary_df$name, df_0bin_base$name)-> taxa_2D_and_partners_bothMethods
taxa_3D[ !(taxa_3D %in% taxa_2D_and_partners_bothMethods) ]-> taxa_3D_only

```


```{r}

union(taxa_3D, taxa_2D_and_partners_bothMethods)-> all_relevant_123D

MDFS_3D$statistic-> stat_3D
colnames(taxonomy.mean.final)->names(stat_3D)

taxa_1D_only<- names(rel_freq_1D)[(rel_freq_1D==30) & (rel_freq_2D<30)]
taxa_2D<- names(rel_freq_1D)[(rel_freq_2D==30)]

plot_colors<- ifelse(all_relevant_123D %in% taxa_1D_only, "red",
                     ifelse(all_relevant_123D %in% taxa_2D, "blue",
                            ifelse(all_relevant_123D %in% taxa_3D_only, "green", "gray")))

stat_3D[all_relevant_123D]-> stat_3D_plot
order(-stat_3D_plot)->order_3D
stat_3D_plot<-stat_3D_plot[order_3D]
plot_colors<-plot_colors[order_3D]

hist(stat_3D[taxa_3D_only])

names(stat_3D_plot)<- lapply(names(stat_3D_plot), get_deepest_taxonomy_lvl) |> unlist()
par(mar = c(8, 4, 4, 2))  # Adjust the margin on the bottom (first value)
barplot(stat_3D_plot[1:30], main="MDFS 3D statistics for relevant taxa",
        col = plot_colors[1:30],
        las=3,cex.names = 0.65, ylab="IG (3D)")
legend("topright", pch=15, col=c("blue","green"), legend=c("2D relevant","3D only"))
abline(h=80, lty="dotted")
abline(h=70, lty="dotted")
abline(h=90, lty="dotted")
abline(h=60, lty="dotted")
abline(h=50, lty="dotted")

```

####Compare with U-test

```{r}
intersect(setdiff(taxa_3D,any_times_relevant_taxa), xx$rel_set)-> only_3D_but_Utest
unname(cbind(stat_3D[only_3D_but_Utest],
      lapply(only_3D_but_Utest, get_deepest_taxonomy_lvl) |> unlist(),
      xx$adjusted.p.value[xx$relevant.variables][match(only_3D_but_Utest,xx$rel_set)]))->df_comparison

colnames(df_comparison)<- c("IG","taxon","U_test.adjusted.p.value")
      df_comparison


```
```{r}
x=base_resamples[[1]]$taxa_abundance[,"sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"]
 y=base_resamples[[1]]$disease_status
 x[(y==0)&(x!=0)]->x0
 x[(y==1)&(x!=0)]->x1
 range(c(x0,x1))->x01rng
 seq(from=x01rng[[1]],to=x01rng[[2]],length.out=20)->brks
 hist(x[(y==0)&(x!=0)], plot=FALSE,breaks=brks)->h1
 hist(x[(y==1)&(x!=0)], plot=FALSE,breaks=brks)->h2
 plot(h2$mids, h2$counts, lwd=2, type="line", col="green",log='y')
 lines(h1$mids, h1$counts, lwd=2, col="red")
```

#### Redo 2D analysis on median dataset

```{r}
library(MDFS)
base_resamples<-readRDS("base_resamples.rds")
 MDFS_1D_result_ab <- MDFS(
    data = base_resamples[[1]]$taxa_abundance, #taxonomy.mean.final, # 
    decision = base_resamples[[1]]$disease_status, #decision.mean.final, 
    dimensions = 1,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed = 1,
    level = 0.05
  )
  MDFS_1D_result_bin <- MDFS(
    data = base_resamples[[1]]$taxa_binary, #taxonomy.mean.final, # 
    decision = base_resamples[[1]]$disease_status, #decision.mean.final, 
    dimensions = 1,
    divisions = 1,
    discretizations = 1,
    range = 0,
    seed = 1,
    level = 0.05
  )

```

#### MDFS::Discretize at fault?

```{r}
base_data<- base_resamples[[1]]
pseudomonas_name<-"sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"

MDFS::Discretize(base_data$taxa_abundance,
                 variable.idx = which(colnames(base_data$taxa_abundance)==
                                  pseudomonas_name),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_ab_MDFS_discretized # dyskretyzowane abundance z MDFS


pseudomonas_bin_median_discr<- base_resamples[[1]]$taxa_binary[,pseudomonas_name] # dyskretyzowane binarnie z miediany


print("MDFS abundance binarized vs manual median binarized")
print(
table(pseudomonas_bin_median_discr, pseudomonas_ab_MDFS_discretized)
)



# binarny wstawiony w MDFS::Discretize
MDFS::Discretize(base_data$taxa_binary,
                 variable.idx = which(colnames(base_data$taxa_abundance)==
                                  pseudomonas_name),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_bin_MDFS_discretized # dyskretyzowane abundance z MDFS



print("MDFS::Discretize(median binarized variable) vs manual median binarized")
print(
table(pseudomonas_bin_median_discr, pseudomonas_bin_MDFS_discretized)
)



```

```{r}
pseudomonas_name %in% colnames(base_resamples[[1]]$taxa_binary)[MDFS_1D_result_ab$relevant.variables]
pseudomonas_name %in% colnames(base_resamples[[1]]$taxa_binary)[MDFS_1D_result_bin$relevant.variables]


```
```{r}
 colnames(base_resamples[[1]]$taxa_binary)-> b1_tnames
MDFS_1D_result_ab$statistic[MDFS_1D_result_ab$relevant.variables]-> b1_stat_ab
MDFS_1D_result_bin$statistic[MDFS_1D_result_ab$relevant.variables]-> b1_stat_bin
data.frame(ab=round(b1_stat_ab,4),bin=round(b1_stat_bin,4),name=lapply(b1_tnames[MDFS_1D_result_ab$relevant.variables], 
                                    get_deepest_taxonomy_lvl) |> unlist())->df_ab_vs_bin_stat

df_ab_vs_bin_stat[order(-df_ab_vs_bin_stat$ab),]

```



```{r}
MDFS::Discretize(base_resamples[[1]]$taxa_abundance,
                 variable.idx = which(colnames(base_resamples[[1]]$taxa_abundance)==
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_MDFS_discr
```

```{r}
MDFS::Discretize(base_resamples[[1]]$taxa_binary,
                 variable.idx = which(colnames(base_resamples[[1]]$taxa_abundance)==
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"),
                 divisions = 1,range=0,discretization.nr=1, seed=123
                                         )-> pseudomonas_bin_MDFS_discr

```


```{r}
base_resamples[[1]]$taxa_binary[,
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"]->pseudomonas_bin
```

```{r}
base_resamples[[1]]$taxa_abundance[,
                                  "sk__Bacteria.k__.p__Proteobacteria.c__Gammaproteobacteria.o__Pseudomonadales.f__Pseudomonadaceae.g__Pseudomonas"]->pseudomonas_ab
```

```{r}

table(pseudomonas_bin, pseudomonas_MDFS_discr)
table(pseudomonas_bin, pseudomonas_bin_MDFS_discr)

```

```{r}

colnames(base_resamples[[1]]$taxa_binary)[MDFS_2D_result_mean$relevant.variables]
#colnames(taxonomy.mean.final)[MDFS_2D_result_mean$relevant.variables]


```

### Different subtypes of food allergy


Main steps of the pipeline are contained in `resampled_MDFS_analysis.R` and include:

- resampling of the dataset - picking 1 sample per each repeating donor
- adjustment for the decision variable used - removal of variables with low counts in one of the classes
- feature selection using MDFS
- selection of consistently relevant taxa
- picking of the best partners for the relevant taxa


```{r}
decisions=c("allergic_to_peanuts", "allergic_to_shellfish", "allergic_to_tree_nuts")
decision_results<- list()
source("resampled_MDFS_analysis.R")
for (i in seq_along(decisions)){
  set.seed(i)
seeds<-sample.int(343242,30)
print(sprintf("working on %s",decisions[[i]]))
resample_MDFS(metadata = metadata, taxonomy = tdata, 
              decision_colname=decisions[[i]],
			         n_resamples=30,
			         seeds=seeds,
			          host_id_colname="host.subject.id",
			            #passed to draw_once_per_host
                   	 min_minority_class_taxa =20, 
			            min_minority_class_dis = 30,
			          binarize_on_median=TRUE,
			          print_summary = FALSE,
                report_progess = TRUE)-> decision_results[[i]]
}
```